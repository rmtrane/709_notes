<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>STAT 709: My notes</title>
  <meta name="description" content="This is my collection of notes for the STAT 709 class taught at UW-Madison.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="STAT 709: My notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my collection of notes for the STAT 709 class taught at UW-Madison." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="STAT 709: My notes" />
  
  <meta name="twitter:description" content="This is my collection of notes for the STAT 709 class taught at UW-Madison." />
  

<meta name="author" content="Ralph Møller Trane">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="discussion-notes.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#textbook"><i class="fa fa-check"></i><b>1.1</b> Textbook</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#conventions-re-infty"><i class="fa fa-check"></i><b>1.2</b> Conventions re: <span class="math inline">\(\infty\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lectures.html"><a href="lectures.html"><i class="fa fa-check"></i><b>2</b> Lecture Notes</a><ul>
<li class="chapter" data-level="2.1" data-path="lectures.html"><a href="lectures.html#chapter-1-probability-theory"><i class="fa fa-check"></i><b>2.1</b> Chapter 1: Probability Theory</a><ul>
<li class="chapter" data-level="2.1.1" data-path="lectures.html"><a href="lectures.html#lecture-1-measure-space-measurable-function-and-integration"><i class="fa fa-check"></i><b>2.1.1</b> Lecture 1: Measure space, measurable function, and integration</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="lectures.html"><a href="lectures.html#lecture-2-911"><i class="fa fa-check"></i><b>2.2</b> Lecture 2: 9/11</a><ul>
<li class="chapter" data-level="2.2.1" data-path="lectures.html"><a href="lectures.html#integration"><i class="fa fa-check"></i><b>2.2.1</b> Integration</a></li>
<li class="chapter" data-level="2.2.2" data-path="lectures.html"><a href="lectures.html#radon-nikodym-derivatives"><i class="fa fa-check"></i><b>2.2.2</b> Radon-Nikodym Derivatives</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lectures.html"><a href="lectures.html#lecture-3-913"><i class="fa fa-check"></i><b>2.3</b> Lecture 3: 9/13</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discussion-notes.html"><a href="discussion-notes.html"><i class="fa fa-check"></i><b>3</b> Discussion Notes</a><ul>
<li class="chapter" data-level="3.1" data-path="discussion-notes.html"><a href="discussion-notes.html#discussion-1-514"><i class="fa fa-check"></i><b>3.1</b> Discussion 1: 5/14</a><ul>
<li class="chapter" data-level="3.1.1" data-path="discussion-notes.html"><a href="discussion-notes.html#sigma-fields-1"><i class="fa fa-check"></i><b>3.1.1</b> <span class="math inline">\(\sigma\)</span>-fields</a></li>
<li class="chapter" data-level="3.1.2" data-path="discussion-notes.html"><a href="discussion-notes.html#pi-lambda-systems"><i class="fa fa-check"></i><b>3.1.2</b> <span class="math inline">\(\pi-\lambda\)</span> systems</a></li>
<li class="chapter" data-level="3.1.3" data-path="discussion-notes.html"><a href="discussion-notes.html#the-good-sets-principle"><i class="fa fa-check"></i><b>3.1.3</b> The “Good Sets” Principle</a></li>
<li class="chapter" data-level="3.1.4" data-path="discussion-notes.html"><a href="discussion-notes.html#from-indicator-function-to-general-borel-function"><i class="fa fa-check"></i><b>3.1.4</b> From Indicator Function to General (Borel) Function</a></li>
<li class="chapter" data-level="3.1.5" data-path="discussion-notes.html"><a href="discussion-notes.html#switch-the-order-of-integration-and-limit"><i class="fa fa-check"></i><b>3.1.5</b> Switch the Order of Integration and Limit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="homework.html"><a href="homework.html"><i class="fa fa-check"></i><b>4</b> Homework</a><ul>
<li class="chapter" data-level="4.1" data-path="homework.html"><a href="homework.html#first-exam-period"><i class="fa fa-check"></i><b>4.1</b> First Exam Period</a><ul>
<li class="chapter" data-level="4.1.1" data-path="homework.html"><a href="homework.html#assigned-problems"><i class="fa fa-check"></i><b>4.1.1</b> Assigned Problems</a></li>
<li class="chapter" data-level="4.1.2" data-path="homework.html"><a href="homework.html#suggested-problems"><i class="fa fa-check"></i><b>4.1.2</b> Suggested Problems</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 709: My notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="homework" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Homework</h1>
<div id="first-exam-period" class="section level2">
<h2><span class="header-section-number">4.1</span> First Exam Period</h2>
<div id="assigned-problems" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Assigned Problems</h3>
<p>NOTE: This homework submission is for both Ralph Trane and Alex Hayes. For almost all of the problems here, we worked together on a whiteboard. We then took pictures or handwritten notes of the solutions and wrote them up here.</p>

<div class="exercise">
<span id="exr:unnamed-chunk-1" class="exercise"><strong>Exercise 4.1  (Ex 2)  </strong></span>Let <span class="math inline">\(\C\)</span> be a collection of subsets of <span class="math inline">\(\Omega\)</span> and let <span class="math inline">\(\Gamma = \{ \F | \F \text{ is a } \sigma \text{-field on } \Omega \text{ and } \C \subset \F \}\)</span>. Show that <span class="math inline">\(\Gamma \neq \emptyset\)</span> and <span class="math inline">\(\sigma(\C) = \cap_{\F \in \Gamma} \F\)</span>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 2). </span> Let <span class="math inline">\(\P(\Omega)\)</span> be the collection of all subsets of <span class="math inline">\(\Omega\)</span>. We know that this is a <span class="math inline">\(\sigma\)</span>-field. It also contains <span class="math inline">\(\C\)</span>. Hence, <span class="math inline">\(\Gamma \neq \emptyset\)</span>.</p>
<p>By definition, <span class="math inline">\(\sigma(\C)\)</span> is the smallest <span class="math inline">\(\sigma\)</span>-field that contains <span class="math inline">\(\C\)</span>, hence <span class="math inline">\(\sigma(\C) \in \Gamma\)</span> and <span class="math inline">\(\sigma(\C) \subset \F\)</span> for all <span class="math inline">\(\F \in \Gamma\)</span>. Therefore, <span class="math inline">\(\sigma(\C) \subset \cap_{\F \in \Gamma} \F\)</span>. But since <span class="math inline">\(\sigma(\C) \in \Gamma\)</span>, <span class="math inline">\(\sigma(\C) \in \cap_{\F \in \Gamma} \F\)</span>, which in turn ensures that <span class="math inline">\(\cap_{\F \in \Gamma} \F \subset \sigma(\C)\)</span>.</p>
Hence <span class="math inline">\(\sigma(\C) = \cap_{\F \in \Gamma} \F\)</span>.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-3" class="exercise"><strong>Exercise 4.2  (Ex 5)  </strong></span>a) Let <span class="math inline">\(\C\)</span> be a <span class="math inline">\(\pi\)</span>-system and <span class="math inline">\(\mathcal{D}\)</span> be a <span class="math inline">\(\lambda\)</span>-system such that <span class="math inline">\(\C \subset \mathcal{D}\)</span>. Show that <span class="math inline">\(\sigma(\C) \subset \mathcal{D}\)</span>.
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 5). </span> TODO
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-5" class="exercise"><strong>Exercise 4.3  (Ex 12)  </strong></span>Let <span class="math inline">\(\nu\)</span> and <span class="math inline">\(\lambda\)</span> be two measures on <span class="math inline">\((\Omega, \F)\)</span> such that <span class="math inline">\(\nu(A) = \lambda(A)\)</span> for any <span class="math inline">\(A \in \C \subset \F\)</span>, where <span class="math inline">\(\C\)</span> is a <span class="math inline">\(\pi\)</span>-system (<a href="#def:pi-system"><strong>??</strong></a>). Assume that <span class="math inline">\(\nu\)</span> is <span class="math inline">\(\sigma\)</span>-finite (<a href="#def:sigma-finite"><strong>??</strong></a>).</p>
<p>Show that <span class="math inline">\(\nu(A) = \lambda(A)\)</span> for all <span class="math inline">\(A \in \sigma(\C)\)</span>.</p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 12). </span> Let <span class="math inline">\(\F = \{A \in \sigma(\C) | \nu(A) = \lambda(A)\}\)</span>. Then <span class="math inline">\(\C \subset \F\)</span>. If we can show that <span class="math inline">\(\F\)</span> is a <span class="math inline">\(\sigma\)</span>-field, then <span class="math inline">\(\sigma(\C) \subset \F\)</span> (since <span class="math inline">\(\sigma(\C)\)</span> is the smallest <span class="math inline">\(\sigma\)</span>-field that contains <span class="math inline">\(\C\)</span>), which proves that <span class="math inline">\(\nu(A) = \lambda(A)\)</span> for all <span class="math inline">\(A \in \sigma(\C)\)</span>.</p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-7" class="exercise"><strong>Exercise 4.4  (Ex 14)  </strong></span>Prove proposition 1.4 (proposition <a href="#prp:borel-function-properties"><strong>??</strong></a>)
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 14 (i)). </span> 
Assume <span class="math inline">\(f\)</span> is Borel. Then <span class="math inline">\(f^{-1}(A) \in \F\)</span> for all open sets <span class="math inline">\(A \in \B\)</span>, hence <span class="math inline">\(f^{-1}(a, \infty) \in \F\)</span>.</p>
<p>Now assume <span class="math inline">\(f^{-1}(a, \infty) \in \F\)</span> for all <span class="math inline">\(a \in \R\)</span>, and let <span class="math inline">\(\mathcal{G} = \{ A \in \B | f^{-1}(A) \in \F \}\)</span>. So, <span class="math inline">\((a, \infty) \in \mathcal{G}\)</span> for all <span class="math inline">\(a \in \R\)</span>. If we can show that <span class="math inline">\(\mathcal{G}\)</span> is a <span class="math inline">\(\sigma\)</span>-field, then we will have that <span class="math inline">\(\sigma((a, \infty)) = \B \subset \mathcal{G}\)</span>, hence <span class="math inline">\(f^{-1}(B) \in \F\)</span> for all <span class="math inline">\(B \in \B\)</span>, meaning that <span class="math inline">\(f\)</span> is measurable.</p>
<p>So let us prove that <span class="math inline">\(\mathcal{G}\)</span> is a <span class="math inline">\(\sigma\)</span>-field.</p>
<ol style="list-style-type: lower-alpha">
<li>First of all, <span class="math inline">\(f^{-1}(\emptyset) = \emptyset \in \F\)</span>.</li>
<li>Second, let <span class="math inline">\(A \in \mathcal{G}\)</span>. Since <span class="math inline">\(f^{-1}(A^C) = (f^{-1}(A))^C \in \F\)</span> (<span class="math inline">\(\F\)</span> is a <span class="math inline">\(\sigma\)</span>-field and <span class="math inline">\(f^{-1}(A) \in \F\)</span>, so <span class="math inline">\((f^{-1}(A))(^C) \in \F\)</span>).</li>
<li>Finally, let <span class="math inline">\(A_1, A_2, \ldots\)</span> be a sequence of sets such that <span class="math inline">\(A_i \in \mathcal{G}\)</span> for all <span class="math inline">\(i\)</span>. Then <span class="math inline">\(f^{-1}\left(\cup_{i=1}^\infty A_i \right) = \cup_{i=1}^\infty f^{-1}(A_i)\)</span>. Since <span class="math inline">\(f^{-1}(A_i) \in \F\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(\F\)</span> is a <span class="math inline">\(\sigma\)</span>-field, <span class="math inline">\(\cup_{i=1}^\infty f^{-1}(A_i) \in \F\)</span>, so <span class="math inline">\(\cup_{i=1}^\infty A_i \in \mathcal{G}\)</span>.</li>
</ol>
<p>So <span class="math inline">\(\mathcal{G}\)</span> is a <span class="math inline">\(\sigma\)</span>-field, which concludes the proof.</p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 14 (ii)). </span> Assume <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are Borel functions. Let <span class="math inline">\(a,b \in \R\)</span>. <span class="math inline">\(af\)</span> is Borel, since</p>
<p><span class="math display">\[
  (af)^{-1}((c,\infty)) = \left\{ \omega \in \Omega : a\cdot f(\omega) \in (c, \infty) \right\}.
\]</span></p>
<p>If <span class="math inline">\(a \neq 0\)</span>,</p>
<p><span class="math display">\[\begin{aligned}
 (af)^{-1}((c,\infty)) &amp;= \left\{ \omega \in \Omega : f(\omega) \in (\tfrac{c}{a}, \infty) \right\} \\
                       &amp;= f^{-1}(\tfrac{c}{a}, \infty).
\end{aligned}\]</span></p>
<p>Since <span class="math inline">\(f\)</span> is Borel, this is a measurable set (by (i)). If <span class="math inline">\(a = 0\)</span>, then</p>
<p><span class="math display">\[(af)^{-1}((c,\infty)) = 
  \left\{ 
    \begin{matrix} 
      \Omega &amp; \text{ if } c \le 0 \\ 
      \emptyset &amp; \text{ if } c &lt; 0 
    \end{matrix}
  \right .
\]</span></p>
<p>In either case, <span class="math inline">\((af)^{-1}((c, \infty)) \in \F\)</span>. Since it holds that for all <span class="math inline">\(a,c \in \R\)</span> that <span class="math inline">\((af)^{-1}((c,\infty)) \in \F\)</span>, <span class="math inline">\(af\)</span> is measurable by (i).</p>
<p>Let <span class="math inline">\(c \in \R\)</span>. Now consider the sum of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
  (f + g)^{-1}((c, \infty)) &amp;= \left\{ \omega \in \Omega : f(\omega) + g(\omega) &gt; c \right\} \\.
                            &amp;= \cup_{t \in \mb{Q}} \{\omega \in \Omega : f(\omega) &gt; c - t \} \cap \{\omega \in \Omega : g(\omega) &gt; t \} \\
                            &amp;= \cup_{t \in \mb{Q}} f^{-1}((c-t, \infty)) \cap g^{-1}((t, \infty)).
\end{aligned}\]</span></p>
<p>Since <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are both measurable, <span class="math inline">\(f^{-1}((c-t, \infty)) \in \F\)</span> and <span class="math inline">\(g^{-1}((t, \infty))\in \F\)</span> for all <span class="math inline">\(t \in \R\)</span>. Hence, the intersection of the two is measurable for any <span class="math inline">\(t \in \R\)</span>, which in turn implies that the union over all rational numbers is measurable (countable union of measurable sets). Hence, <span class="math inline">\(f+g\)</span> is measurable.</p>
Combine the two results to get the final result.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 14 (iii)). </span> TODO
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 14 (iv)). </span> Assume <span class="math inline">\(f\)</span> is measurable from <span class="math inline">\((\Omega, \F)\)</span> to <span class="math inline">\((\Lambda, \mathcal{G})\)</span>, and <span class="math inline">\(g\)</span> measureable from <span class="math inline">\((\Lambda, \mathcal{G})\)</span> to <span class="math inline">\((\Delta, \mathcal{H})\)</span>. Let <span class="math inline">\(H \in \mathcal{H}\)</span>. We want to show that <span class="math inline">\((g \circ f)^{-1}(H) \in \F\)</span>, since this would mean <span class="math inline">\(g \circ f\)</span> is measurable. So,</p>
<p><span class="math display">\[\begin{aligned}
  (g \circ f)^{-1}(H) &amp;= \left\{ \omega \in \Omega | g(f(\omega)) \in H \right\} \\ 
                      &amp;= \left\{ \omega \in \Omega | f(\omega) \in g^{-1}(H) \right\} \\ 
                      &amp;= f^{-1}(g^{-1}(H)).
\end{aligned}\]</span></p>
<p>Since <span class="math inline">\(g\)</span> is measurable, <span class="math inline">\(g^{-1}(H) \in \mathcal{G}\)</span>, and since <span class="math inline">\(f\)</span> is measurable, <span class="math inline">\(f^{-1}(g^{-1}(H)) \in \F\)</span>. So, <span class="math inline">\(g \circ f\)</span> is measurable.</p>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 14 (v)). </span> Let <span class="math inline">\(f: \Omega \to \R^p\)</span>, where <span class="math inline">\(\Omega\)</span> is a borel set. Assume <span class="math inline">\(f\)</span> is continuous. Then, if <span class="math inline">\(A\)</span> is an open set, <span class="math inline">\(f^{-1}(A)\)</span> is an open set, and therefore borel. Hence, <span class="math inline">\(f^{-1}((a,\infty))\)</span> is a borel set for all <span class="math inline">\(a\)</span>, and by <span class="math inline">\((i)\)</span> we have that <span class="math inline">\(f\)</span> is a borel function.
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-13" class="exercise"><strong>Exercise 4.5  (Ex 19)  </strong></span>
Let <span class="math inline">\(\{f_n\}\)</span> be a sequence of Borel functions on a measurable space. Show that</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\sigma(f_1, f_2, \ldots) = \sigma(\cup_{j=1}^{\infty} \sigma(f_j)) = \sigma(\cup_{j=1}^\infty \sigma(f_1,\ldots, f_j)).\)</span></li>
<li><span class="math inline">\(\sigma(\lim \sup_n f_n) \subset \cap_{n=1}^\infty \sigma(f_n, f_{n+1},\ldots).\)</span></li>
</ol>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 19). </span> TODO
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-15" class="exercise"><strong>Exercise 4.6  (Ex 24)  </strong></span>
Let <span class="math inline">\(f\)</span> be an integrable function on <span class="math inline">\((\Omega, \F, \nu)\)</span>. Show that for each <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta_\epsilon\)</span> such that for <span class="math inline">\(A \in \F\)</span>:</p>
<p><span class="math display">\[
  \nu(A) &lt; \delta_\epsilon \to \int_A |f| d\nu &lt; \epsilon. 
\]</span></p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Let <span class="math inline">\(\epsilon &gt; 0\)</span>, <span class="math inline">\(A \in \F\)</span> with <span class="math inline">\(\nu(A) &lt; \delta_\epsilon = \frac{\epsilon}{\sup_{\omega \in A} |f(\omega)|}\)</span>. Then</p>
<p><span class="math display">\[\begin{align*}
  \int_A |f| d\nu &amp;\leq \int_A \sup_{\omega \in A} |f(\omega)| d\nu \\
                  &amp;= \sup_{\omega \in A} |f(\omega)| \nu(A) \\
                  &amp;&lt; \epsilon.
\end{align*}\]</span></p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-17" class="exercise"><strong>Exercise 4.7  (Ex 30)  </strong></span>For any c.d.f. <span class="math inline">\(F\)</span> and any <span class="math inline">\(a \ge 0\)</span>, show that <span class="math inline">\(\int [F(x+a) - F(x)] dx = a\)</span>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Note that <span class="math inline">\(F(X) = \int 1_{-\infty, x} dP\)</span>. Then</p>
<span class="math display">\[
\begin{aligned}
\int [F(x+a) - F(x)] dx &amp;= \int_\R \left(\int 1_{-\infty, x + a} dP \right) -
   \left(\int 1_{-\infty, x} dP \right) dx\\
&amp;= \int_\R \int 1_{x, x + a} dx \\
&amp;= a 
\end{aligned}
\]</span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-19" class="exercise"><strong>Exercise 4.8  (Ex 34)  </strong></span>Prove proposition <a href="#prp:calc-radon-nikodym"><strong>??</strong></a>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 34 i)). </span> Let <span class="math inline">\(g\)</span> be the unique function denoted by <span class="math inline">\(\frac{d\lambda}{d\nu}\)</span>. Assume <span class="math inline">\(f = 1_A\)</span> for some <span class="math inline">\(A\in \F\)</span>. Since <span class="math inline">\(\lambda &lt;&lt; \nu\)</span>, we know that <span class="math inline">\(\lambda(A) = \int_A g d\nu\)</span>. So,</p>
<p><span class="math display">\[\begin{align*}
  \int f d\lambda &amp;= \int 1_A d\lambda \\
                  &amp;= \lambda(A) \\
                  &amp;= \int_A g d\nu \\
                  &amp;= \int 1_A g d\nu = \int f g d\nu.
\end{align*}\]</span></p>
<p>Hence, (i) is true for all indicator functions, and so by linearity of integrals (<a href="#prp:int-linearity"><strong>??</strong></a>) for all non-negative simple functions.</p>
<p>Now, let <span class="math inline">\(f\)</span> be a general non-negative Borel function. Then we know that there exists a sequence of simple functions <span class="math inline">\(\phi_1, \phi_2, \ldots\)</span> such that <span class="math inline">\(\phi_n \uparrow f\)</span>. Hence, utilizing the monotone convergence theorem and the fact that we know (i) holds for simple functions,</p>
<p><span class="math display">\[\begin{align*}
  \int f d\lambda &amp;= \int \lim_{n \to \infty} \phi_n d\lambda \\
                  &amp;= \lim_{n \to \infty} \int \phi_n d\lambda \\
                  &amp;= \lim_{n \to \infty} \int \phi_n g d\nu \\
                  &amp;= \int \lim_{n \to \infty} \phi_n g d\nu \\
                  &amp;= \int f g d\nu,
\end{align*}\]</span></p>
<p>and so we have shown that (i) holds for any non-negative Borel function.</p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 34 ii)). </span> Assume <span class="math inline">\(\lambda_1 &lt;&lt; \nu\)</span> and <span class="math inline">\(\lambda_2 &lt;&lt; \nu\)</span>. Then</p>
<p><span class="math display">\[\begin{align*}
  (\lambda_1 + \lambda_2)(A) &amp;= \lambda_1(A) + \lambda_2(A) \\
                             &amp;= \int_A g_1 d\nu + \int_A g_2 d\nu \\
                             &amp;= \int_A (g_1 + g_2)d\nu,
\end{align*}\]</span></p>
<p>so <span class="math inline">\(\lambda_1 + \lambda_2 &lt;&lt; \nu\)</span>, and</p>
<span class="math display">\[\frac{d(\lambda_1 + \lambda_2)}{d\nu} = g_1 + g_2 = \frac{d\lambda_1}{d\nu} + \frac{d\lambda_2}{d\nu}.\]</span>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 34 iii)). </span> Since <span class="math inline">\(\tau &lt;&lt; \lambda\)</span>,</p>
<p><span class="math display">\[\tau(A) = \int_A \frac{d\tau}{d\lambda}d\lambda.\]</span></p>
<p>Since <span class="math inline">\(\lambda &lt;&lt; \nu\)</span>, we can use (i) with <span class="math inline">\(f = \frac{d\tau}{d\lambda}\)</span>, to get</p>
<p><span class="math display">\[\tau(A) = \int_A \frac{d\tau}{d\lambda}\frac{d\lambda}{d\tau} d\tau,\]</span></p>
<p>which tells us that <span class="math inline">\(\tau &lt;&lt; \nu\)</span> and</p>
<p><span class="math display">\[\frac{d\tau}{d\nu} = \frac{d\tau}{d\lambda}\frac{d\lambda}{d\tau}.\]</span></p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 34 iv)). </span> 
By definition, <span class="math inline">\((\lambda_1 \times \lambda_2)(A) = \int_A d(\lambda_1 \times \lambda_2) = \int 1_A d(\lambda_1 \times \lambda_2)\)</span>. Since <span class="math inline">\(1_A \ge 0\)</span>, we can use Fubini to get</p>
<p><span class="math display">\[ (\lambda_1 \times \lambda_2)(A) = \int \int 1_A d\lambda_1 d\lambda_2. \]</span></p>
<p>Since <span class="math inline">\(\lambda_1 &lt;&lt; \nu_1\)</span>, we can use (i) with <span class="math inline">\(f = 1_A\)</span> (<span class="math inline">\(1_A\)</span> is non-negative) to obtain that</p>
<p><span class="math display">\[(\lambda_1 \times \lambda_2)(A) = \int \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1 d\lambda_2,\]</span></p>
<p>and then, since <span class="math inline">\(\lambda_2 &lt;&lt; \nu_2\)</span>, using (i) again with <span class="math inline">\(f = \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1\)</span> (which is non-negative) to get</p>
<p><span class="math display">\[(\lambda_1 \times \lambda_2)(A) = \int \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1 \frac{d\lambda_2}{d\nu_2}d\nu_2.\]</span></p>
<p>Finally, using Fubini again we get</p>
<p><span class="math display">\[\begin{aligned}
  (\lambda_1 \times \lambda_2)(A) &amp;= \int \int 1_A \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2} d\nu_1 d\nu_2 \\
                                  &amp;= \int_A \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2} d(\nu_1\times\nu_2).
\end{aligned}\]</span></p>
<p>I.e. <span class="math inline">\(\lambda_1 \times \lambda_2 &lt;&lt; \nu_1 \times \nu_2\)</span> and <span class="math inline">\(\frac{d(\lambda_1 \times \lambda_2)}{d(\nu_1 \times \nu_2)} = \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2}\)</span>.</p>
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-24" class="exercise"><strong>Exercise 4.9  (Ex 35)  </strong></span>Let <span class="math inline">\(\{a_n\}\)</span> be a sequence of positive numbser with <span class="math inline">\(\sum_{i=1}^\infty a_n = 1\)</span>, and <span class="math inline">\(\{P_n\}\)</span> a sequence of probability measure on a common measurable space, <span class="math inline">\((\Omega, \F)\)</span>. Define <span class="math inline">\(P = \sum_{n=1}^\infty P_n\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Show that <span class="math inline">\(P\)</span> is a probability measure.</li>
<li>Let <span class="math inline">\(\nu\)</span> be a <span class="math inline">\(\sigma\)</span>-finite measure. Show that</li>
</ol>
<p><span class="math display">\[P_n &lt;&lt; \nu \text{ for all } n \in \mb{N}\quad \iff \quad P &lt;&lt; \nu.\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Derive the Lebesgue p.d.f. of <span class="math inline">\(P\)</span> when <span class="math inline">\(P_n\)</span> is the gamma distribution <span class="math inline">\(\Gamma(\alpha, n^{-1})\)</span> with <span class="math inline">\(\alpha &gt; 1\)</span> and <span class="math inline">\(a_n \propto n^{-\alpha}\)</span>.</li>
</ol>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 35 a)). </span> Need to show that <span class="math inline">\(P = \sum_{n=1}^{\infty} a_n P_n\)</span> is a probability measure. So we check the three properties for a probability measure (<a href="#def:measure"><strong>??</strong></a>), with the extra property that <span class="math inline">\(P(\Omega) = 1\)</span>:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(P(A) = \sum_{n=1}^\infty a_n P_n(A) \geq 0\)</span> for all <span class="math inline">\(A\)</span> since <span class="math inline">\(a_n &gt; 0\)</span> for all <span class="math inline">\(n\)</span> by assumption, and <span class="math inline">\(P_n(A) \ge 0\)</span> for all <span class="math inline">\(n\)</span>, since <span class="math inline">\(P_n\)</span> is a probability measure. Furthermore, <span class="math inline">\(P(\Omega) = \sum_{n=1}^\infty a_n P_n(\Omega) = \sum_{n=1}^\infty a_n = 1\)</span>, where the second equality holds since <span class="math inline">\(P_n\)</span> is a probability measure (by assumption), and the last equality is exactly the assumption we made about the <span class="math inline">\(a_n\)</span>s. I.e. <span class="math inline">\(0 \le P(A) \le 1\)</span>.</li>
<li>Since <span class="math inline">\(P_n(\emptyset) = 0\)</span>, <span class="math inline">\(P(\emptyset) = \sum_{n=1}^\infty a_n P_n(\emptyset) = 0\)</span>.</li>
<li>Let <span class="math inline">\(A_1, A_2,\ldots\)</span> be a countable sequence of pairwise disjoint sets. Then using that <span class="math inline">\(P_n\)</span> is a measure for all <span class="math inline">\(n\)</span>,</li>
</ol>
<p><span class="math display">\[\begin{aligned}
  P(\cup_{i=1}^\infty A_i) &amp;= \sum_{n=1}^\infty a_nP_n\left(\cup_{i=1}^\infty A_i\right) \\
                           &amp;= \sum_{n=1}^\infty a_n\sum_{i=1}^\infty P_n(A_i) \\
                           &amp;= \sum_{i=1}^\infty \sum_{n=1}^\infty a_n P_n(A_i) \\
                           &amp;= \sum_{i=1}^\infty P(A_i).
\end{aligned}\]</span></p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 35 b)). </span> Assume <span class="math inline">\(P &lt;&lt; \nu\)</span>. Let <span class="math inline">\(A \in \F\)</span> with <span class="math inline">\(\nu(A) = 0\)</span>. Assume there exists <span class="math inline">\(n \in \mb{N}\)</span> such that <span class="math inline">\(P_n(A) &gt; 0\)</span>. Then <span class="math inline">\(P(A) &gt; a_n P_n(A) &gt; 0\)</span>. But <span class="math inline">\(P &lt;&lt; \nu\)</span> implies that <span class="math inline">\(P(A) = 0\)</span>, so by contradiction, <span class="math inline">\(P_n(A) = 0\)</span> for all <span class="math inline">\(n \in \mb{N}\)</span>.</p>
<p>Now assume <span class="math inline">\(P_n &lt;&lt; \nu\)</span>. Let <span class="math inline">\(A \in \F\)</span> with <span class="math inline">\(\nu(A) = 0\)</span>. Then <span class="math inline">\(P_n(A) = 0\)</span> for all <span class="math inline">\(n \in \mb{N}\)</span>. Hence, <span class="math inline">\(P(A) = \sum_{n=1}^\infty a_n P_n(A) = 0\)</span>, which means that <span class="math inline">\(P &lt;&lt; \nu\)</span>.</p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-27" class="exercise"><strong>Exercise 4.10  (Ex 50)  </strong></span>
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-28" class="exercise"><strong>Exercise 4.11  (Ex 55)  </strong></span>Let <span class="math inline">\(X\)</span> be a random variable. Show that</p>
<ol style="list-style-type: lower-alpha">
<li><p>If <span class="math inline">\(E X\)</span> exists, then <span class="math inline">\(E X = \int_0^\infty P(X &gt; x) dx - \int_{-\infty}^0 P(X \le x) dx\)</span>.</p></li>
<li>If <span class="math inline">\(X\)</span> has range <span class="math inline">\(0, 1, 2, ...\)</span>, then <span class="math inline">\(E X = \sum_{n=1}^\infty  P(X \ge x)\)</span>
</div></li>
</ol>

<div class="solution">
<p> <span class="solution"><em>Solution</em> (EX 55 (a)). </span> First rewrite the RHS in terms of PDFS</p>
<p><span class="math display">\[\int_0^\infty \int_x^\infty f(y) dy dx - \int_{-\infty}^0 \int_{-\infty}^x f(y) dy dx\]</span></p>
<p>Then we can use Fubini (since <span class="math inline">\(f\)</span> is positive) to switch the order of the integrals</p>
<span class="math display">\[
\begin{aligned}
&amp;= \int_0^\infty \int_0^y f(y) dy dx - \int_{-\infty}^0 \int_{-y}^0 f(y) dy dx \\
&amp;= \int_0^\infty f(y) \int_0^y 1 dx dy - \int_{-\infty}^0 f(y) \int_{-y}^0 1 dx dy \\
&amp;= \int_0^\infty f(y) y dy dx - \int_{-\infty}^0 -y \cdot f(y) dy \\
&amp;= E X
\end{aligned}
\]</span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-30" class="exercise"><strong>Exercise 4.12  (Ex 56)  </strong></span>Calculate the expectation and variance of the noncentral t distribution.
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 56 (a)). </span> We did these. The integrals were hard. There were two. We don’t have time to write up the nasty calculus, but do know that we suffered to prove this result. YAY MAAAAATH! We may staple the ugly to the back to the back of the nice solutions.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-32" class="exercise"><strong>Exercise 4.13  (Ex 65)  </strong></span>TODO
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-33" class="exercise"><strong>Exercise 4.14  (Ex 74)  </strong></span>Let <span class="math inline">\(\phi_n\)</span> be a the chf of a probability measure <span class="math inline">\(P_n, n = 1, 2, ...\)</span>. Let <span class="math inline">\(\{a_n\}\)</span> be a sequence of nonnegative numbers with <span class="math inline">\(\sum_{n=1}^\infty a_n = 1\)</span>. Show that <span class="math inline">\(\sum_{n=1}^\infty a_n \phi_n\)</span> is a ch.f. and find its corresponding probability measure.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 74). </span> Take <span class="math inline">\(P = \sum_n a_n P_n\)</span>. Note that <span class="math inline">\(P_n\)</span> is dominated by <span class="math inline">\(P\)</span>, so that there exists a density <span class="math inline">\(g_n = dP_n/dP\)</span> for each <span class="math inline">\(n\)</span> (exercise 35). Consider <span class="math inline">\(P(\Omega) = \int_\Omega \sum a_n g_n(x) dP = 1\)</span>, so that <span class="math inline">\(\sum a_n g_n(x) = 1\)</span> almost everywhere. Then</p>
<span class="math display">\[
\begin{aligned}
\sum_n a_n \phi_n &amp;= \sum_n a_n \int e^{itx} g_n(x) dP \\
&amp;= \int \sum_n a_n e^{itx} g_n(x) dP \qquad \text{Fubini} \\
&amp;= \int e^{itx} dP \\
&amp;= \phi(x)
\end{aligned}
\]</span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-35" class="exercise"><strong>Exercise 4.15  (Ex 83)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-36" class="exercise"><strong>Exercise 4.16  (Ex 85)  </strong></span>TODO
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-37" class="exercise"><strong>Exercise 4.17  (Ex 93)  </strong></span>TODO
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-38" class="exercise"><strong>Exercise 4.18  (Ex 99)  </strong></span>LEt <span class="math inline">\(X_1, X_2, ...\)</span> be i.i.d random variables and let <span class="math inline">\(Y\)</span> be a discrete random variable taking positive integer values. Assume that <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y\)</span> are independent.</p>
<ol style="list-style-type: lower-alpha">
<li>Obtain the ch.f. of Z</li>
<li>Show <span class="math inline">\(E Z = E Y E X_1\)</span></li>
<li>Show Var Z = E Y Var(X_1) + Var(Y) (E X_1)^2
</div></li>
</ol>

<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 99 (a)). </span> TODO
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 99 (b)). </span> <span class="math display">\[
\begin{aligned}
E Z &amp;= E(\sum_{i=1}^Y X_i) \\
&amp;= E( E(\sum_{i=1}^Y X_i) | Y ) \\
&amp;= E(Y E(X_1 | Y)) \\
&amp;= EY E(E(X_1 | Y)) \\
&amp;= EY E X_1
\end{aligned}
\]</span>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 99 (c)). </span> <span class="math display">\[
\begin{aligned}
Var Z &amp;= Var(E(Z | Y)) + E(Var(Z | Y)) \\
&amp;= Var(E(Y X_1 | Y)) + E(Var(Y X_1)) \\
&amp;= Var(Y E(X_1 | Y)) + E(Y^2 Var(X_1)) \\
&amp;= (E(X_1))^2 Var(Y) + E(Y^2) Var(X_1)
\end{aligned}
\]</span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-42" class="exercise"><strong>Exercise 4.19  (Ex 101)  </strong></span>TODO
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-43" class="exercise"><strong>Exercise 4.20  (Ex 106)  </strong></span>Let <span class="math inline">\(\{Y_n\}\)</span> be a sequence of independent random. Show that the following are martingales:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(X_1 = Y_1\)</span>, <span class="math inline">\(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n)\)</span> where <span class="math inline">\(h_n\)</span> are Borel.</li>
<li>Suppose <span class="math inline">\(E Y_n = 0\)</span> and <span class="math inline">\(Var Y_n = \sigma^2\)</span> for all <span class="math inline">\(n\)</span>. <span class="math inline">\(X_n = (sum_{j=1}^n Y_j)^2 - n \sigma^2\)</span></li>
<li>Suppose <span class="math inline">\(Y_n &gt; 0\)</span> and <span class="math inline">\(E Y_n = 1\)</span> for all <span class="math inline">\(n\)</span>. <span class="math inline">\(X_n = Y_1 \cdot ... \cdot Y_n\)</span>.
</div></li>
</ol>

<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 106 (a)). </span> Recall that a sequence <span class="math inline">\(X_n\)</span> is a martingale if <span class="math inline">\(E(X_{n+1} | X_1, ..., X_n) = X_n\)</span>.</p>
<span class="math display">\[
\begin{aligned}
E(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n) | X_1, ..., X_n) &amp;= 
  X_n +  h_n(X_1, ..., X_n) E(Y_{n+1} | X_1, ..., X_n) \\
&amp;= X_n +  h_n(X_1, ..., X_n) 0 \\
&amp;= X_n
\end{aligned}
\]</span>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 106 (b)). </span> <span class="math display">\[
\begin{aligned}
E(\sum_{j=1}^{n+1} Y_j)^2 - (n + 1) \sigma^2 | X_1, ..., X_n) &amp;= 
  E(\sum_{j=1}^{n} Y_j + Y_{n+1})^2  | X_1, ..., X_n) - (n + 1) \sigma^2 \\
&amp;= E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1} \cdot \sum_{j=1}^{n} Y_j | X_1, ..., X_n) + E(Y_{n+1}^2  | X_1, ..., X_n) - (n + 1) \sigma^2 \\
&amp;= E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1}) E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n) + \sigma^2 - (n + 1) \sigma^2 \\
&amp;= (\sum_{j=1}^{n} Y_j)^2 + n \sigma^2
\end{aligned}
\]</span>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 106 (c)). </span> <span class="math display">\[
\begin{aligned}
E( Y_1 \cdot ... \cdot Y_n \cdot Y_{n+1} | X_1, ..., X_n) &amp;= Y_1 \cdot ... \cdot Y_n E(Y_{n+1} | X_1, ..., X_n) \\
&amp;= Y_1 \cdot ... \cdot Y_n \\
&amp;= X_n
\end{aligned}
\]</span>
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-47" class="exercise"><strong>Exercise 4.21  (Ex 115)  </strong></span>Let <span class="math inline">\(X_1, X_2, ...\)</span> be a sequence of identically distributed random variables with finite <span class="math inline">\(E |X_1|\)</span> and let <span class="math inline">\(Y_n = n^{-1} \max_{i \le n} |X_i|\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Show that <span class="math inline">\(Y_n \to 0\)</span> in <span class="math inline">\(L_1\)</span></li>
<li>Show that <span class="math inline">\(Y_n \to 0\)</span> almost surely
</div></li>
</ol>

<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 115 (a)). </span> <span class="math inline">\(E Y_n = \int_0^\infty {1 \over n} P(\max_{i \le n} |X_i| &gt; t) dt\)</span> by exercise 1.55. The integrand is then bounded by</p>
<p><span class="math display">\[{1 \over n} \sum P(\max_{i \le n} |X_i| &gt; t)\]</span></p>
<p>which equals <span class="math inline">\({1 \over n} P(|X_1| &gt; t)\)</span> since the <span class="math inline">\(X_i\)</span> are identical. This is finite by hypothesis. Thus we can apply the DCT to see that</p>
<span class="math display">\[\lim E Y_n = \int_0^\infty \lim {1 \over n}  P(\max_{i \le n} |X_i| &gt; t) dt = 0\]</span>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Ex 115 (b)). </span> The condition that <span class="math inline">\(E |X_1|\)</span> converges and being identical gives us that that $ X_n / n$ converges to zero almost surely. then we truncate. for some large enough N, <span class="math inline">\(X_n / n\)</span> must be less than epsilon. then for <span class="math inline">\(|X_n| / n\)</span> for n &lt; N, there are only finitely many cases and so the max exists and is bounded, and goes to zero by the <span class="math inline">\(n\)</span> in the denominator. this gives us that <span class="math inline">\(\lim Y_n\)</span> goes to zero as <span class="math inline">\(n\)</span> goes to zero. in fact it goes to zero almost everywhere, since the limit <span class="math inline">\(|X_n| / n\)</span> goes to zero almost everywhere by the hypothesis that <span class="math inline">\(X_n\)</span> is absolutely integrable. thus <span class="math inline">\(\lim Y_n\)</span> goes to zero almost surely.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-50" class="exercise"><strong>Exercise 4.22  (Ex 117)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-51" class="exercise"><strong>Exercise 4.23  (Ex 126)  </strong></span>Prove (vii) of Theorem 1.8
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Let <span class="math inline">\(X_n \to d X\)</span>, <span class="math inline">\(P(X = c) = 1\)</span>.</p>
<p>Apply triangle inequality and assumption:</p>
<p><span class="math display">\[
  \lim_{n \to \infty} P(\norm{X_n - c} &gt; \epsilon) \le \lim_{n \to \infty} P(\norm{X_n - X} &gt; \epsilon) + \lim_{n \to \infty} P(\norm{X - c} &gt; \epsilon) = 0.
\]</span></p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-53" class="exercise"><strong>Exercise 4.24  (Ex 127)  </strong></span>(a) Suppose X_n converge in distribution to X. Show X_n is O_P(1).
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 127 (a)). </span> Suppose X_n converge in distribution to X. For large enough M, we have <span class="math inline">\(P(|X| &gt; M) &lt; \epsilon_1\)</span> (i.e the tail probability is small). For large enough <span class="math inline">\(n\)</span>, $P(|X_n| &gt; _1) - P(|X| &gt; ) &lt; ) &lt; <span class="math inline">\(\epsilon_2\)</span>. Pick <span class="math inline">\(n\)</span> large enough so that <span class="math inline">\(\epsilon_2\)</span> is controlled.</p>
<a href="http://users.ices.utexas.edu/~alen/articles/asymp-final.pdf" class="uri">http://users.ices.utexas.edu/~alen/articles/asymp-final.pdf</a> - page 7
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-55" class="exercise"><strong>Exercise 4.25  (Ex 128)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-56" class="exercise"><strong>Exercise 4.26  (Ex 137)  </strong></span>Let <span class="math inline">\(\{X_n\}\)</span> and <span class="math inline">\(\{Y_n\}\)</span> be two sequences of R.Vs. Assume <span class="math inline">\(X_n \to_d X\)</span> and <span class="math inline">\(P_{Y_n | X_n = x_n} \to_w P_Y\)</span> almost surely for every sequence of numbers <span class="math inline">\(\{x_n\}\)</span>, where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables. Show that <span class="math inline">\(X_n + Y_n \to_d X + Y\)</span>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> 
<span class="math display">\[
  P_{Y_n,X_n} = P_{Y_n|X_n}\cdot P_{X_n} \to P_Y P_X = P_{Y,X},
\]</span></p>
<p>where the last equality holds due to independence of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-58" class="exercise"><strong>Exercise 4.27  (Ex 138)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-59" class="exercise"><strong>Exercise 4.28  (Ex 140)  </strong></span><span class="math inline">\(X_n \sim N(\mu_n, \sigma^2_n, n \in \N\)</span> and <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>. Show that <span class="math inline">\(X_n \to_d X \iff \mu_n \to \mu\)</span> and <span class="math inline">\(\sigma_n \to \sigma\)</span>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Assume <span class="math inline">\(\mu_n \to \mu\)</span> and <span class="math inline">\(\sigma_n \to \sigma\)</span>. Then <span class="math inline">\(f_n(x) = \frac{1}{\sqrt{2\pi}\sigma_n}e^{\tfrac{-(x-\mu_n)^2}{\sigma_n}} \to f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\tfrac{-(x-\mu)^2}{\sigma}}\)</span> for all <span class="math inline">\(x\)</span>. Hence, <span class="math inline">\(X_n \to_d X\)</span>.</p>
Assume <span class="math inline">\(X_n \to_d X\)</span>, and assume for contradiciton that <span class="math inline">\((\mu_n, \sigma^2_n) \to (a,b^2) \neq (\mu, \sigma^2)\)</span>. This implies that <span class="math inline">\(f_n = \frac{1}{\sqrt{2\pi}\sigma_n}e^{\tfrac{-(x-\mu_n)^2}{\sigma_n}} \to f = \frac{1}{\sqrt{2\pi}b}e^{\tfrac{-(x-a)^2}{b}}\)</span>, hence <span class="math inline">\(X_n \to_d Y\)</span> where <span class="math inline">\(Y \sim N(a,b^2)\)</span>. Since <span class="math inline">\((a,b) \neq (\mu, \sigma^2)\)</span>, and we know the limiting distribution is unique, this contradicts our assumption.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-61" class="exercise"><strong>Exercise 4.29  (Ex 142)  </strong></span><span class="math inline">\(f_n\)</span> is the Lebesgue p.d.f. of the t-distribution <span class="math inline">\(t_n\)</span>. Show that <span class="math inline">\(f_n(x) \to f(x)\)</span> for all <span class="math inline">\(x \in \R\)</span>, where <span class="math inline">\(f\)</span> is the Lebesgue p.d.f. for standard normal.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> By definition, <span class="math inline">\(f_n(x) = \frac{\Gamma(\tfrac{n+1}{2})}{\sqrt{n\pi} \Gamma(\tfrac{n}{2})}\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}}\)</span>.</p>
<p>Note that <span class="math inline">\(\lim_{n \to \infty}\left(1+\frac{x}{n}\right)^n = e^x\)</span>. So, since <span class="math inline">\(\sqrt{1+\tfrac{x^2}{n}} \to 0\)</span>,</p>
<p><span class="math display">\[\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}} = \frac{1}{\left(1+\tfrac{x^2/2}{n/2}\right)^{-n/2}\sqrt{1+\tfrac{x^2}{n}}} \to e^{-x^2/2}.\]</span></p>
<p>Since <span class="math inline">\(\lim_{n \to \infty} \frac{\Gamma(n + c)}{\Gamma(n)n^c} = 1\)</span>,</p>
<p><span class="math display">\[\lim_{n \to \infty} \frac{\Gamma(\tfrac{n}{2} + \tfrac{1}{2})}{\Gamma(\tfrac{n}{2})\sqrt{n/2}} = 1.\]</span></p>
<p>So</p>
<p><span class="math display">\[\begin{aligned}
  \lim_{n \to \infty} f_n(x) &amp;= \lim_{n\to \infty} \frac{\Gamma(\tfrac{n+1}{2})}{\sqrt{n\pi} \Gamma(\tfrac{n}{2})}\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}} \\
                                     &amp;= \frac{1}{\sqrt{2\pi}}e^{-x^2/2}\lim_{n\to \infty}\frac{\Gamma(\tfrac{n}{2} + \tfrac{1}{2})}{\Gamma(\tfrac{n}{2})\sqrt{n/2}} \\
                                     &amp;= \frac{1}{\sqrt{2\pi}}e^{-x^2/2}.
\end{aligned}\]</span></p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-63" class="exercise"><strong>Exercise 4.30  (Ex 146)  </strong></span>Let <span class="math inline">\(U_1, U_2, \ldots\)</span> be i.i.d. random variables, <span class="math inline">\(U_i \sim U[0,1]\)</span>. Let <span class="math inline">\(Y_n = (\prod_{i=1}^n U_i)^{-1/n}\)</span>. Show that <span class="math inline">\(\sqrt{n}(Y_n - e) \to_d N(0,e^2)\)</span>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Let <span class="math inline">\(X_i = -log(U_i)\)</span>. Then <span class="math inline">\(EX_1 = \text{Var}(X_1) = 1\)</span>, and implies <span class="math inline">\(U_i = e^{-X_i}\)</span>. So</p>
<p><span class="math display">\[\begin{aligned}
  Y_n &amp;= \left(\prod_{i=1}^n e^{-X_u} \right)^{-1/n} \\
      &amp;= e^{\tfrac{1}{n}\sum_{i=1}^n X_i}.
\end{aligned}\]</span></p>
<p>By the CLT (corollary 1.2; page 69), <span class="math inline">\(\tfrac{1}{\sqrt{n}}\sum_{i=1}^n (X_i - EX_1) = \tfrac{n}{\sqrt{n}}\left(\tfrac{1}{n}\sum_{i=1}^n X_i - 1\right) \to_d N(0, 1)\)</span>.</p>
<p>Let <span class="math inline">\(g = e^{x}\)</span>. Then <span class="math inline">\(g^\prime(x) = g(x)\)</span>, and <span class="math inline">\(U_i = g(X_i)\)</span>. Using the delta method (specifically corollary 1.1; page 61), we get that</p>
<p><span class="math display">\[
  \sqrt{n}\left(Y_n - e\right) = \tfrac{n}{\sqrt{n}}\left(g\left(\tfrac{1}{n}\sum_{i=1}^n X_i\right) - g(1)\right) \to_d N(0,g(1)^2) = N(0, e^2).
\]</span></p>
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-65" class="exercise"><strong>Exercise 4.31  (Ex 149)  </strong></span>Let <span class="math inline">\(X_1, \ldots X_n\)</span> be i.i.d. random variables such that for <span class="math inline">\(x = 3,4,\ldots\)</span>, <span class="math inline">\(P(X_1 = \pm x) = (2cx^2 \log(x))^{-1}\)</span>, where <span class="math inline">\(c = \sum_{x=3}^\infty \tfrac{x^{-2}}{\log(x)}\)</span>.</p>
Show that <span class="math inline">\(E|X_1| = \infty\)</span>, but <span class="math inline">\(\tfrac{1}{n} \sum_{i=1}^n X_i \to_p 0\)</span>, using Theorem 1.13(i).
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Notice that</p>
<p><span class="math display">\[
  E|X_1| = \sum_{x=3}^\infty 2\frac{x}{2cx^2\log(x)} = \frac{1}{c}\sum_{x=3}^\infty \frac{1}{x\log(x)} \ge \tfrac{1}{c} \int_3^\infty \frac{1}{x\log(x)}dx = \infty,
\]</span></p>
<p>and that <span class="math inline">\(EX_1 = 0\)</span>. (To see that the inequality above holds, draw it!)</p>
<p>Consider <span class="math inline">\(nP(|X_1| &gt; n)\)</span>:</p>
<p><span class="math display">\[
  \begin{aligned}
    nP(|X_1| &gt; n) &amp;= n\sum(x=n)^\infty \frac{1}{2cx^2\log(x)} \\
                  &amp;\le \frac{n}{c} \int_n^\infty \frac{1}{x^2\log(x)} dx \\
                  &amp;\le \frac{n}{c\log(n)} \int_n^\infty \frac{1}{x^2} dx \\
                  &amp;= \frac{n}{c\log(n)} \frac{1}{n} \to 0 \text{ as } n \to \infty.
  \end{aligned}
\]</span></p>
So by theorem 1.13(i), we <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n X_i - a_n \to_p 0\)</span>, where <span class="math inline">\(a_n = E(X_1 I_{\left\{|X_1| \le n\right\}}) \to 0\)</span> (can be seen using an argument as above).
</div>


<div class="exercise">
<p><span id="exr:unnamed-chunk-67" class="exercise"><strong>Exercise 4.32  (Ex 152)  </strong></span>Let <span class="math inline">\(T_n = \sum_{i=1}^n X_i\)</span>, where <span class="math inline">\(X_1,X_2,\ldots\)</span> are independent and <span class="math inline">\(P(X_n = \pm n^\theta) = 0.5\)</span> for some <span class="math inline">\(\theta &gt; 0\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Show that when <span class="math inline">\(\theta &lt; 0.5\)</span>, then <span class="math inline">\(T_n/n \to_{a.s.} 0\)</span></li>
<li>Show that when <span class="math inline">\(\theta \ge 1\)</span>, then <span class="math inline">\(T_n/n \to_{p} 0\)</span> does NOT hold</li>
</ol>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> (a)</p>
<p>Since <span class="math inline">\(\theta &lt; 0.5\)</span>, <span class="math inline">\(2(\theta - 1) &lt; -1\)</span>. So</p>
<p><span class="math display">\[
  \begin{aligned}
    \sum_{n=1}^\infty \frac{E|X_n|^2}{n^2} &amp;= \sum_{n=1}^\infty \frac{(n^\theta)^2}{n^2} \\
                                           &amp;= \sum_{n=1}^\infty n^{2(\theta - 1)} &lt; \infty.
  \end{aligned}
\]</span></p>
<p>By SLLN, <span class="math inline">\(T_n/n = \frac{1}{n} \sum_{i=1}^\infty X_i \to_{a.s.} EX_1 = 0\)</span>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li></li>
</ol>
<p>Note that the p.d.f. of <span class="math inline">\(X_n\)</span> is <span class="math inline">\(F_n(x) = 0 1_{X_n &lt; -n^\theta} + \tfrac{1}{2}1_{-n^\theta \le X_n &lt; n^\theta} + 1_{X_n \ge n^\theta}\)</span>. By definition, <span class="math inline">\(X_n \to_d 0\)</span> if and only if <span class="math inline">\(F_n(x) \to F(x) = 1_{(X \ge 0)}\)</span> for all <span class="math inline">\(x\)</span> continuity points of <span class="math inline">\(F\)</span>. For any <span class="math inline">\(n &gt; 1\)</span>, <span class="math inline">\(F_n(\tfrac{-n^\theta}{2}) = 0.5 \neq F(\tfrac{-n^\theta}{2}) = 0\)</span>. So <span class="math inline">\(X_n\)</span> does not converge to <span class="math inline">\(0\)</span> in distribution. By theorem 1.8(iii), this means that <span class="math inline">\(X_n\)</span> does not converge to <span class="math inline">\(0\)</span> in probability (since convergence in probability implies convergence in distribution).</p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-69" class="exercise"><strong>Exercise 4.33  (Ex 153)  </strong></span>Let <span class="math inline">\(X_2, X_3, \ldots\)</span> be independent random variables with <span class="math inline">\(P(X_n = \pm \sqrt{n/\log(n)}) = 0.5\)</span>. Show that <span class="math inline">\(\sum_{k=1}^\infty \frac{E|X_k|^p}{k^p} = \infty\)</span> for all <span class="math inline">\(p \in [1,2]\)</span>, but <span class="math inline">\(\lim_{n \to \infty}\frac{1}{n^2} \sum_{i = 1}^\infty E|X_i|^2 = 0\)</span>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> For any <span class="math inline">\(p\in [1,2]\)</span>:</p>
<p><span class="math display">\[
  \sum_{n=2}^\infty \frac{E|X_n|^p}{n^p} = \sum_{n=2}^\infty \frac{(n/\log(n))^{p/2}}{n^p} = \sum_{n=2}^/infty \frac{1}{(n\log(n))^{p/2}} = \infty.
\]</span></p>
<p>Use that <span class="math inline">\(\log(x)\)</span> is an increasing function:</p>
<p><span class="math display">\[\begin{aligned}
  \lim_{n \to \infty} \frac{1}{n^2} \sum_{k=2}^n E|X_k|^2 &amp;= \lim_{n \to \infty} \frac{1}{n^2} \sum_{k=2}^\infty \frac{k}{\log(k)} \\
                                                          &amp;\leq \lim_{n \to \infty} \frac{(n-1)\tfrac{n}{\log(n)}}{n^2} \\
                                                          &amp;\leq \lim_{n \to \infty} \frac{n \tfrac{n}{\log(n)}}{n^2} \\
                                                          &amp;\leq \lim_{n \to \infty} \frac{1}{\log(n)} = 0.
\end{aligned}\]</span></p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-71" class="exercise"><strong>Exercise 4.34  (Ex 163)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-72" class="exercise"><strong>Exercise 4.35  (Ex 164)  </strong></span>Let <span class="math inline">\(X_1, X_2, \ldots\)</span> be independent variables with <span class="math inline">\(P(X_j = \pm j^a) = P(X_j = 0) = \tfrac{1}{3}\)</span>, where <span class="math inline">\(a &gt; 0\)</span>, <span class="math inline">\(j=1,2,\ldots\)</span>. Does Liapounov’s condition hold?
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> <span class="math inline">\(\sigma_n^ = \sqrt{\sum_{j=1}^n \frac{2j^{2a}}{3}}\)</span>. So, want to see if</p>
<p><span class="math display">\[
  \frac{\sum_{j=1}^n E|X_j - EX_j|^{2+\delta}}{\sigma_n^{2+\delta}} \to 0.
\]</span></p>
<p>So,</p>
<p><span class="math display">\[\begin{aligned}
  \frac{\sum_{j=1}^n \left(\tfrac{2}{3}j^{2a}\right)^{2+\delta}}{\left(\tfrac{2}{3}\sum_{j=1}^n j^{2a}\right)^{(2+\delta)/2}} &amp;= \frac{(\tfrac{2}{3})^{2+\delta}}{(\tfrac{2}{3})^{(2+\delta)/2}} \frac{\sum_{j=1}^\infty j^{(2+\delta)a}}{\left(\sum_{j=1}^\infty j^{2a}\right)^{(2+\delta)/2}}.
\end{aligned}\]</span></p>
<p>Choose <span class="math inline">\(\delta = 2\)</span>. Using Jensens inequality with <span class="math inline">\(\phi(x) = x^2\)</span> and the ratio test, we see that</p>
<p><span class="math display">\[
\frac{(\tfrac{2}{3})^4}{(\tfrac{2}{3})^2} \frac{\sum_{j=1}^\infty ((j^a)^2)^2}{\left(\sum_{j=1}^\infty j^{2a}\right)^{2}} \to 0.
\]</span></p>
</div>

</div>
<div id="suggested-problems" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Suggested Problems</h3>

<div class="exercise">
<span id="exr:unnamed-chunk-74" class="exercise"><strong>Exercise 4.36  (Ex 3)  </strong></span>Let <span class="math inline">\(\Omega, \F_j)\)</span>, <span class="math inline">\(j=1,2,\ldots\)</span>, be measurable spaces such that <span class="math inline">\(\F_j \subset \F_{j+1}\)</span>. Is <span class="math inline">\(\cup_j \F_j\)</span> a <span class="math inline">\(\sigma\)</span>-field?
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 3). </span> No.</p>
<p>Let <span class="math inline">\(\Omega = [0,1]\)</span>, and <span class="math inline">\(\F_n = \sigma \left\{[0,\tfrac{1}{2^n}),[\tfrac{1}{2^n},\tfrac{2}{2^n}), \ldots, [\tfrac{2^{n-1}}{2^n}, 1)\right\}\)</span>.</p>
<p>Now, consider the set <span class="math inline">\(B_n = [0, \tfrac{1}{2^n})\)</span>. Clearly <span class="math inline">\(B_n \in \F_n\)</span> for all <span class="math inline">\(n\)</span>, hence <span class="math inline">\(B_n \in \cup_{i=1}^\infty \F_i\)</span>. Hower, <span class="math inline">\(\cap_{i = 1}^{\infty} B_i = \{0\} \notin \cup_{i=1}^\infty \F_i\)</span>. So <span class="math inline">\(\cup_{i=1}^\infty \F_i\)</span> is not closed under countable intersection, i.e. it is not a <span class="math inline">\(\sigma\)</span>-algebra.</p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-76" class="exercise"><strong>Exercise 4.37  (Ex 6)  </strong></span>Prove part (ii) and (iii) of proposition <a href="#prp:properties-of-measures"><strong>??</strong></a>.
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Ex 6). </span> 
i) Let <span class="math inline">\(A \subset B\)</span>. Then <span class="math inline">\(B \setminus A \cap A = \emptyset\)</span>, hence <span class="math inline">\(\nu(B) = \nu((B\setminus A) \cup A) = \nu(B\setminus A) + \nu(A) \geq \nu(A)\)</span>.</p>
<ol start="2" style="list-style-type: lower-roman">
<li>Let <span class="math inline">\(A_1, A_2, \ldots\)</span> be a sequence of sets. Define <span class="math inline">\(B_i = A_i \setminus \left(\cup_{k = 1}^{i-1} A_k \right)\)</span>. Then the <span class="math inline">\(B_i\)</span>s are pairwise disjoint. Hence,</li>
</ol>
<p><span class="math display">\[\begin{align*}
  \nu\left(\cup_{i = 1}^\infty A_i\right) &amp;= \nu\left(\cup_{i=1}^\infty B_i\right) \\
                                          &amp;= \sum_{i=1}^\infty \nu(B_i) \\
                                          &amp;= \sum_{i=1}^\infty \nu\left(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right ) \right ).
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right) \subset A_i\)</span>, we use (i) to get the result:</p>
<p><span class="math display">\[\begin{align*}
  \sum_{i=1}^\infty \nu\left(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right ) \right ) \leq \sum_{i=1}^\infty \nu\left(A_i \right )
\end{align*}\]</span></p>
<ol start="3" style="list-style-type: lower-roman">
<li>Let <span class="math inline">\(A_1 \subset A_2 \subset A_3 \subset \dots\)</span>. Define <span class="math inline">\(B_i = A_i \setminus A_{i-1}\)</span>. Then <span class="math inline">\(B_1, B_2, \ldots\)</span> is a sequence of pairwise disjoint sets, and <span class="math inline">\(\cup_{i = 1}^\infty B_i = \cup_{i=1}^\infty A_i\)</span>. Hence,</li>
</ol>
<p><span class="math display">\[\begin{align*}
  \nu\left(\cup_{i=1}^k A_i\right) &amp;= \nu\left(\cup_{i=1}^k B_i\right) \\
                                   &amp;= \sum_{i=1}^k \nu(B_i) \\
                                   &amp;= \sum_{i=1}^k \nu(A_i\setminus A_{i-1}) \\
                                   &amp;= \sum_{i=1}^k \nu(A_i) - \nu(A_{i-1}) \\
                                   &amp;= \nu(A_k). 
\end{align*}\]</span></p>
<p>Taking the limit on both sides gives us</p>
<p><span class="math display">\[
  \nu\left(\cup_{i=1}^k A_i \right) = \lim_{n \to \infty} \nu(A_n).
\]</span></p>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-78" class="exercise"><strong>Exercise 4.38  (Ex 15)  </strong></span>Show that a monotone function from <span class="math inline">\(\R\)</span> to <span class="math inline">\(\R\)</span> is Borel, and a c.d.f. on <span class="math inline">\(\R^k\)</span> is Borel.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-79" class="exercise"><strong>Exercise 4.39  (Ex 17)  </strong></span>Let <span class="math inline">\(f\)</span> be a non-negative Borel function on <span class="math inline">\((\Omega, \F)\)</span>. Show that <span class="math inline">\(f\)</span> is the limit of a sequence of simple functions <span class="math inline">\(\{\phi_n \}\)</span> on <span class="math inline">\((\Omega, \F)\)</span> with <span class="math inline">\(0 \le \phi_1 \le \phi_2 \le \dots \le f\)</span>.
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-80" class="exercise"><strong>Exercise 4.40  (Ex 23)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-81" class="exercise"><strong>Exercise 4.41  (Ex 25)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-82" class="exercise"><strong>Exercise 4.42  (Ex 31)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-83" class="exercise"><strong>Exercise 4.43  (Ex 36)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-84" class="exercise"><strong>Exercise 4.44  (Ex 46)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-85" class="exercise"><strong>Exercise 4.45  (Ex 53)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-86" class="exercise"><strong>Exercise 4.46  (Ex 57)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-87" class="exercise"><strong>Exercise 4.47  (Ex 61)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-88" class="exercise"><strong>Exercise 4.48  (Ex 66)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-89" class="exercise"><strong>Exercise 4.49  (Ex 70)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-90" class="exercise"><strong>Exercise 4.50  (Ex 73)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-91" class="exercise"><strong>Exercise 4.51  (Ex 78)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-92" class="exercise"><strong>Exercise 4.52  (Ex 79)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-93" class="exercise"><strong>Exercise 4.53  (Ex 81)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-94" class="exercise"><strong>Exercise 4.54  (Ex 82)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-95" class="exercise"><strong>Exercise 4.55  (Ex 86)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-96" class="exercise"><strong>Exercise 4.56  (Ex 88)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-97" class="exercise"><strong>Exercise 4.57  (Ex 91)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-98" class="exercise"><strong>Exercise 4.58  (Ex 97)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-99" class="exercise"><strong>Exercise 4.59  (Ex 98)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-100" class="exercise"><strong>Exercise 4.60  (Ex 102)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-101" class="exercise"><strong>Exercise 4.61  (Ex 104)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-102" class="exercise"><strong>Exercise 4.62  (Ex 114)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-103" class="exercise"><strong>Exercise 4.63  (Ex 116)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-104" class="exercise"><strong>Exercise 4.64  (Ex 116)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-105" class="exercise"><strong>Exercise 4.65  (Ex 118)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-106" class="exercise"><strong>Exercise 4.66  (Ex 119)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-107" class="exercise"><strong>Exercise 4.67  (Ex 121)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-108" class="exercise"><strong>Exercise 4.68  (Ex 122)  </strong></span>TODO - Alex
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-109" class="exercise"><strong>Exercise 4.69  (Ex 125)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-110" class="exercise"><strong>Exercise 4.70  (Ex 136)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-111" class="exercise"><strong>Exercise 4.71  (Ex 141)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-112" class="exercise"><strong>Exercise 4.72  (Ex 144)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-113" class="exercise"><strong>Exercise 4.73  (Ex 145)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-114" class="exercise"><strong>Exercise 4.74  (Ex 150)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-115" class="exercise"><strong>Exercise 4.75  (Ex 154)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-116" class="exercise"><strong>Exercise 4.76  (Ex 156)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-117" class="exercise"><strong>Exercise 4.77  (Ex 161)  </strong></span>
</div>


<div class="exercise">
<span id="exr:unnamed-chunk-118" class="exercise"><strong>Exercise 4.78  (Ex 166)  </strong></span>
</div>


</div>
</div>
</div>






<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note: This could be done in one step, but I found it easier to split up into two.<a href="homework.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discussion-notes.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["709_notes.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
