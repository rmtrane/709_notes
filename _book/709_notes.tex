\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={STAT 709: My notes},
            pdfauthor={Ralph Møller Trane},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{STAT 709: My notes}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Ralph Møller Trane}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{Fall 2018 (compiled 2018-10-08)}

\usepackage{booktabs}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\newcommand{\mc}[1]{\mathcal{#1}}
\renewcommand{\B}{\mathcal{B}}
\renewcommand{\C}{\mathcal{C}}
\newcommand{\F}{\mathcal{F}}

\newcommand{\mb}[1]{\mathbb{#1}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\norm}[1]{\left | \left | #1 \right | \right |}

\chapter{Intro}\label{intro}

\section{Textbook}\label{textbook}

As of Fall 2018, this class uses the book \emph{Mathematical Statistics}
by Jun Shao (2nd. edition). Unless otherwise noted, all definitions,
lemmas, proposition, theorems, etc. can be found there. Numbering might
not match.

\section{\texorpdfstring{Conventions re:
\(\infty\)}{Conventions re: \textbackslash{}infty}}\label{conventions-re-infty}

We will use the following conventions:

\begin{itemize}
\tightlist
\item
  \(\infty + x = \infty, x \in \R\)
\item
  \(x\cdot \infty = \infty\) if \(x > 0\)
\item
  \(x\cdot \infty = -\infty\) if \(x < 0\)
\item
  \(0\cdot \infty = 0\)
\item
  \(\infty + \infty = \infty\)
\item
  \(\infty^a = \infty, \forall a > 0\)
\item
  \(\infty - \infty\) and \(\frac{\infty}{\infty}\) are not defined
\end{itemize}

\chapter{Lecture Notes}\label{lectures}

\section{Chapter 1: Probability
Theory}\label{chapter-1-probability-theory}

\subsection{Lecture 1: Measure space, measurable function, and
integration}\label{lecture-1-measure-space-measurable-function-and-integration}

\subsubsection{\texorpdfstring{\(\sigma\)-fields}{\textbackslash{}sigma-fields}}\label{sigma-fields}

\BeginKnitrBlock{definition}[$\sigma$-field (or $\sigma$-algebra)]
\protect\hypertarget{def:sigmaField}{}{\label{def:sigmaField}
\iffalse (\(\sigma\)-field (or \(\sigma\)-algebra)) \fi{} }A \(\F\)
collection of subsets of \(\Omega\) is called a \(\sigma\)-field (or
\(\sigma\)-algebra) if the following three conditions hold:

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \(\emptyset \in \F\)
\item
  \(A \in \F \Rightarrow A^{c} \in \F\)
\item
  If \(A_i \in \F\) for all \(i = 1,2,\ldots\), then
  \(\bigcup_i A_i \in \F\).
\end{enumerate}
\EndKnitrBlock{definition}

\BeginKnitrBlock{example}[A Few $\sigma$-fields]
\protect\hypertarget{exm:unnamed-chunk-1}{}{\label{exm:unnamed-chunk-1}
\iffalse (A Few \(\sigma\)-fields) \fi{} }There are some trivial
examples. One is the example where \(\F = \{\emptyset,\Omega\}\). It is
easy to check that the three conditions are met for this collection of
subsets. Another trivial example would be
\(\F = \P(\Omega)\)\footnote{P is used to denote the collection of all subsets.}.

The simplest non-trivial example is
\(\F = \left\{\emptyset, A, A^C, \Omega\right\}\) where
\(A \subset \Omega\). Since this collection of subsets is so small, it
is easy to check the three conditions mentioned above.
\EndKnitrBlock{example}

\BeginKnitrBlock{definition}[Measurable Space]
\protect\hypertarget{def:measurableSpace}{}{\label{def:measurableSpace}
\iffalse (Measurable Space) \fi{} }If \(\F\) is a \(\sigma\)-field on
\(\Omega\), then we call \(\left(\Omega, \F\right)\) a
\textbf{\emph{measurable space}}.
\EndKnitrBlock{definition}

\subsubsection{\texorpdfstring{\(\sigma\)-field generated by a
collection of
subsets}{\textbackslash{}sigma-field generated by a collection of subsets}}\label{sigma-field-generated-by-a-collection-of-subsets}

Sometimes we are interested in a specific collection of subsets, \(\C\),
that is NOT a \(\sigma\)-field. But since all the machinery we will
develop works with \(\sigma\)-fields, we are interested in creating a
\(\sigma\)-field that contains \(\C\). So we introduce the notion of a
\emph{\(\sigma\)-field generated by a collection of subsets}.

\BeginKnitrBlock{definition}[Generated $\sigma$-field]
\protect\hypertarget{def:unnamed-chunk-2}{}{\label{def:unnamed-chunk-2}
\iffalse (Generated \(\sigma\)-field) \fi{} }The smallest
\(\sigma\)-field containing a collection of subsets, \(\C\), is called
the \(\sigma\)-field generated by \(\C\).
\EndKnitrBlock{definition}

\(\sigma\left(\C\right)\) is used to denote the \(\sigma\)-field
generated by \(\C\), and is by definition the smallest \(\sigma\)-field
that contains \(\C\): if \(\F\) is a \(\sigma\)-field with
\(\C \subset \F\), then \(\sigma\left(\C\right) \subseteq \F\).

\subsubsection{\texorpdfstring{Borel
\(\sigma\)-field}{Borel \textbackslash{}sigma-field}}\label{borel-sigma-field}

A particular important \(\sigma\)-field is the Borel \(\sigma\)-field.
In general, this is defined as the \(\sigma\)-field generated by the
collection of all open subsets of a specific topology. In particular, if
we consider \(\R^k\) is the \(k\)-dimensional Euclidean space,
\(\mc{O} = \left\{O \subseteq \R^k \left | O\ \text{open set} \right\}\right.\),
then \(\sigma\left(\mc{O}\right) = \B^k\) (the Borel \(\sigma\)-field on
\(\R^k\)).

It can be shown that the \(\sigma\)-field generated by the collection of
all closed sets is also the Borel \(\sigma\)-field.

Sometimes it is useful to be able to limit ourselves to a subspace of
\(\R^k\). In such cases, we can create the Borel \(\sigma\)-field on
that subspace in the following way: if \(C \in \B^k\), then
\(\B_C = \left\{ C\cap B \left | B \in \B^k \right\}\right.\) is the
Borel \(\sigma\)-field on \(C\).

\subsubsection{Measures}\label{measures}

\BeginKnitrBlock{definition}[Measure]
\protect\hypertarget{def:measure}{}{\label{def:measure} \iffalse (Measure)
\fi{} }Let \(\left( \Omega, \F \right)\) is a measurable space

\(\nu: \F \rightarrow \R \cup\{\infty\}\) is said to be a
\textbf{\emph{measure}} if

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \(0 \leq \nu(A) \leq \infty\) for all \(A \in \F\)
\item
  \(\nu(\emptyset) = 0\)
\item
  If \(A_i \in \F\) for \(i=1,2,...\), and
  \(A_i \cap A_j = \emptyset, \forall i \neq j\) (i.e. \(A_i\)'s are
  pairwise disjoint), then it must hold that
  \[\nu\left(\bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \nu(A_i)\]
\end{enumerate}
\EndKnitrBlock{definition}

\BeginKnitrBlock{example}[Counting Measure]
\protect\hypertarget{exm:unnamed-chunk-3}{}{\label{exm:unnamed-chunk-3}
\iffalse (Counting Measure) \fi{} }The \emph{counting measure} is simply
the measure that returns the number of elements in a set.
\EndKnitrBlock{example}

\BeginKnitrBlock{example}[Lebesgue Measure]
\protect\hypertarget{exm:unnamed-chunk-4}{}{\label{exm:unnamed-chunk-4}
\iffalse (Lebesgue Measure) \fi{} }The measure \(m: \R \rightarrow \R\)
satisfying that for all intervals \([a,b], a < b\),

\[m([a,b]) = b-a,\]

is called the \emph{lebesgue measure}. This measure is unique.
\EndKnitrBlock{example}

\BeginKnitrBlock{definition}[$\sigma$-finite measures]
\protect\hypertarget{def:sigma-finite}{}{\label{def:sigma-finite}
\iffalse (\(\sigma\)-finite measures) \fi{} }A measure \(\nu\) is called
\emph{\(\sigma\)-finite} if and only if there exists a sequence
\(\left\{A_1,A_2,\ldots\right\}\) such that \(\cup A_i = \Omega\) and
\(\nu(A_i) < \infty, \forall i\).
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Measure Space]
\protect\hypertarget{def:unnamed-chunk-5}{}{\label{def:unnamed-chunk-5}
\iffalse (Measure Space) \fi{} }If \(\nu\) is a measure on \(\F\), and
\((\Omega, \F)\) is a measurable space, then \((\Omega, \F, \nu)\) is a
\textbf{\emph{measure space}}.
\EndKnitrBlock{definition}

\BeginKnitrBlock{example}
\protect\hypertarget{exm:unnamed-chunk-6}{}{\label{exm:unnamed-chunk-6}
}Both the Lebesque measure is \(\sigma\)-finite.

The counting measure is \(\sigma\)-finite if and only if \(\Omega\) is
countable.
\EndKnitrBlock{example}

\BeginKnitrBlock{definition}[Probability Space]
\protect\hypertarget{def:unnamed-chunk-7}{}{\label{def:unnamed-chunk-7}
\iffalse (Probability Space) \fi{} }If \((\Omega, \F, \nu)\) is a
measurable space with \(\nu(\Omega) = 1\), then it is called a
\textbf{\emph{probability space}}.
\EndKnitrBlock{definition}

\BeginKnitrBlock{proposition}[Properties of measures]
\protect\hypertarget{prp:properties-of-measures}{}{\label{prp:properties-of-measures}
\iffalse (Properties of measures) \fi{} }Let \((\Omega, \F, \nu)\) be a
measure space. Then the following holds:

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \textbf{Monotonicity:} if \(A \subseteq B\), then
  \(\nu(A) \leq \nu(B)\)
\item
  \textbf{Subadditivity:} for any sequence, \(A_1,A_2,\ldots\),
\end{enumerate}

\[
\nu\left(\bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty \nu(A_i)
\]

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Continuity:} if \(A_1 \subset A_2 \subset \dots\) (or
  \(A_1 \supset A_2 \supset \dots\)), then
\end{enumerate}

\[
\nu\left(\lim_{n\rightarrow \infty}A_n\right) = \lim_{n\rightarrow\infty}\nu\left(A_n\right),
\] where

\[
\lim_{n\rightarrow\infty}A_n = \bigcup_{i=1}^\infty A_i \left(\text{or} = \bigcap_{i=1}^\infty A_i\right)
\]
\EndKnitrBlock{proposition}

\BeginKnitrBlock{definition}[Cumulative Distribution Function]
\protect\hypertarget{def:cdf}{}{\label{def:cdf} \iffalse (Cumulative
Distribution Function) \fi{} }The \emph{cumulative distribution
function} (c.d.f.) of a measure \(\nu\) is defined as
\[F(x) = \nu((-\infty,x]), x\in\R.\]
\EndKnitrBlock{definition}

There is a one-to-one correpsondence between probability measures on
\((\R, \B)\) and the set of c.d.f.'s.

\BeginKnitrBlock{proposition}[Properties of c.d.f.'s]
\protect\hypertarget{prp:cdfProperties}{}{\label{prp:cdfProperties}
\iffalse (Properties of c.d.f.'s) \fi{} } i) For a c.d.f, \(\F\), on
\(\R\), it holds that: a) \(F(-\infty) = 0\) b) \(F(\infty) = 1\) c)
\(x \leq y \Rightarrow F(x) \leq F(y)\) (\emph{non-decreasing}) d)
\(\lim_{y\rightarrow x^+} F(y) = F(x)\) (\emph{right continuous}) ii) If
a function \(F: \R \rightarrow \R\) satisfies the four conditions above,
it is a c.d.f. of a unique probability measure on \((\R, \B)\).
\EndKnitrBlock{proposition}

\BeginKnitrBlock{proposition}[The Product Measure Theorem]
\protect\hypertarget{prp:productMeasure}{}{\label{prp:productMeasure}
\iffalse (The Product Measure Theorem) \fi{} }If
\(\left(\Omega_i, \F_i, \nu_i\right), i = 1,\ldots,k\) are measure
spaces with \(\sigma\)-finite measures. Then there exists a unique
measure on the \(\sigma\)-field \(\sigma(\F_1 \times \dots \F_k)\):

\[
\nu_1 \times \dots \times \nu_k(A_1 \times \dots \times A_k) = \nu_1(A_1)\dots \nu_k(A_k)
\]

for all \(A_i \in \F_i, i = 1,\ldots,k\).

This measure is called the \emph{product measure}.
\EndKnitrBlock{proposition}

\BeginKnitrBlock{definition}[Joint and Marginal c.d.f.'s]
\protect\hypertarget{def:joint-marginal}{}{\label{def:joint-marginal}
\iffalse (Joint and Marginal c.d.f.'s) \fi{} }The \emph{join c.d.f.} of
a probability measure on \((\R^k, \B^k)\) is defined as

\[
F(x_1,\ldots, x_k) = P((-\infty, x_1]\times \dots \times (-\infty,x_k]), \quad x_i \in \R.
\]
\EndKnitrBlock{definition}

\section{Lecture 2: 9/11}\label{lecture-2-911}

\BeginKnitrBlock{definition}[Measurable Function]
\protect\hypertarget{def:measurable-function}{}{\label{def:measurable-function}
\iffalse (Measurable Function) \fi{} } Let \((\Omega, \F)\) and
\((\Lambda, \mathcal{G})\) be measurable spaces. Let
\(f: \Omega \rightarrow \Lambda\).

\(f\) is called a \emph{measurable function} if and only if

\[
  f^{-1}(\mathcal{G}) \subset \F (\text{i.e.} f^{-1}(G) \in \F \forall G \in \mathcal{G}).
\]
\EndKnitrBlock{definition}

Note that if \(\F\) is the collection of all subsets of \(\Omega\), then
all functions are measurable.

\BeginKnitrBlock{definition}[$\sigma$-field generated by a function]
\protect\hypertarget{def:unnamed-chunk-8}{}{\label{def:unnamed-chunk-8}
\iffalse (\(\sigma\)-field generated by a function) \fi{} } Let \(f\) be
as in @ref\{measurable-function\}. Then \(f^{-1}(\mathcal{G})\) is a
sub-\(\sigma\)-field of \(\F\). We call it the \(\sigma\)-field
generated by \(f\), and denote it by \(\sigma(f)\).
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Borel Functions]
\protect\hypertarget{def:borel-functions}{}{\label{def:borel-functions}
\iffalse (Borel Functions) \fi{} } A function from \((\Omega, \F)\) to
\((\R, \B)\) is called a *Borel function\$ if it is measurable.
\EndKnitrBlock{definition}

\BeginKnitrBlock{proposition}[Properties of Borel Functions]
\protect\hypertarget{prp:borel-function-properties}{}{\label{prp:borel-function-properties}
\iffalse (Properties of Borel Functions) \fi{} } Let \((\Omega, \F)\) be
a measurable space.

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\item
  A function is Borel if and only if \(f^{-1}(a,\infty) \in \F\) for all
  \(a \in \R\).
\item
  If \(f\) and \(g\) are Borel, then so are \(fg\) and \(af + bg\),
  where \(a,b \in \R\). Also, if \(g(\omega) \neq 0\) for all
  \(\omega \in \Omega\), then \(f/g\) is also Borel.
\item
  If \(f_1, f_2, \ldots\) are all Borel functions, then so are
  \(\sup_n f_n\), \(\inf_n f_n\), \(\lim \sup_n f_n\), and
  \(\lim \inf_n f_n\). Furthermore, the set \[ 
    A = \left\{ \omega \in \Omega | \lim_{n \rightarrow \infty} f_n(\omega) \text{ exists} \right \}
  \] is an event, and the function \[
    h(\omega) = \left\{ 
  \begin{array}{ll}
    \lim_{n\rightarrow \infty} f_n \omega & \quad \omega \in A \\
    f_1(\omega) & \quad \omega \notin A 
  \end{array}
    \right .
  \]
\end{enumerate}

is borel.

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{3}
\item
  Suppose that \(f\) is measurable from \((\Omega, \F)\) to
  \((\Lambda, \mathcal{G})\) and \(g\) is measurable from
  \((\Lambda, \mathcal{G})\) to \((\Delta, \mathcal{H})\). Then the
  composite function \(g \circ f\) is measurable from \((\Omega, \F)\)
  to \((\Delta, \mathcal{H})\).
\item
  Let \(\Omega\) be a Borel set in \(\R^p\). If \(f\) is a continuous
  function from \(\Omega\) to \(\R^q\), then \(f\) is measurable.
\end{enumerate}
\EndKnitrBlock{proposition}

\BeginKnitrBlock{proposition}
\protect\hypertarget{prp:unnamed-chunk-9}{}{\label{prp:unnamed-chunk-9} }For
any non-negative Borel function \(f\) there exists a sequence of
non-negative simple functions \(f_1, f_2, \ldots\) such that

\[f_n \rightarrow f \text{ for } n \rightarrow \infty\]
\EndKnitrBlock{proposition}

\BeginKnitrBlock{definition}[Distribution]
\protect\hypertarget{def:distribution}{}{\label{def:distribution}
\iffalse (Distribution) \fi{} }Let \((\Omega, \F, \nu)\) be a measure
space, and \(f\) a measurable function from this measure space into the
measurable space \((\Lambda, \mathcal{G})\).

The measure defined as

\[
  \nu \circ f^{-1}(B) = \nu(f\in B) = \nu(f^{-1}(B)), \quad B \in \mathcal{G} 
\]

is called the \emph{induced measure} by \(f\).

If \(\nu\) is a probability measure and \(f\) is a random variable
(i.e.~a Borel function), then \(\nu\circ f^{-1}\) is called the
\emph{distribution} (or \emph{law}) of \(f\), and is denoted \(\nu_f\).
\EndKnitrBlock{definition}

Notice that there are many notations for the same thing. If \(P\) is a
probability measure and \(X\) a random variable, then

\[P_X(B) = P(X \in B) = P(X^{-1}(B)) = P \circ X^{-1}.\]

\subsection{Integration}\label{integration}

\BeginKnitrBlock{definition}[Simple Function]
\protect\hypertarget{def:simple-function}{}{\label{def:simple-function}
\iffalse (Simple Function) \fi{} }A function \(\phi\) is called a
\emph{simple function} if it is of the form

\[
  \phi = \sum_{i=1}^\infty a_i 1_{A_i},
\]

where \(A_1, A_2, \ldots\) are sets. If \(a_i \geq 0\) for all
\(i \ge 1\), then \(\phi\) is a non-negative simple function.
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Integral of a Non-negative Simple Function]
\protect\hypertarget{def:int-simple}{}{\label{def:int-simple}
\iffalse (Integral of a Non-negative Simple Function) \fi{} }The
integral of a non-negative simple function \(\phi\) with respect to a
measure \(\nu\) is defined as

\[
  \int \phi d\nu = \sum_{i=1}^k a_i \nu(A_i).
\]
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Integral of Non-negative Borel Function]
\protect\hypertarget{def:int-nonneg}{}{\label{def:int-nonneg}
\iffalse (Integral of Non-negative Borel Function) \fi{} }Let \(f\) be a
non-negative Borel function. Let \(\mathcal{S}_f\) be the collection of
ALL non-negative simple function with
\(\phi(\omega) \le f(\omega), \forall \omega \in \Omega\).

The integral of \(f\) with respect to \(\nu\) is defined as

\[
  \int f d\nu = \sup\left\{\int \phi d\nu \left | \phi \in \mathcal{S}_f \right\} \right . .  
\]
\EndKnitrBlock{definition}

Note: one consequence of this is that for any non-negative Borel
function, there exists a sequence of simple functions
\(\phi_1, \phi_2, \ldots\) such that \(0 \leq \phi_i \leq f\) for all i
and

\[
  \lim_{n \rightarrow \infty} \int \phi_n d\nu = \int f d\nu
\]

\BeginKnitrBlock{definition}[Integral of General Borel Function]
\protect\hypertarget{def:int-borel}{}{\label{def:int-borel}
\iffalse (Integral of General Borel Function) \fi{} } Let \(f\) be a
Borel function, and let \(f_+(\omega) = \max\{f(\omega), 0\}\) (i.e.~the
positive part) and \(f_-(\omega) = \max\{-f(\omega), 0\}\) (i.e.~the
negative part). If at least one of \(\int f_+ d\nu\) and
\(\int f_- d\nu\) is finite, we say that \(\int f d\nu\) exists and

\[
  \int f d\nu = \int f_+ d\nu - \int f_- d\nu.
\]
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Integrable Functions]
\protect\hypertarget{def:int-function}{}{\label{def:int-function}
\iffalse (Integrable Functions) \fi{} } When \(\int f d\nu < \infty\),
i.e.~the integral of both the positive and negative part of \(f\) is
finite, we say that \(f\) is \emph{integrable}.
\EndKnitrBlock{definition}

Note: as a consequence of the definition of an integrable function we
have that a Borel function is integrable if and only if \(|f|\) is
integrable. (This is true since \(|f| = f_+ + f_-\).)

Notation: There are many different ways to write down an integral:

\[ 
  \int f d\nu = \int_\Omega f d\nu = \int f(\omega) d\nu = \int f(\omega) d\nu(\omega) = \int f(\omega) \nu(d\omega),
\]

and if \(F\) is the c.d.f. (\ref{def:cdf}) of a probability measure P on
\((\R^k, \B^k)\),

\[
  \int f(x) dP = \int f(x) dF(x) = \int fdF
\]

\BeginKnitrBlock{proposition}[Linearity of Integrals]
\protect\hypertarget{prp:int-linearity}{}{\label{prp:int-linearity}
\iffalse (Linearity of Integrals) \fi{} } Let \((\Omega, \F, \nu)\) be a
measure space, and \(f\) and \(g\) be Borel functions.

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  If \(\int fd\nu\) exists, then for any \(a \in \R\), \(\int (af)d\nu\)
  exists, and
\end{enumerate}

\[ \int (af)d\nu = a \int f d\nu \]

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  If \(\int f d\nu\) and \(\int g d\nu\) both are well defined, then
  \(\int (f+g) d\nu\) exists and
\end{enumerate}

\[ \int (f+g) d\nu = \int f d\nu + \int g d\nu \]
\EndKnitrBlock{proposition}

\BeginKnitrBlock{proof}
\iffalse{} {Proof. } \fi{} Show that it holds for indicator functions,
simple functions, non-negative functions, and then all functions.
\EndKnitrBlock{proof}

\BeginKnitrBlock{definition}[Almost Everywhere or Almost Surely]
\protect\hypertarget{def:unnamed-chunk-11}{}{\label{def:unnamed-chunk-11}
\iffalse (Almost Everywhere or Almost Surely) \fi{} } A statement is
said to be true \(\nu\)-a.e. (or \(\nu\)-a.s.) if it is true for all
\(\omega \notin N\) and \(\nu(N) = 0\).
\EndKnitrBlock{definition}

\BeginKnitrBlock{proposition}[a.e. for integrals]
\protect\hypertarget{prp:unnamed-chunk-12}{}{\label{prp:unnamed-chunk-12}
\iffalse (a.e. for integrals) \fi{} }Let \((\Omega, \F, \nu)\) be a
measure space, and \(f\) and \(g\) be Borel functions.

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  If \(f\leq g\) \(\nu\)-a.e., then \(\int f d\nu \le \int g d\nu\),
  given that both integrals exist
\item
  If \(f \ge 0\) \(\nu\)-a.e. and \(\int f d\nu = 0\), then \(f = 0\)
  \(\nu\)-a.e.
\end{enumerate}
\EndKnitrBlock{proposition}

\BeginKnitrBlock{proof}
\iffalse{} {Proof. } \fi{} ii) Let \(A = \{f>0\}\) and
\(A_n = \{f \ge n^{-1}\}\), \(n=1,2,\ldots\). Then \(A_n \subset A\) for
any \(n\) and \(\lim_{n \rightarrow \infty} A_n = \cup A_n = A\)
(\textbf{show that this holds}).

Then, by (iii) of \ref{prp:properties-of-measures},
\(\lim_{n \rightarrow \infty} \nu(A_n) = \nu(A)\). By part (i) and
proposition \ref{prp:int-linearity}, we get that, for any n,

\begin{align*}
  n^{-1} \nu(A_n) = \int n^{-1} I_{A_n} d\nu \le \int f I_{A_n} d\nu \le \int f d\nu = 0.
\end{align*}
\EndKnitrBlock{proof}

\subsection{Radon-Nikodym Derivatives}\label{radon-nikodym-derivatives}

\section{Lecture 3: 9/13}\label{lecture-3-913}

Proof of Ex 1.11: for any borel set A: if A = (-infty, x), it holds. If
not, then\ldots{}

\textbf{\(\pi\)- and \(\lambda\)-systems.}

\textbf{Definition: \(\pi\)-system}

If \(\C\) is a collection of subsets, and it holds that
\(A,B \in \C \Rightarrow A \cap B \in \C\).

For a pi system, \(\sigma(\C) = \B\)

\BeginKnitrBlock{proposition}[Calculus with Radon-Nikodym Derivatives]
\protect\hypertarget{prp:calc-radon-nikodym}{}{\label{prp:calc-radon-nikodym}
\iffalse (Calculus with Radon-Nikodym Derivatives) \fi{} }Let \(\nu\) be
a \(\sigma\)-finite measure on a measure space \((\Omega, \F)\). All
other measures discussed in the following are defined on
\((\Omega, \F)\).

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  If \(\lambda\) is a meaure, \(\lambda << \nu\), and \(f\ge 0\), then
  \[\int f d\lambda = \int f \frac{d\lambda}{d\nu}d\nu.\]
\item
  If \(\lambda_i\), \(i=1,2\), are measures and \(\lambda_i << \nu\),
  then \(\lambda_1 + \lambda_2 << \nu\) and
  \[\frac{d(\lambda_1 + \lambda_2)}{d\nu} = \frac{d\lambda_1}{d\nu} + \frac{d\lambda_2}{d\nu}\quad \nu\text{-a.e.}\]
\item
  If \(\tau\) is a measure, \(\lambda\) a \(\sigma\)-finite measure, and
  \(\tau << \lambda << \nu\), then
  \[\frac{d\tau}{d\nu} = \frac{d\tau}{d\lambda}\frac{d\lambda}{d\nu}\quad \nu\text{-a.e.}.\]
\item
  Let \((\Omega_i, \F_i, \nu_i)\) be a measure space and \(\nu_i\) be
  \(\sigma\)-finite, \(i=1,2\). Let \(\lambda_i\) be a \(\sigma\)-finite
  measure on \((\Omega_i, \F_i)\) and \(\lambda_1 << \nu_i\), \(i=1,2\).
  Then \(\lambda_1 \times \lambda_2 << \nu_1 \times \nu_2\) and
  \[\frac{d(\lambda_1 \times \lambda_2)}{d(\nu_1 \times \nu_2)}(\omega_1,\omega_2) = \frac{d\lambda_1}{d\nu_1}(\omega_1)\frac{d\lambda_2}{d\nu_2}(\omega_2)\quad \nu_1\times \nu_2\text{-a.e.}\].
\end{enumerate}
\EndKnitrBlock{proposition}

\chapter{Discussion Notes}\label{discussion-notes}

\section{Discussion 1: 5/14}\label{discussion-1-514}

\subsection{\texorpdfstring{\(\sigma\)-fields}{\textbackslash{}sigma-fields}}\label{sigma-fields-1}

\BeginKnitrBlock{exercise}[Countable intersection/union of $\sigma$-fields]
\protect\hypertarget{exr:ex11}{}{\label{exr:ex11} \iffalse (Countable
intersection/union of \(\sigma\)-fields) \fi{} }Let
\(\F_n, n=1,2,\ldots\) be a sequance of \(\sigma\)-fields on \(\Omega\).
Show the following:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\cap_{i=1}^\infty \F_n\) is a \(\sigma\)-field.
\item
  If \(\F_1 \subset \F_2 \subset \dots\), then
  \(\cup_{i=1}^\infty \F_n\) is not necessarily a \(\sigma\)-field.
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[\@ref(exr:ex11) a)]
\iffalse{} {Solution (\ref{exr:ex11} a)). } \fi{}We need to show
(i)-(iii) from definition \ref{def:sigmaField}.

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  Since \(\F_n\) are all \(\sigma\)-fields, \(\emptyset \in \F_n\) for
  all \(n=1,2,\ldots\). Hence,
  \(\emptyset \in \cap_{i=1}^{\infty} \F_n\).
\item
  As (i).
\item
  Let \(\{A_i\}_{i=1}^\infty\) be a sequence of subsets from
  \(\cap_{i=1}^{\infty} \F_n\). Then, for all \(i\), \(A_i \in \F_n\)
  for all \(n\). Since \(F_n\) is a \(\sigma\)-field,
  \(\cup_{i=1}^\infty A_i \in \F_n\) for all \(n\), and so
  \(\cup_{i=1}^\infty A_i \in \cap_{i=1}^\infty \F_n\).
\end{enumerate}

Hence, \(\cap_{i=1}^\infty \F_n\) is a \(\sigma\)-field.
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[\@ref(exr:ex11) b)]
\iffalse{} {Solution (\ref{exr:ex11} b)). } \fi{} Let
\(\Omega = [0,1]\), and
\(\F_n = \sigma \left\{[0,\tfrac{1}{2^n}),[\tfrac{1}{2^n},\tfrac{2}{2^n}), \ldots, [\tfrac{2^{n-1}}{2^n}, 1)\right\}\).

Now, consider the set \(B_n = [0, \tfrac{1}{2^n})\). Clearly
\(B_n \in \F_n\) for all \(n\), hence
\(B_n \in \cup_{i=1}^\infty \F_n\). Hower,
\(\cap_{i = 1}^{\infty} B_n = \{0\} \notin \cup_{i=1}^\infty \F_n\). So
\(\cup_{i=1}^\infty \F_n\) is not closed under countable intersection,
i.e.~it is not a \(\sigma\)-algebra.
\EndKnitrBlock{solution}

\subsection{\texorpdfstring{\(\pi-\lambda\)
systems}{\textbackslash{}pi-\textbackslash{}lambda systems}}\label{pi-lambda-systems}

\BeginKnitrBlock{definition}[$\pi$-system]
\protect\hypertarget{def:pi-system}{}{\label{def:pi-system}
\iffalse (\(\pi\)-system) \fi{} }Let \(\mathcal{D}\) be a collection of
subsets of \(\Omega\). \(\mathcal{D}\) is said to be a
\textbf{\emph{\(\pi\)-system}} if it is closed under intersection,
i.e.~if

\[
  A,B \in \mathcal{D} \Rightarrow A \cap B \in \mathcal{D}.
\]
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[$\lambda$-system]
\protect\hypertarget{def:lambda-system}{}{\label{def:lambda-system}
\iffalse (\(\lambda\)-system) \fi{} }Let \(\mathcal{L}\) be a collection
of subsets of \(\Omega\). \(\mathcal{L}\) is said to be a
\textbf{\emph{\(\lambda\)-system}} if it satisfies that

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \(\Omega \in \mathcal{L}\),
\item
  If \(A,B \in \Omega\) with \(A \subset B\), then
  \(B\setminus A \in \Omega\)
\item
  If \(A_n \in \mathcal{L}\) and \(A_n \subset A_{n+1}\) for all \(n\),
  then
\end{enumerate}

\[
  \cup_{i=1}^{\infty} A_n \in \mathcal{L}  
\]
\EndKnitrBlock{definition}

\BeginKnitrBlock{theorem}[$\pi-\lambda$ Theorem]
\protect\hypertarget{thm:pi-lambda}{}{\label{thm:pi-lambda}
\iffalse (\(\pi-\lambda\) Theorem) \fi{} }If \(\mathcal{D}\) is a
\(\pi\)-system and \(\mathcal{L}\) is a \(\lambda\)-system s.t.
\(\mathcal{D} \subset \mathcal{L}\), the
\(\sigma\{\mathcal(D)\} \subset \mathcal{L}\).
\EndKnitrBlock{theorem}

\BeginKnitrBlock{exercise}[Proof of the $\pi-\lambda$ Theorem]
\protect\hypertarget{exr:unnamed-chunk-16}{}{\label{exr:unnamed-chunk-16}
\iffalse (Proof of the \(\pi-\lambda\) Theorem) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Proof hints:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  If \(\mathcal{L}_t\) is \(\lambda\)-system for all \(t \in I\),
  \(\mathcal{D} \subset \mathcal{L}_t\), then
  \(\cap_{t \in I} \mathcal{L}_t\) is a \(\lambda\)-system. Denote this
  \(\mathcal{L}(\mathcal{D})\) (smallest \(\lambda\)-system containing
  \(\mathcal{D}\)).
\item
  If \(\mathcal{L}\) is a \(\pi\)-system AND a \(\lambda\)-system, then
  \(\mathcal{L}\) is a \(\sigma\)-field.
\item
  If \(\mathcal{D}\) is \(\pi\)-system, then
  \(\mathcal{L}(\mathcal{D})\) is \(\pi\)-system.
\end{enumerate}

By 1)-3), \(\mathcal{L} = \sigma(\mathcal{D})\), which implies \ldots{}
\EndKnitrBlock{solution}

\subsection{\texorpdfstring{The ``Good Sets''
Principle}{The Good Sets Principle}}\label{the-good-sets-principle}

\BeginKnitrBlock{exercise}
\protect\hypertarget{exr:good-sets}{}{\label{exr:good-sets} }Let
\(\mathcal{P}\) be a \(\pi\)-system, and \(\nu_1\) and \(\nu_2\) two
measures that agree on \(\mathcal{P}\), i.e.

\[
  \nu_1(A) = \nu_2(A) \text{ for all } A \in \mathcal{P}.
\]

Assume there is a sequence of sets \(A_n \in \mathcal{P}\) with
\(A_n \uparrow \Omega\) and \(\nu_i(A_n) < \infty\) for all \(n\).

Use the \(\pi-\lambda\) theorem to prove that \(\nu_1\) and \(\nu_2\)
agree on \(\sigma(\mathcal{P})\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Let \(\F_n\) be given by

\[
  \F_n = \left \{A \in \sigma(\mathcal{P}) \left | \nu_1(A \cap A_n) = \nu_2(A \cap A_n) \forall n \right \} \right .
\]

Let \(A \in \mathcal{P}\). Since \(A_n \in \mathcal{P}\) for all \(n\)
and \(\mathcal{P}\) is a \(\pi\)-system, \(A \cap A_n \in \mathcal{P}\).
So \(\nu_1(A \cap A_n) = \nu_2(A \cap A_n)\), hence
\(\mathcal{P} \subset \F_n\).

By definition, \(\F_n \subset \sigma(\mathcal{P})\), so
\(\mathcal{P} \subset \F_n \subset \sigma(\mathcal{P})\).

Now, if we can prove that \(\F_n\) is a \(\lambda\)-system for all
\(n\), then by the \(\pi-\lambda\) theorem (theorem
\ref{thm:pi-lambda}), we have that \(\sigma(\mathcal{P}) \subset \F_n\),
which combined with the paragraph above gives us that
\(\sigma(\mathcal{P}) = \F_n\), hence \(\nu_1\) and \(\nu_2\) agree on
\(\sigma(\mathcal{P})\).

So let us show that \(\F_n\) is indeed a \(\lambda\)-system:

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \(\Omega \in \F_n\). Since \(A_n \uparrow \Omega\), we can use
  continuity of measure (proposition \ref{prp:properties-of-measures})
  to conclude that
\end{enumerate}

\begin{align*}
  \lim_{n \rightarrow \infty} \nu_i(A_n) &= \nu_i(\lim_{n \rightarrow \infty} A_n) \\
    &= \nu_i(\Omega).
\end{align*}

Since \(\nu_1(A_n) = \nu_2(A_n)\) (\(A_n \in \mathcal{P}\)), it holds
that \(\nu_1(\Omega) = \nu_2(\Omega)\), so
\(\Omega \in \P \subset \F_n\).

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Let \(A,B \in \F_n\) with \(A \subset B\). So,
\end{enumerate}

\begin{align*}
  \nu_1((A\setminus B) \cap A_n) &= \nu_1(A\cap A_n) - \nu_1(B\cap A_n) \\
    &= \nu_2(A\cap A_n) - \nu_2(B\cap A_n) \\
    &= \nu_2((A\setminus B) \cap A_n),
\end{align*}

which means that \(A\setminus B \in \F_n\).

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Let \(B_i \in \F_n\) s.t. \(B_i \subset B_{i+1}\). Then, once again
  using continuity of measures to move limits around, we have
\end{enumerate}

\begin{align}
  \nu_1\left(\cup_{i=1}^\infty B_i \cap A_n \right) &= \nu_1\left(\cup_{i=1}^\infty (B_i \cap A_n) \right) \\
    &= \lim_{i \rightarrow \infty} \nu_1(B_i \cap A_n) \\
    &= \lim_{i \rightarrow \infty} \nu_2(B_i \cap A_n) \\
    &= \nu_2\left(\cup_{i=1}^\infty (B_i \cap A_n) \right) \\
    &= \nu_2\left(\cup_{i=1}^\infty B_i \cap A_n \right),
\end{align}

which gives us that \(\cup_{i = 1}^\infty B_i \in \F_n\), hence \(\F_n\)
is a \(\lambda\)-system.
\EndKnitrBlock{solution}

\subsection{From Indicator Function to General (Borel)
Function}\label{from-indicator-function-to-general-borel-function}

When we deine the Lebesgue integral, we define it in three steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  First for indicator functions, which in turn is generalized to simple
  non-negative functions (i.e.~linear combinations of indicator
  functions).
\item
  Second for any non-negative functions (which is done by utilizing that
  any such function can be described as the limit of a sequence of
  simple functions)
\item
  A general function (by separating the positive and negative parts)
\end{enumerate}

\BeginKnitrBlock{exercise}
\protect\hypertarget{exr:unnamed-chunk-18}{}{\label{exr:unnamed-chunk-18}
}Let \(\Omega = \left\{\omega_1, \omega_2, \ldots \right\}\) be a
countable set, \(\F\) all subsets of \(\Omega\), and \(\nu\) the
counting measure on \(\Omega\). Show that for any Borel function \(f\),
the integral of \(f\) with respect to \(\nu\) is

\begin{equation}
  \int f d\nu = \sum_{i=1}^\infty f(\omega_i)  \label{eq:ex14}
\end{equation}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Let \(A \in \F\) and define \(f = 1_A\).
Then

\begin{align*}
  \int f d\nu &= \int_A d\nu \\
              &= \nu(A) \\
              &= \sum_{i=1}^\infty 1_A(\omega_i)
\end{align*}

I.e. \eqref{eq:ex14} holds for indicator functions, and hence also for
simple functions.

Now, let \(f\) be a non-negative Borel function. Then we know that there
exists a sequence \((f_n)_i^{\infty}\) of simple functions such that
\(f_n \uparrow f\). Then

\begin{align*}
  \int f d\nu &= \int \lim_{n \rightarrow \infty} f_n d\nu \\
              &= \lim_{n\rightarrow \infty} \int f_n d\nu.
\end{align*}

Since \(f_n\) is a simple function, we know that @ref\{eq:ex14\} holds.
Hence,

\begin{align*}
  \int f d\nu &= \lim_{n \rightarrow \infty} \sum_{i=1}^\infty f_n(\omega_i) \\
  &= \sum_{i=1}^\infty \lim_{n \rightarrow \infty} f_n(\omega_i) \\
  &= \sum_{i=1}^\infty f(\omega_i),
\end{align*}

and so @ref\{eq:ex14\} holds for non-negative Borel functions.

Finally, let \(f\) be any Borel function. Then we can write
\(f = f_+ - f_-\), where \(f_+ = \max(f,0)\) and \(f_- = \max(-f, 0)\).
Then both \(f_+\) and \(f_-\) are non-negative Borel functions, hence
@ref\{eq:ex14\} holds for both. So

\begin{align*}
  \int f d\nu &= \int f_+ d\nu - \int f_- d\nu \\
              &= \sum_{i=1}^\infty f_+(\omega_i) - \sum_{i=1}^\infty f_-(\omega_i) \\
              &= \sum_{i=1}^\infty f_+(\omega_i) - f_-(\omega_i) \\
              &= \sum_{i=1}^\infty f(\omega_i).
\end{align*}

So \eqref{eq:ex14} holds for all Borel functions.
\EndKnitrBlock{solution}

\subsection{Switch the Order of Integration and
Limit}\label{switch-the-order-of-integration-and-limit}

\BeginKnitrBlock{exercise}[Generalized Dominated Convergence Theorem]
\protect\hypertarget{exr:unnamed-chunk-20}{}{\label{exr:unnamed-chunk-20}
\iffalse (Generalized Dominated Convergence Theorem) \fi{} }If
\(\lim f_n = f\) and there exists a sequence of integrable functions
\(g_1, g_2, g_3, \ldots\) such that

\begin{itemize}
\tightlist
\item
  \(|f_n| \leq g_n\) a.e.
\item
  \(g_n \rightarrow g\) a.e.
\item
  \(\lim_{n \rightarrow \infty} \int g_n d\nu = \int g d\nu\)
\end{itemize}

then

\begin{equation}
  \int \lim_{n \rightarrow \infty} f_n d\nu = \lim_{n \rightarrow \infty} \int f_n d\nu \label{eq:ex15}
\end{equation}
\EndKnitrBlock{exercise}

\chapter{Homework}\label{homework}

\section{First Exam Period}\label{first-exam-period}

\subsection{Assigned Problems}\label{assigned-problems}

NOTE: This homework submission is for both Ralph Trane and Alex Hayes.
For almost all of the problems here, we worked together on a whiteboard.
We then took pictures or handwritten notes of the solutions and wrote
them up here.

\BeginKnitrBlock{exercise}[Ex 2]
\protect\hypertarget{exr:unnamed-chunk-21}{}{\label{exr:unnamed-chunk-21}
\iffalse (Ex 2) \fi{} }Let \(\C\) be a collection of subsets of
\(\Omega\) and let
\(\Gamma = \{ \F | \F \text{ is a } \sigma \text{-field on } \Omega \text{ and } \C \subset \F \}\).
Show that \(\Gamma \neq \emptyset\) and
\(\sigma(\C) = \cap_{\F \in \Gamma} \F\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 2]
\iffalse{} {Solution (Ex 2). } \fi{}Let \(\P(\Omega)\) be the collection
of all subsets of \(\Omega\). We know that this is a \(\sigma\)-field.
It also contains \(\C\). Hence, \(\Gamma \neq \emptyset\).

By definition, \(\sigma(\C)\) is the smallest \(\sigma\)-field that
contains \(\C\), hence \(\sigma(\C) \in \Gamma\) and
\(\sigma(\C) \subset \F\) for all \(\F \in \Gamma\). Therefore,
\(\sigma(\C) \subset \cap_{\F \in \Gamma} \F\). But since
\(\sigma(\C) \in \Gamma\), \(\sigma(\C) \in \cap_{\F \in \Gamma} \F\),
which in turn ensures that
\(\cap_{\F \in \Gamma} \F \subset \sigma(\C)\).

Hence \(\sigma(\C) = \cap_{\F \in \Gamma} \F\).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 5]
\protect\hypertarget{exr:unnamed-chunk-23}{}{\label{exr:unnamed-chunk-23}
\iffalse (Ex 5) \fi{} }a) Let \(\C\) be a \(\pi\)-system and
\(\mathcal{D}\) be a \(\lambda\)-system such that
\(\C \subset \mathcal{D}\). Show that
\(\sigma(\C) \subset \mathcal{D}\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 5]
\iffalse{} {Solution (Ex 5). } \fi{}TODO
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 12]
\protect\hypertarget{exr:unnamed-chunk-25}{}{\label{exr:unnamed-chunk-25}
\iffalse (Ex 12) \fi{} }Let \(\nu\) and \(\lambda\) be two measures on
\((\Omega, \F)\) such that \(\nu(A) = \lambda(A)\) for any
\(A \in \C \subset \F\), where \(\C\) is a \(\pi\)-system
(\ref{def:pi-system}). Assume that \(\nu\) is \(\sigma\)-finite
(\ref{def:sigma-finite}).

Show that \(\nu(A) = \lambda(A)\) for all \(A \in \sigma(\C)\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 12]
\iffalse{} {Solution (Ex 12). } \fi{}Let
\(\F = \{A \in \sigma(\C) | \nu(A) = \lambda(A)\}\). Then
\(\C \subset \F\). If we can show that \(\F\) is a \(\sigma\)-field,
then \(\sigma(\C) \subset \F\) (since \(\sigma(\C)\) is the smallest
\(\sigma\)-field that contains \(\C\)), which proves that
\(\nu(A) = \lambda(A)\) for all \(A \in \sigma(\C)\).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 14]
\protect\hypertarget{exr:unnamed-chunk-27}{}{\label{exr:unnamed-chunk-27}
\iffalse (Ex 14) \fi{} }Prove proposition 1.4 (proposition
\ref{prp:borel-function-properties})
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 14 (i)]
\iffalse{} {Solution (Ex 14 (i)). } \fi{} Assume \(f\) is Borel. Then
\(f^{-1}(A) \in \F\) for all open sets \(A \in \B\), hence
\(f^{-1}(a, \infty) \in \F\).

Now assume \(f^{-1}(a, \infty) \in \F\) for all \(a \in \R\), and let
\(\mathcal{G} = \{ A \in \B | f^{-1}(A) \in \F \}\). So,
\((a, \infty) \in \mathcal{G}\) for all \(a \in \R\). If we can show
that \(\mathcal{G}\) is a \(\sigma\)-field, then we will have that
\(\sigma((a, \infty)) = \B \subset \mathcal{G}\), hence
\(f^{-1}(B) \in \F\) for all \(B \in \B\), meaning that \(f\) is
measurable.

So let us prove that \(\mathcal{G}\) is a \(\sigma\)-field.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  First of all, \(f^{-1}(\emptyset) = \emptyset \in \F\).
\item
  Second, let \(A \in \mathcal{G}\). Since
  \(f^{-1}(A^C) = (f^{-1}(A))^C \in \F\) (\(\F\) is a \(\sigma\)-field
  and \(f^{-1}(A) \in \F\), so \((f^{-1}(A))(^C) \in \F\)).
\item
  Finally, let \(A_1, A_2, \ldots\) be a sequence of sets such that
  \(A_i \in \mathcal{G}\) for all \(i\). Then
  \(f^{-1}\left(\cup_{i=1}^\infty A_i \right) = \cup_{i=1}^\infty f^{-1}(A_i)\).
  Since \(f^{-1}(A_i) \in \F\) for all \(i\) and \(\F\) is a
  \(\sigma\)-field, \(\cup_{i=1}^\infty f^{-1}(A_i) \in \F\), so
  \(\cup_{i=1}^\infty A_i \in \mathcal{G}\).
\end{enumerate}

So \(\mathcal{G}\) is a \(\sigma\)-field, which concludes the proof.
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 14 (ii)]
\iffalse{} {Solution (Ex 14 (ii)). } \fi{}Assume \(f\) and \(g\) are
Borel functions. Let \(a,b \in \R\). \(af\) is Borel, since

\[
  (af)^{-1}((c,\infty)) = \left\{ \omega \in \Omega : a\cdot f(\omega) \in (c, \infty) \right\}.
\]

If \(a \neq 0\),

\[\begin{aligned}
 (af)^{-1}((c,\infty)) &= \left\{ \omega \in \Omega : f(\omega) \in (\tfrac{c}{a}, \infty) \right\} \\
                       &= f^{-1}(\tfrac{c}{a}, \infty).
\end{aligned}\]

Since \(f\) is Borel, this is a measurable set (by (i)). If \(a = 0\),
then

\[(af)^{-1}((c,\infty)) = 
  \left\{ 
    \begin{matrix} 
      \Omega & \text{ if } c \le 0 \\ 
      \emptyset & \text{ if } c < 0 
    \end{matrix}
  \right .
\]

In either case, \((af)^{-1}((c, \infty)) \in \F\). Since it holds that
for all \(a,c \in \R\) that \((af)^{-1}((c,\infty)) \in \F\), \(af\) is
measurable by (i).

Let \(c \in \R\). Now consider the sum of \(f\) and \(g\):

\[\begin{aligned}
  (f + g)^{-1}((c, \infty)) &= \left\{ \omega \in \Omega : f(\omega) + g(\omega) > c \right\} \\.
                            &= \cup_{t \in \mb{Q}} \{\omega \in \Omega : f(\omega) > c - t \} \cap \{\omega \in \Omega : g(\omega) > t \} \\
                            &= \cup_{t \in \mb{Q}} f^{-1}((c-t, \infty)) \cap g^{-1}((t, \infty)).
\end{aligned}\]

Since \(f\) and \(g\) are both measurable,
\(f^{-1}((c-t, \infty)) \in \F\) and \(g^{-1}((t, \infty))\in \F\) for
all \(t \in \R\). Hence, the intersection of the two is measurable for
any \(t \in \R\), which in turn implies that the union over all rational
numbers is measurable (countable union of measurable sets). Hence,
\(f+g\) is measurable.

Combine the two results to get the final result.\footnote{Note: This
  could be done in one step, but I found it easier to split up into two.}
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 14 (iii)]
\iffalse{} {Solution (Ex 14 (iii)). } \fi{}TODO
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 14 (iv)]
\iffalse{} {Solution (Ex 14 (iv)). } \fi{}Assume \(f\) is measurable
from \((\Omega, \F)\) to \((\Lambda, \mathcal{G})\), and \(g\)
measureable from \((\Lambda, \mathcal{G})\) to
\((\Delta, \mathcal{H})\). Let \(H \in \mathcal{H}\). We want to show
that \((g \circ f)^{-1}(H) \in \F\), since this would mean \(g \circ f\)
is measurable. So,

\[\begin{aligned}
  (g \circ f)^{-1}(H) &= \left\{ \omega \in \Omega | g(f(\omega)) \in H \right\} \\ 
                      &= \left\{ \omega \in \Omega | f(\omega) \in g^{-1}(H) \right\} \\ 
                      &= f^{-1}(g^{-1}(H)).
\end{aligned}\]

Since \(g\) is measurable, \(g^{-1}(H) \in \mathcal{G}\), and since
\(f\) is measurable, \(f^{-1}(g^{-1}(H)) \in \F\). So, \(g \circ f\) is
measurable.
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 14 (v)]
\iffalse{} {Solution (Ex 14 (v)). } \fi{}Let \(f: \Omega \to \R^p\),
where \(\Omega\) is a borel set. Assume \(f\) is continuous. Then, if
\(A\) is an open set, \(f^{-1}(A)\) is an open set, and therefore borel.
Hence, \(f^{-1}((a,\infty))\) is a borel set for all \(a\), and by
\((i)\) we have that \(f\) is a borel function.
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 19]
\protect\hypertarget{exr:unnamed-chunk-33}{}{\label{exr:unnamed-chunk-33}
\iffalse (Ex 19) \fi{} } Let \(\{f_n\}\) be a sequence of Borel
functions on a measurable space. Show that

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\sigma(f_1, f_2, \ldots) = \sigma(\cup_{j=1}^{\infty} \sigma(f_j)) = \sigma(\cup_{j=1}^\infty \sigma(f_1,\ldots, f_j)).\)
\item
  \(\sigma(\lim \sup_n f_n) \subset \cap_{n=1}^\infty \sigma(f_n, f_{n+1},\ldots).\)
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 19]
\iffalse{} {Solution (Ex 19). } \fi{}TODO
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 24]
\protect\hypertarget{exr:unnamed-chunk-35}{}{\label{exr:unnamed-chunk-35}
\iffalse (Ex 24) \fi{} } Let \(f\) be an integrable function on
\((\Omega, \F, \nu)\). Show that for each \(\epsilon > 0\), there exists
a \(\delta_\epsilon\) such that for \(A \in \F\):

\[
  \nu(A) < \delta_\epsilon \to \int_A |f| d\nu < \epsilon. 
\]
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Let \(\epsilon > 0\), \(A \in \F\) with
\(\nu(A) < \delta_\epsilon = \frac{\epsilon}{\sup_{\omega \in A} |f(\omega)|}\).
Then

\begin{align*}
  \int_A |f| d\nu &\leq \int_A \sup_{\omega \in A} |f(\omega)| d\nu \\
                  &= \sup_{\omega \in A} |f(\omega)| \nu(A) \\
                  &< \epsilon.
\end{align*}
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 30]
\protect\hypertarget{exr:unnamed-chunk-37}{}{\label{exr:unnamed-chunk-37}
\iffalse (Ex 30) \fi{} }For any c.d.f. \(F\) and any \(a \ge 0\), show
that \(\int [F(x+a) - F(x)] dx = a\)
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Note that
\(F(X) = \int 1_{-\infty, x} dP\). Then

\[
\begin{aligned}
\int [F(x+a) - F(x)] dx &= \int_\R \left(\int 1_{-\infty, x + a} dP \right) -
   \left(\int 1_{-\infty, x} dP \right) dx\\
&= \int_\R \int 1_{x, x + a} dx \\
&= a 
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 34]
\protect\hypertarget{exr:unnamed-chunk-39}{}{\label{exr:unnamed-chunk-39}
\iffalse (Ex 34) \fi{} }Prove proposition \ref{prp:calc-radon-nikodym}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 34 i)]
\iffalse{} {Solution (Ex 34 i)). } \fi{}Let \(g\) be the unique function
denoted by \(\frac{d\lambda}{d\nu}\). Assume \(f = 1_A\) for some
\(A\in \F\). Since \(\lambda << \nu\), we know that
\(\lambda(A) = \int_A g d\nu\). So,

\begin{align*}
  \int f d\lambda &= \int 1_A d\lambda \\
                  &= \lambda(A) \\
                  &= \int_A g d\nu \\
                  &= \int 1_A g d\nu = \int f g d\nu.
\end{align*}

Hence, (i) is true for all indicator functions, and so by linearity of
integrals (\ref{prp:int-linearity}) for all non-negative simple
functions.

Now, let \(f\) be a general non-negative Borel function. Then we know
that there exists a sequence of simple functions
\(\phi_1, \phi_2, \ldots\) such that \(\phi_n \uparrow f\). Hence,
utilizing the monotone convergence theorem and the fact that we know (i)
holds for simple functions,

\begin{align*}
  \int f d\lambda &= \int \lim_{n \to \infty} \phi_n d\lambda \\
                  &= \lim_{n \to \infty} \int \phi_n d\lambda \\
                  &= \lim_{n \to \infty} \int \phi_n g d\nu \\
                  &= \int \lim_{n \to \infty} \phi_n g d\nu \\
                  &= \int f g d\nu,
\end{align*}

and so we have shown that (i) holds for any non-negative Borel function.
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 34 ii)]
\iffalse{} {Solution (Ex 34 ii)). } \fi{}Assume \(\lambda_1 << \nu\) and
\(\lambda_2 << \nu\). Then

\begin{align*}
  (\lambda_1 + \lambda_2)(A) &= \lambda_1(A) + \lambda_2(A) \\
                             &= \int_A g_1 d\nu + \int_A g_2 d\nu \\
                             &= \int_A (g_1 + g_2)d\nu,
\end{align*}

so \(\lambda_1 + \lambda_2 << \nu\), and

\[\frac{d(\lambda_1 + \lambda_2)}{d\nu} = g_1 + g_2 = \frac{d\lambda_1}{d\nu} + \frac{d\lambda_2}{d\nu}.\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 34 iii)]
\iffalse{} {Solution (Ex 34 iii)). } \fi{}Since \(\tau << \lambda\),

\[\tau(A) = \int_A \frac{d\tau}{d\lambda}d\lambda.\]

Since \(\lambda << \nu\), we can use (i) with
\(f = \frac{d\tau}{d\lambda}\), to get

\[\tau(A) = \int_A \frac{d\tau}{d\lambda}\frac{d\lambda}{d\tau} d\tau,\]

which tells us that \(\tau << \nu\) and

\[\frac{d\tau}{d\nu} = \frac{d\tau}{d\lambda}\frac{d\lambda}{d\tau}.\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 34 iv)]
\iffalse{} {Solution (Ex 34 iv)). } \fi{} By definition,
\((\lambda_1 \times \lambda_2)(A) = \int_A d(\lambda_1 \times \lambda_2) = \int 1_A d(\lambda_1 \times \lambda_2)\).
Since \(1_A \ge 0\), we can use Fubini to get

\[ (\lambda_1 \times \lambda_2)(A) = \int \int 1_A d\lambda_1 d\lambda_2. \]

Since \(\lambda_1 << \nu_1\), we can use (i) with \(f = 1_A\) (\(1_A\)
is non-negative) to obtain that

\[(\lambda_1 \times \lambda_2)(A) = \int \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1 d\lambda_2,\]

and then, since \(\lambda_2 << \nu_2\), using (i) again with
\(f = \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1\) (which is non-negative)
to get

\[(\lambda_1 \times \lambda_2)(A) = \int \int 1_A \frac{d\lambda_1}{d\nu_1}d\nu_1 \frac{d\lambda_2}{d\nu_2}d\nu_2.\]

Finally, using Fubini again we get

\[\begin{aligned}
  (\lambda_1 \times \lambda_2)(A) &= \int \int 1_A \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2} d\nu_1 d\nu_2 \\
                                  &= \int_A \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2} d(\nu_1\times\nu_2).
\end{aligned}\]

I.e. \(\lambda_1 \times \lambda_2 << \nu_1 \times \nu_2\) and
\(\frac{d(\lambda_1 \times \lambda_2)}{d(\nu_1 \times \nu_2)} = \frac{d\lambda_1}{d\nu_1}\frac{d\lambda_2}{d\nu_2}\).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 35]
\protect\hypertarget{exr:unnamed-chunk-44}{}{\label{exr:unnamed-chunk-44}
\iffalse (Ex 35) \fi{} }Let \(\{a_n\}\) be a sequence of positive
numbser with \(\sum_{i=1}^\infty a_n = 1\), and \(\{P_n\}\) a sequence
of probability measure on a common measurable space, \((\Omega, \F)\).
Define \(P = \sum_{n=1}^\infty P_n\).

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Show that \(P\) is a probability measure.
\item
  Let \(\nu\) be a \(\sigma\)-finite measure. Show that
\end{enumerate}

\[P_n << \nu \text{ for all } n \in \mb{N}\quad \iff \quad P << \nu.\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Derive the Lebesgue p.d.f. of \(P\) when \(P_n\) is the gamma
  distribution \(\Gamma(\alpha, n^{-1})\) with \(\alpha > 1\) and
  \(a_n \propto n^{-\alpha}\).
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 35 a)]
\iffalse{} {Solution (Ex 35 a)). } \fi{}Need to show that
\(P = \sum_{n=1}^{\infty} a_n P_n\) is a probability measure. So we
check the three properties for a probability measure
(\ref{def:measure}), with the extra property that \(P(\Omega) = 1\):

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\tightlist
\item
  \(P(A) = \sum_{n=1}^\infty a_n P_n(A) \geq 0\) for all \(A\) since
  \(a_n > 0\) for all \(n\) by assumption, and \(P_n(A) \ge 0\) for all
  \(n\), since \(P_n\) is a probability measure. Furthermore,
  \(P(\Omega) = \sum_{n=1}^\infty a_n P_n(\Omega) = \sum_{n=1}^\infty a_n = 1\),
  where the second equality holds since \(P_n\) is a probability measure
  (by assumption), and the last equality is exactly the assumption we
  made about the \(a_n\)s. I.e. \(0 \le P(A) \le 1\).
\item
  Since \(P_n(\emptyset) = 0\),
  \(P(\emptyset) = \sum_{n=1}^\infty a_n P_n(\emptyset) = 0\).
\item
  Let \(A_1, A_2,\ldots\) be a countable sequence of pairwise disjoint
  sets. Then using that \(P_n\) is a measure for all \(n\),
\end{enumerate}

\[\begin{aligned}
  P(\cup_{i=1}^\infty A_i) &= \sum_{n=1}^\infty a_nP_n\left(\cup_{i=1}^\infty A_i\right) \\
                           &= \sum_{n=1}^\infty a_n\sum_{i=1}^\infty P_n(A_i) \\
                           &= \sum_{i=1}^\infty \sum_{n=1}^\infty a_n P_n(A_i) \\
                           &= \sum_{i=1}^\infty P(A_i).
\end{aligned}\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 35 b)]
\iffalse{} {Solution (Ex 35 b)). } \fi{}Assume \(P << \nu\). Let
\(A \in \F\) with \(\nu(A) = 0\). Assume there exists \(n \in \mb{N}\)
such that \(P_n(A) > 0\). Then \(P(A) > a_n P_n(A) > 0\). But
\(P << \nu\) implies that \(P(A) = 0\), so by contradiction,
\(P_n(A) = 0\) for all \(n \in \mb{N}\).

Now assume \(P_n << \nu\). Let \(A \in \F\) with \(\nu(A) = 0\). Then
\(P_n(A) = 0\) for all \(n \in \mb{N}\). Hence,
\(P(A) = \sum_{n=1}^\infty a_n P_n(A) = 0\), which means that
\(P << \nu\).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 50]
\protect\hypertarget{exr:unnamed-chunk-47}{}{\label{exr:unnamed-chunk-47}
\iffalse (Ex 50) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 55]
\protect\hypertarget{exr:unnamed-chunk-48}{}{\label{exr:unnamed-chunk-48}
\iffalse (Ex 55) \fi{} } Let \(X\) be a random variable. Show that

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  If \(E X\) exists, then
  \(E X = \int_0^\infty P(X > x) dx - \int_{-\infty}^0 P(X \le x) dx\).
\item
  If \(X\) has range \(0, 1, 2, ...\), then
  \(E X = \sum_{n=1}^\infty P(X \ge x)\)
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[EX 55 (a)]
\iffalse{} {Solution (EX 55 (a)). } \fi{} First rewrite the RHS in terms
of PDFS

\[\int_0^\infty \int_x^\infty f(y) dy dx - \int_{-\infty}^0 \int_{-\infty}^x f(y) dy dx\]

Then we can use Fubini (since \(f\) is positive) to switch the order of
the integrals

\[
\begin{aligned}
&= \int_0^\infty \int_0^y f(y) dy dx - \int_{-\infty}^0 \int_{-y}^0 f(y) dy dx \\
&= \int_0^\infty f(y) \int_0^y 1 dx dy - \int_{-\infty}^0 f(y) \int_{-y}^0 1 dx dy \\
&= \int_0^\infty f(y) y dy dx - \int_{-\infty}^0 -y \cdot f(y) dy \\
&= E X
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 56]
\protect\hypertarget{exr:unnamed-chunk-50}{}{\label{exr:unnamed-chunk-50}
\iffalse (Ex 56) \fi{} }Calculate the expectation and variance of the
noncentral t distribution.
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 56 (a)]
\iffalse{} {Solution (Ex 56 (a)). } \fi{}We did these. The integrals
were hard. There were two. We don't have time to write up the nasty
calculus, but do know that we suffered to prove this result. YAY
MAAAAATH! We may staple the ugly to the back to the back of the nice
solutions.
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 65]
\protect\hypertarget{exr:unnamed-chunk-52}{}{\label{exr:unnamed-chunk-52}
\iffalse (Ex 65) \fi{} }TODO
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 74]
\protect\hypertarget{exr:unnamed-chunk-53}{}{\label{exr:unnamed-chunk-53}
\iffalse (Ex 74) \fi{} }Let \(\phi_n\) be a the chf of a probability
measure \(P_n, n = 1, 2, ...\). Let \(\{a_n\}\) be a sequence of
nonnegative numbers with \(\sum_{n=1}^\infty a_n = 1\). Show that
\(\sum_{n=1}^\infty a_n \phi_n\) is a ch.f. and find its corresponding
probability measure.
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 74]
\iffalse{} {Solution (Ex 74). } \fi{}Take \(P = \sum_n a_n P_n\). Note
that \(P_n\) is dominated by \(P\), so that there exists a density
\(g_n = dP_n/dP\) for each \(n\) (exercise 35). Consider
\(P(\Omega) = \int_\Omega \sum a_n g_n(x) dP = 1\), so that
\(\sum a_n g_n(x) = 1\) almost everywhere. Then

\[
\begin{aligned}
\sum_n a_n \phi_n &= \sum_n a_n \int e^{itx} g_n(x) dP \\
&= \int \sum_n a_n e^{itx} g_n(x) dP \qquad \text{Fubini} \\
&= \int e^{itx} dP \\
&= \phi(x)
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 83]
\protect\hypertarget{exr:unnamed-chunk-55}{}{\label{exr:unnamed-chunk-55}
\iffalse (Ex 83) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 85]
\protect\hypertarget{exr:unnamed-chunk-56}{}{\label{exr:unnamed-chunk-56}
\iffalse (Ex 85) \fi{} }TODO
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 93]
\protect\hypertarget{exr:unnamed-chunk-57}{}{\label{exr:unnamed-chunk-57}
\iffalse (Ex 93) \fi{} }TODO
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 99]
\protect\hypertarget{exr:unnamed-chunk-58}{}{\label{exr:unnamed-chunk-58}
\iffalse (Ex 99) \fi{} }LEt \(X_1, X_2, ...\) be i.i.d random variables
and let \(Y\) be a discrete random variable taking positive integer
values. Assume that \(X_i\) and \(Y\) are independent.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Obtain the ch.f. of Z
\item
  Show \(E Z = E Y E X_1\)
\item
  Show Var Z = E Y Var(X\_1) + Var(Y) (E X\_1)\^{}2
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 99 (a)]
\iffalse{} {Solution (Ex 99 (a)). } \fi{}TODO
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 99 (b)]
\iffalse{} {Solution (Ex 99 (b)). } \fi{} \[
\begin{aligned}
E Z &= E(\sum_{i=1}^Y X_i) \\
&= E( E(\sum_{i=1}^Y X_i) | Y ) \\
&= E(Y E(X_1 | Y)) \\
&= EY E(E(X_1 | Y)) \\
&= EY E X_1
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 99 (c)]
\iffalse{} {Solution (Ex 99 (c)). } \fi{} \[
\begin{aligned}
Var Z &= Var(E(Z | Y)) + E(Var(Z | Y)) \\
&= Var(E(Y X_1 | Y)) + E(Var(Y X_1)) \\
&= Var(Y E(X_1 | Y)) + E(Y^2 Var(X_1)) \\
&= (E(X_1))^2 Var(Y) + E(Y^2) Var(X_1)
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 101]
\protect\hypertarget{exr:unnamed-chunk-62}{}{\label{exr:unnamed-chunk-62}
\iffalse (Ex 101) \fi{} }TODO
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 106]
\protect\hypertarget{exr:unnamed-chunk-63}{}{\label{exr:unnamed-chunk-63}
\iffalse (Ex 106) \fi{} }Let \(\{Y_n\}\) be a sequence of independent
random. Show that the following are martingales:

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  \(X_1 = Y_1\), \(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n)\) where
  \(h_n\) are Borel.
\item
  Suppose \(E Y_n = 0\) and \(Var Y_n = \sigma^2\) for all \(n\).
  \(X_n = (sum_{j=1}^n Y_j)^2 - n \sigma^2\)
\item
  Suppose \(Y_n > 0\) and \(E Y_n = 1\) for all \(n\).
  \(X_n = Y_1 \cdot ... \cdot Y_n\).
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 106 (a)]
\iffalse{} {Solution (Ex 106 (a)). } \fi{}Recall that a sequence \(X_n\)
is a martingale if \(E(X_{n+1} | X_1, ..., X_n) = X_n\).

\[
\begin{aligned}
E(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n) | X_1, ..., X_n) &= 
  X_n +  h_n(X_1, ..., X_n) E(Y_{n+1} | X_1, ..., X_n) \\
&= X_n +  h_n(X_1, ..., X_n) 0 \\
&= X_n
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 106 (b)]
\iffalse{} {Solution (Ex 106 (b)). } \fi{} \[
\begin{aligned}
E(\sum_{j=1}^{n+1} Y_j)^2 - (n + 1) \sigma^2 | X_1, ..., X_n) &= 
  E(\sum_{j=1}^{n} Y_j + Y_{n+1})^2  | X_1, ..., X_n) - (n + 1) \sigma^2 \\
&= E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1} \cdot \sum_{j=1}^{n} Y_j | X_1, ..., X_n) + E(Y_{n+1}^2  | X_1, ..., X_n) - (n + 1) \sigma^2 \\
&= E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1}) E(\sum_{j=1}^{n} Y_j | X_1, ..., X_n) + \sigma^2 - (n + 1) \sigma^2 \\
&= (\sum_{j=1}^{n} Y_j)^2 + n \sigma^2
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 106 (c)]
\iffalse{} {Solution (Ex 106 (c)). } \fi{} \[
\begin{aligned}
E( Y_1 \cdot ... \cdot Y_n \cdot Y_{n+1} | X_1, ..., X_n) &= Y_1 \cdot ... \cdot Y_n E(Y_{n+1} | X_1, ..., X_n) \\
&= Y_1 \cdot ... \cdot Y_n \\
&= X_n
\end{aligned}
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 115]
\protect\hypertarget{exr:unnamed-chunk-67}{}{\label{exr:unnamed-chunk-67}
\iffalse (Ex 115) \fi{} }Let \(X_1, X_2, ...\) be a sequence of
identically distributed random variables with finite \(E |X_1|\) and let
\(Y_n = n^{-1} \max_{i \le n} |X_i|\).

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Show that \(Y_n \to 0\) in \(L_1\)
\item
  Show that \(Y_n \to 0\) almost surely
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 115 (a)]
\iffalse{} {Solution (Ex 115 (a)). }
\fi{}\(E Y_n = \int_0^\infty {1 \over n} P(\max_{i \le n} |X_i| > t) dt\)
by exercise 1.55. The integrand is then bounded by

\[{1 \over n} \sum P(\max_{i \le n} |X_i| > t)\]

which equals \({1 \over n} P(|X_1| > t)\) since the \(X_i\) are
identical. This is finite by hypothesis. Thus we can apply the DCT to
see that

\[\lim E Y_n = \int_0^\infty \lim {1 \over n}  P(\max_{i \le n} |X_i| > t) dt = 0\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{solution}[Ex 115 (b)]
\iffalse{} {Solution (Ex 115 (b)). } \fi{}The condition that \(E |X_1|\)
converges and being identical gives us that that \(\lim X_n / n\)
converges to zero almost surely. then we truncate. for some large enough
N, \(X_n / n\) must be less than epsilon. then for \(|X_n| / n\) for n
\textless{} N, there are only finitely many cases and so the max exists
and is bounded, and goes to zero by the \(n\) in the denominator. this
gives us that \(\lim Y_n\) goes to zero as \(n\) goes to zero. in fact
it goes to zero almost everywhere, since the limit \(|X_n| / n\) goes to
zero almost everywhere by the hypothesis that \(X_n\) is absolutely
integrable. thus \(\lim Y_n\) goes to zero almost surely.
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 117]
\protect\hypertarget{exr:unnamed-chunk-70}{}{\label{exr:unnamed-chunk-70}
\iffalse (Ex 117) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 126]
\protect\hypertarget{exr:unnamed-chunk-71}{}{\label{exr:unnamed-chunk-71}
\iffalse (Ex 126) \fi{} }Prove (vii) of Theorem 1.8
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Let \(X_n \to d X\), \(P(X = c) = 1\).

Apply triangle inequality and assumption:

\[
  \lim_{n \to \infty} P(\norm{X_n - c} > \epsilon) \le \lim_{n \to \infty} P(\norm{X_n - X} > \epsilon) + \lim_{n \to \infty} P(\norm{X - c} > \epsilon) = 0.
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 127]
\protect\hypertarget{exr:unnamed-chunk-73}{}{\label{exr:unnamed-chunk-73}
\iffalse (Ex 127) \fi{} }(a) Suppose X\_n converge in distribution to X.
Show X\_n is O\_P(1).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 127 (a)]
\iffalse{} {Solution (Ex 127 (a)). } \fi{}Suppose X\_n converge in
distribution to X. For large enough M, we have
\(P(|X| > M) < \epsilon_1\) (i.e the tail probability is small). For
large enough \(n\),
\(P(|X_n| > \epsilon_1) - P(|X| > \epsilon) < \epsilon) < \epsilon_2\).
Pick \(n\) large enough so that \(\epsilon_2\) is controlled.

\url{http://users.ices.utexas.edu/~alen/articles/asymp-final.pdf} - page
7
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 128]
\protect\hypertarget{exr:unnamed-chunk-75}{}{\label{exr:unnamed-chunk-75}
\iffalse (Ex 128) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 137]
\protect\hypertarget{exr:unnamed-chunk-76}{}{\label{exr:unnamed-chunk-76}
\iffalse (Ex 137) \fi{} }Let \(\{X_n\}\) and \(\{Y_n\}\) be two
sequences of R.Vs. Assume \(X_n \to_d X\) and
\(P_{Y_n | X_n = x_n} \to_w P_Y\) almost surely for every sequence of
numbers \(\{x_n\}\), where \(X\) and \(Y\) are independent random
variables. Show that \(X_n + Y_n \to_d X + Y\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{} \[
  P_{Y_n,X_n} = P_{Y_n|X_n}\cdot P_{X_n} \to P_Y P_X = P_{Y,X},
\]

where the last equality holds due to independence of \(X\) and \(Y\).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 138]
\protect\hypertarget{exr:unnamed-chunk-78}{}{\label{exr:unnamed-chunk-78}
\iffalse (Ex 138) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 140]
\protect\hypertarget{exr:unnamed-chunk-79}{}{\label{exr:unnamed-chunk-79}
\iffalse (Ex 140) \fi{} }\(X_n \sim N(\mu_n, \sigma^2_n, n \in \N\) and
\(X \sim N(\mu, \sigma^2)\). Show that
\(X_n \to_d X \iff \mu_n \to \mu\) and \(\sigma_n \to \sigma\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Assume \(\mu_n \to \mu\) and
\(\sigma_n \to \sigma\). Then
\(f_n(x) = \frac{1}{\sqrt{2\pi}\sigma_n}e^{\tfrac{-(x-\mu_n)^2}{\sigma_n}} \to f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\tfrac{-(x-\mu)^2}{\sigma}}\)
for all \(x\). Hence, \(X_n \to_d X\).

Assume \(X_n \to_d X\), and assume for contradiciton that
\((\mu_n, \sigma^2_n) \to (a,b^2) \neq (\mu, \sigma^2)\). This implies
that
\(f_n = \frac{1}{\sqrt{2\pi}\sigma_n}e^{\tfrac{-(x-\mu_n)^2}{\sigma_n}} \to f = \frac{1}{\sqrt{2\pi}b}e^{\tfrac{-(x-a)^2}{b}}\),
hence \(X_n \to_d Y\) where \(Y \sim N(a,b^2)\). Since
\((a,b) \neq (\mu, \sigma^2)\), and we know the limiting distribution is
unique, this contradicts our assumption.
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 142]
\protect\hypertarget{exr:unnamed-chunk-81}{}{\label{exr:unnamed-chunk-81}
\iffalse (Ex 142) \fi{} }\(f_n\) is the Lebesgue p.d.f. of the
t-distribution \(t_n\). Show that \(f_n(x) \to f(x)\) for all
\(x \in \R\), where \(f\) is the Lebesgue p.d.f. for standard normal.
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}By definition,
\(f_n(x) = \frac{\Gamma(\tfrac{n+1}{2})}{\sqrt{n\pi} \Gamma(\tfrac{n}{2})}\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}}\).

Note that \(\lim_{n \to \infty}\left(1+\frac{x}{n}\right)^n = e^x\). So,
since \(\sqrt{1+\tfrac{x^2}{n}} \to 0\),

\[\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}} = \frac{1}{\left(1+\tfrac{x^2/2}{n/2}\right)^{-n/2}\sqrt{1+\tfrac{x^2}{n}}} \to e^{-x^2/2}.\]

Since \(\lim_{n \to \infty} \frac{\Gamma(n + c)}{\Gamma(n)n^c} = 1\),

\[\lim_{n \to \infty} \frac{\Gamma(\tfrac{n}{2} + \tfrac{1}{2})}{\Gamma(\tfrac{n}{2})\sqrt{n/2}} = 1.\]

So

\[\begin{aligned}
  \lim_{n \to \infty} f_n(x) &= \lim_{n\to \infty} \frac{\Gamma(\tfrac{n+1}{2})}{\sqrt{n\pi} \Gamma(\tfrac{n}{2})}\left(1 + \frac{x^2}{n}\right)^{\tfrac{-(n+1)}{2}} \\
                                     &= \frac{1}{\sqrt{2\pi}}e^{-x^2/2}\lim_{n\to \infty}\frac{\Gamma(\tfrac{n}{2} + \tfrac{1}{2})}{\Gamma(\tfrac{n}{2})\sqrt{n/2}} \\
                                     &= \frac{1}{\sqrt{2\pi}}e^{-x^2/2}.
\end{aligned}\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 146]
\protect\hypertarget{exr:unnamed-chunk-83}{}{\label{exr:unnamed-chunk-83}
\iffalse (Ex 146) \fi{} }Let \(U_1, U_2, \ldots\) be i.i.d. random
variables, \(U_i \sim U[0,1]\). Let
\(Y_n = (\prod_{i=1}^n U_i)^{-1/n}\). Show that
\(\sqrt{n}(Y_n - e) \to_d N(0,e^2)\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Let \(X_i = -log(U_i)\). Then
\(EX_1 = \text{Var}(X_1) = 1\), and implies \(U_i = e^{-X_i}\). So

\[\begin{aligned}
  Y_n &= \left(\prod_{i=1}^n e^{-X_u} \right)^{-1/n} \\
      &= e^{\tfrac{1}{n}\sum_{i=1}^n X_i}.
\end{aligned}\]

By the CLT (corollary 1.2; page 69),
\(\tfrac{1}{\sqrt{n}}\sum_{i=1}^n (X_i - EX_1) = \tfrac{n}{\sqrt{n}}\left(\tfrac{1}{n}\sum_{i=1}^n X_i - 1\right) \to_d N(0, 1)\).

Let \(g = e^{x}\). Then \(g^\prime(x) = g(x)\), and \(U_i = g(X_i)\).
Using the delta method (specifically corollary 1.1; page 61), we get
that

\[
  \sqrt{n}\left(Y_n - e\right) = \tfrac{n}{\sqrt{n}}\left(g\left(\tfrac{1}{n}\sum_{i=1}^n X_i\right) - g(1)\right) \to_d N(0,g(1)^2) = N(0, e^2).
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 149]
\protect\hypertarget{exr:unnamed-chunk-85}{}{\label{exr:unnamed-chunk-85}
\iffalse (Ex 149) \fi{} }Let \(X_1, \ldots X_n\) be i.i.d. random
variables such that for \(x = 3,4,\ldots\),
\(P(X_1 = \pm x) = (2cx^2 \log(x))^{-1}\), where
\(c = \sum_{x=3}^\infty \tfrac{x^{-2}}{\log(x)}\).

Show that \(E|X_1| = \infty\), but
\(\tfrac{1}{n} \sum_{i=1}^n X_i \to_p 0\), using Theorem 1.13(i).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}Notice that

\[
  E|X_1| = \sum_{x=3}^\infty 2\frac{x}{2cx^2\log(x)} = \frac{1}{c}\sum_{x=3}^\infty \frac{1}{x\log(x)} \ge \tfrac{1}{c} \int_3^\infty \frac{1}{x\log(x)}dx = \infty,
\]

and that \(EX_1 = 0\). (To see that the inequality above holds, draw
it!)

Consider \(nP(|X_1| > n)\):

\[
  \begin{aligned}
    nP(|X_1| > n) &= n\sum(x=n)^\infty \frac{1}{2cx^2\log(x)} \\
                  &\le \frac{n}{c} \int_n^\infty \frac{1}{x^2\log(x)} dx \\
                  &\le \frac{n}{c\log(n)} \int_n^\infty \frac{1}{x^2} dx \\
                  &= \frac{n}{c\log(n)} \frac{1}{n} \to 0 \text{ as } n \to \infty.
  \end{aligned}
\]

So by theorem 1.13(i), we \(\frac{1}{n}\sum_{i=1}^n X_i - a_n \to_p 0\),
where \(a_n = E(X_1 I_{\left\{|X_1| \le n\right\}}) \to 0\) (can be seen
using an argument as above).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 152]
\protect\hypertarget{exr:unnamed-chunk-87}{}{\label{exr:unnamed-chunk-87}
\iffalse (Ex 152) \fi{} }Let \(T_n = \sum_{i=1}^n X_i\), where
\(X_1,X_2,\ldots\) are independent and \(P(X_n = \pm n^\theta) = 0.5\)
for some \(\theta > 0\).

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Show that when \(\theta < 0.5\), then \(T_n/n \to_{a.s.} 0\)
\item
  Show that when \(\theta \ge 1\), then \(T_n/n \to_{p} 0\) does NOT
  hold
\end{enumerate}
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}(a)

Since \(\theta < 0.5\), \(2(\theta - 1) < -1\). So

\[
  \begin{aligned}
    \sum_{n=1}^\infty \frac{E|X_n|^2}{n^2} &= \sum_{n=1}^\infty \frac{(n^\theta)^2}{n^2} \\
                                           &= \sum_{n=1}^\infty n^{2(\theta - 1)} < \infty.
  \end{aligned}
\]

By SLLN,
\(T_n/n = \frac{1}{n} \sum_{i=1}^\infty X_i \to_{a.s.} EX_1 = 0\).

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\item
\end{enumerate}

Note that the p.d.f. of \(X_n\) is
\(F_n(x) = 0 1_{X_n < -n^\theta} + \tfrac{1}{2}1_{-n^\theta \le X_n < n^\theta} + 1_{X_n \ge n^\theta}\).
By definition, \(X_n \to_d 0\) if and only if
\(F_n(x) \to F(x) = 1_{(X \ge 0)}\) for all \(x\) continuity points of
\(F\). For any \(n > 1\),
\(F_n(\tfrac{-n^\theta}{2}) = 0.5 \neq F(\tfrac{-n^\theta}{2}) = 0\). So
\(X_n\) does not converge to \(0\) in distribution. By theorem 1.8(iii),
this means that \(X_n\) does not converge to \(0\) in probability (since
convergence in probability implies convergence in distribution).
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 153]
\protect\hypertarget{exr:unnamed-chunk-89}{}{\label{exr:unnamed-chunk-89}
\iffalse (Ex 153) \fi{} }Let \(X_2, X_3, \ldots\) be independent random
variables with \(P(X_n = \pm \sqrt{n/\log(n)}) = 0.5\). Show that
\(\sum_{k=1}^\infty \frac{E|X_k|^p}{k^p} = \infty\) for all
\(p \in [1,2]\), but
\(\lim_{n \to \infty}\frac{1}{n^2} \sum_{i = 1}^\infty E|X_i|^2 = 0\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. } \fi{}For any \(p\in [1,2]\):

\[
  \sum_{n=2}^\infty \frac{E|X_n|^p}{n^p} = \sum_{n=2}^\infty \frac{(n/\log(n))^{p/2}}{n^p} = \sum_{n=2}^/infty \frac{1}{(n\log(n))^{p/2}} = \infty.
\]

Use that \(\log(x)\) is an increasing function:

\[\begin{aligned}
  \lim_{n \to \infty} \frac{1}{n^2} \sum_{k=2}^n E|X_k|^2 &= \lim_{n \to \infty} \frac{1}{n^2} \sum_{k=2}^\infty \frac{k}{\log(k)} \\
                                                          &\leq \lim_{n \to \infty} \frac{(n-1)\tfrac{n}{\log(n)}}{n^2} \\
                                                          &\leq \lim_{n \to \infty} \frac{n \tfrac{n}{\log(n)}}{n^2} \\
                                                          &\leq \lim_{n \to \infty} \frac{1}{\log(n)} = 0.
\end{aligned}\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 163]
\protect\hypertarget{exr:unnamed-chunk-91}{}{\label{exr:unnamed-chunk-91}
\iffalse (Ex 163) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 164]
\protect\hypertarget{exr:unnamed-chunk-92}{}{\label{exr:unnamed-chunk-92}
\iffalse (Ex 164) \fi{} }Let \(X_1, X_2, \ldots\) be independent
variables with \(P(X_j = \pm j^a) = P(X_j = 0) = \tfrac{1}{3}\), where
\(a > 0\), \(j=1,2,\ldots\). Does Liapounov's condition hold?
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}
\iffalse{} {Solution. }
\fi{}\(\sigma_n^ = \sqrt{\sum_{j=1}^n \frac{2j^{2a}}{3}}\). So, want to
see if

\[
  \frac{\sum_{j=1}^n E|X_j - EX_j|^{2+\delta}}{\sigma_n^{2+\delta}} \to 0.
\]

So,

\[\begin{aligned}
  \frac{\sum_{j=1}^n \left(\tfrac{2}{3}j^{2a}\right)^{2+\delta}}{\left(\tfrac{2}{3}\sum_{j=1}^n j^{2a}\right)^{(2+\delta)/2}} &= \frac{(\tfrac{2}{3})^{2+\delta}}{(\tfrac{2}{3})^{(2+\delta)/2}} \frac{\sum_{j=1}^\infty j^{(2+\delta)a}}{\left(\sum_{j=1}^\infty j^{2a}\right)^{(2+\delta)/2}}.
\end{aligned}\]

Choose \(\delta = 2\). Using Jensens inequality with \(\phi(x) = x^2\)
and the ratio test, we see that

\[
\frac{(\tfrac{2}{3})^4}{(\tfrac{2}{3})^2} \frac{\sum_{j=1}^\infty ((j^a)^2)^2}{\left(\sum_{j=1}^\infty j^{2a}\right)^{2}} \to 0.
\]
\EndKnitrBlock{solution}

\subsection{Suggested Problems}\label{suggested-problems}

\BeginKnitrBlock{exercise}[Ex 3]
\protect\hypertarget{exr:unnamed-chunk-94}{}{\label{exr:unnamed-chunk-94}
\iffalse (Ex 3) \fi{} }Let \(\Omega, \F_j)\), \(j=1,2,\ldots\), be
measurable spaces such that \(\F_j \subset \F_{j+1}\). Is
\(\cup_j \F_j\) a \(\sigma\)-field?
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 3]
\iffalse{} {Solution (Ex 3). } \fi{}No.

Let \(\Omega = [0,1]\), and
\(\F_n = \sigma \left\{[0,\tfrac{1}{2^n}),[\tfrac{1}{2^n},\tfrac{2}{2^n}), \ldots, [\tfrac{2^{n-1}}{2^n}, 1)\right\}\).

Now, consider the set \(B_n = [0, \tfrac{1}{2^n})\). Clearly
\(B_n \in \F_n\) for all \(n\), hence
\(B_n \in \cup_{i=1}^\infty \F_i\). Hower,
\(\cap_{i = 1}^{\infty} B_i = \{0\} \notin \cup_{i=1}^\infty \F_i\). So
\(\cup_{i=1}^\infty \F_i\) is not closed under countable intersection,
i.e.~it is not a \(\sigma\)-algebra.
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 6]
\protect\hypertarget{exr:unnamed-chunk-96}{}{\label{exr:unnamed-chunk-96}
\iffalse (Ex 6) \fi{} }Prove part (ii) and (iii) of proposition
\ref{prp:properties-of-measures}.
\EndKnitrBlock{exercise}

\BeginKnitrBlock{solution}[Ex 6]
\iffalse{} {Solution (Ex 6). } \fi{} i) Let \(A \subset B\). Then
\(B \setminus A \cap A = \emptyset\), hence
\(\nu(B) = \nu((B\setminus A) \cup A) = \nu(B\setminus A) + \nu(A) \geq \nu(A)\).

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Let \(A_1, A_2, \ldots\) be a sequence of sets. Define
  \(B_i = A_i \setminus \left(\cup_{k = 1}^{i-1} A_k \right)\). Then the
  \(B_i\)s are pairwise disjoint. Hence,
\end{enumerate}

\begin{align*}
  \nu\left(\cup_{i = 1}^\infty A_i\right) &= \nu\left(\cup_{i=1}^\infty B_i\right) \\
                                          &= \sum_{i=1}^\infty \nu(B_i) \\
                                          &= \sum_{i=1}^\infty \nu\left(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right ) \right ).
\end{align*}

Since \(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right) \subset A_i\),
we use (i) to get the result:

\begin{align*}
  \sum_{i=1}^\infty \nu\left(A_i \setminus \left(\cup_{k=1}^{i-1} A_k \right ) \right ) \leq \sum_{i=1}^\infty \nu\left(A_i \right )
\end{align*}

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Let \(A_1 \subset A_2 \subset A_3 \subset \dots\). Define
  \(B_i = A_i \setminus A_{i-1}\). Then \(B_1, B_2, \ldots\) is a
  sequence of pairwise disjoint sets, and
  \(\cup_{i = 1}^\infty B_i = \cup_{i=1}^\infty A_i\). Hence,
\end{enumerate}

\begin{align*}
  \nu\left(\cup_{i=1}^k A_i\right) &= \nu\left(\cup_{i=1}^k B_i\right) \\
                                   &= \sum_{i=1}^k \nu(B_i) \\
                                   &= \sum_{i=1}^k \nu(A_i\setminus A_{i-1}) \\
                                   &= \sum_{i=1}^k \nu(A_i) - \nu(A_{i-1}) \\
                                   &= \nu(A_k). 
\end{align*}

Taking the limit on both sides gives us

\[
  \nu\left(\cup_{i=1}^k A_i \right) = \lim_{n \to \infty} \nu(A_n).
\]
\EndKnitrBlock{solution}

\BeginKnitrBlock{exercise}[Ex 15]
\protect\hypertarget{exr:unnamed-chunk-98}{}{\label{exr:unnamed-chunk-98}
\iffalse (Ex 15) \fi{} }Show that a monotone function from \(\R\) to
\(\R\) is Borel, and a c.d.f. on \(\R^k\) is Borel.
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 17]
\protect\hypertarget{exr:unnamed-chunk-99}{}{\label{exr:unnamed-chunk-99}
\iffalse (Ex 17) \fi{} }Let \(f\) be a non-negative Borel function on
\((\Omega, \F)\). Show that \(f\) is the limit of a sequence of simple
functions \(\{\phi_n \}\) on \((\Omega, \F)\) with
\(0 \le \phi_1 \le \phi_2 \le \dots \le f\).
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 23]
\protect\hypertarget{exr:unnamed-chunk-100}{}{\label{exr:unnamed-chunk-100}
\iffalse (Ex 23) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 25]
\protect\hypertarget{exr:unnamed-chunk-101}{}{\label{exr:unnamed-chunk-101}
\iffalse (Ex 25) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 31]
\protect\hypertarget{exr:unnamed-chunk-102}{}{\label{exr:unnamed-chunk-102}
\iffalse (Ex 31) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 36]
\protect\hypertarget{exr:unnamed-chunk-103}{}{\label{exr:unnamed-chunk-103}
\iffalse (Ex 36) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 46]
\protect\hypertarget{exr:unnamed-chunk-104}{}{\label{exr:unnamed-chunk-104}
\iffalse (Ex 46) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 53]
\protect\hypertarget{exr:unnamed-chunk-105}{}{\label{exr:unnamed-chunk-105}
\iffalse (Ex 53) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 57]
\protect\hypertarget{exr:unnamed-chunk-106}{}{\label{exr:unnamed-chunk-106}
\iffalse (Ex 57) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 61]
\protect\hypertarget{exr:unnamed-chunk-107}{}{\label{exr:unnamed-chunk-107}
\iffalse (Ex 61) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 66]
\protect\hypertarget{exr:unnamed-chunk-108}{}{\label{exr:unnamed-chunk-108}
\iffalse (Ex 66) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 70]
\protect\hypertarget{exr:unnamed-chunk-109}{}{\label{exr:unnamed-chunk-109}
\iffalse (Ex 70) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 73]
\protect\hypertarget{exr:unnamed-chunk-110}{}{\label{exr:unnamed-chunk-110}
\iffalse (Ex 73) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 78]
\protect\hypertarget{exr:unnamed-chunk-111}{}{\label{exr:unnamed-chunk-111}
\iffalse (Ex 78) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 79]
\protect\hypertarget{exr:unnamed-chunk-112}{}{\label{exr:unnamed-chunk-112}
\iffalse (Ex 79) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 81]
\protect\hypertarget{exr:unnamed-chunk-113}{}{\label{exr:unnamed-chunk-113}
\iffalse (Ex 81) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 82]
\protect\hypertarget{exr:unnamed-chunk-114}{}{\label{exr:unnamed-chunk-114}
\iffalse (Ex 82) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 86]
\protect\hypertarget{exr:unnamed-chunk-115}{}{\label{exr:unnamed-chunk-115}
\iffalse (Ex 86) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 88]
\protect\hypertarget{exr:unnamed-chunk-116}{}{\label{exr:unnamed-chunk-116}
\iffalse (Ex 88) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 91]
\protect\hypertarget{exr:unnamed-chunk-117}{}{\label{exr:unnamed-chunk-117}
\iffalse (Ex 91) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 97]
\protect\hypertarget{exr:unnamed-chunk-118}{}{\label{exr:unnamed-chunk-118}
\iffalse (Ex 97) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 98]
\protect\hypertarget{exr:unnamed-chunk-119}{}{\label{exr:unnamed-chunk-119}
\iffalse (Ex 98) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 102]
\protect\hypertarget{exr:unnamed-chunk-120}{}{\label{exr:unnamed-chunk-120}
\iffalse (Ex 102) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 104]
\protect\hypertarget{exr:unnamed-chunk-121}{}{\label{exr:unnamed-chunk-121}
\iffalse (Ex 104) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 114]
\protect\hypertarget{exr:unnamed-chunk-122}{}{\label{exr:unnamed-chunk-122}
\iffalse (Ex 114) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 116]
\protect\hypertarget{exr:unnamed-chunk-123}{}{\label{exr:unnamed-chunk-123}
\iffalse (Ex 116) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 116]
\protect\hypertarget{exr:unnamed-chunk-124}{}{\label{exr:unnamed-chunk-124}
\iffalse (Ex 116) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 118]
\protect\hypertarget{exr:unnamed-chunk-125}{}{\label{exr:unnamed-chunk-125}
\iffalse (Ex 118) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 119]
\protect\hypertarget{exr:unnamed-chunk-126}{}{\label{exr:unnamed-chunk-126}
\iffalse (Ex 119) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 121]
\protect\hypertarget{exr:unnamed-chunk-127}{}{\label{exr:unnamed-chunk-127}
\iffalse (Ex 121) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 122]
\protect\hypertarget{exr:unnamed-chunk-128}{}{\label{exr:unnamed-chunk-128}
\iffalse (Ex 122) \fi{} }TODO - Alex
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 125]
\protect\hypertarget{exr:unnamed-chunk-129}{}{\label{exr:unnamed-chunk-129}
\iffalse (Ex 125) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 136]
\protect\hypertarget{exr:unnamed-chunk-130}{}{\label{exr:unnamed-chunk-130}
\iffalse (Ex 136) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 141]
\protect\hypertarget{exr:unnamed-chunk-131}{}{\label{exr:unnamed-chunk-131}
\iffalse (Ex 141) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 144]
\protect\hypertarget{exr:unnamed-chunk-132}{}{\label{exr:unnamed-chunk-132}
\iffalse (Ex 144) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 145]
\protect\hypertarget{exr:unnamed-chunk-133}{}{\label{exr:unnamed-chunk-133}
\iffalse (Ex 145) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 150]
\protect\hypertarget{exr:unnamed-chunk-134}{}{\label{exr:unnamed-chunk-134}
\iffalse (Ex 150) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 154]
\protect\hypertarget{exr:unnamed-chunk-135}{}{\label{exr:unnamed-chunk-135}
\iffalse (Ex 154) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 156]
\protect\hypertarget{exr:unnamed-chunk-136}{}{\label{exr:unnamed-chunk-136}
\iffalse (Ex 156) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 161]
\protect\hypertarget{exr:unnamed-chunk-137}{}{\label{exr:unnamed-chunk-137}
\iffalse (Ex 161) \fi{} }
\EndKnitrBlock{exercise}

\BeginKnitrBlock{exercise}[Ex 166]
\protect\hypertarget{exr:unnamed-chunk-138}{}{\label{exr:unnamed-chunk-138}
\iffalse (Ex 166) \fi{} }
\EndKnitrBlock{exercise}


\end{document}
