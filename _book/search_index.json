[
["index.html", "STAT 709: My notes Chapter 1 Intro 1.1 Textbook 1.2 Conventions re: \\(\\infty\\)", " STAT 709: My notes Ralph Møller Trane Fall 2018 (compiled 2018-10-08) Chapter 1 Intro 1.1 Textbook As of Fall 2018, this class uses the book Mathematical Statistics by Jun Shao (2nd. edition). Unless otherwise noted, all definitions, lemmas, proposition, theorems, etc. can be found there. Numbering might not match. 1.2 Conventions re: \\(\\infty\\) We will use the following conventions: \\(\\infty + x = \\infty, x \\in {\\mathbb{R}}\\) \\(x\\cdot \\infty = \\infty\\) if \\(x &gt; 0\\) \\(x\\cdot \\infty = -\\infty\\) if \\(x &lt; 0\\) \\(0\\cdot \\infty = 0\\) \\(\\infty + \\infty = \\infty\\) \\(\\infty^a = \\infty, \\forall a &gt; 0\\) \\(\\infty - \\infty\\) and \\(\\frac{\\infty}{\\infty}\\) are not defined "],
["lectures.html", "Chapter 2 Lecture Notes 2.1 Chapter 1: Probability Theory 2.2 Lecture 2: 9/11 2.3 Lecture 3: 9/13", " Chapter 2 Lecture Notes 2.1 Chapter 1: Probability Theory 2.1.1 Lecture 1: Measure space, measurable function, and integration 2.1.1.1 \\(\\sigma\\)-fields Definition 2.1 (\\(\\sigma\\)-field (or \\(\\sigma\\)-algebra)) A \\({\\mathcal{F}}\\) collection of subsets of \\(\\Omega\\) is called a \\(\\sigma\\)-field (or \\(\\sigma\\)-algebra) if the following three conditions hold: \\(\\emptyset \\in {\\mathcal{F}}\\) \\(A \\in {\\mathcal{F}}\\Rightarrow A^{c} \\in {\\mathcal{F}}\\) If \\(A_i \\in {\\mathcal{F}}\\) for all \\(i = 1,2,\\ldots\\), then \\(\\bigcup_i A_i \\in {\\mathcal{F}}\\). Example 2.1 (A Few \\(\\sigma\\)-fields) There are some trivial examples. One is the example where \\({\\mathcal{F}}= \\{\\emptyset,\\Omega\\}\\). It is easy to check that the three conditions are met for this collection of subsets. Another trivial example would be \\({\\mathcal{F}}= {\\mathbb{P}}(\\Omega)\\). The simplest non-trivial example is \\({\\mathcal{F}}= \\left\\{\\emptyset, A, A^C, \\Omega\\right\\}\\) where \\(A \\subset \\Omega\\). Since this collection of subsets is so small, it is easy to check the three conditions mentioned above. Definition 2.2 (Measurable Space) If \\({\\mathcal{F}}\\) is a \\(\\sigma\\)-field on \\(\\Omega\\), then we call \\(\\left(\\Omega, {\\mathcal{F}}\\right)\\) a measurable space. 2.1.1.2 \\(\\sigma\\)-field generated by a collection of subsets Sometimes we are interested in a specific collection of subsets, \\({\\mathcal{C}}\\), that is NOT a \\(\\sigma\\)-field. But since all the machinery we will develop works with \\(\\sigma\\)-fields, we are interested in creating a \\(\\sigma\\)-field that contains \\({\\mathcal{C}}\\). So we introduce the notion of a \\(\\sigma\\)-field generated by a collection of subsets. Definition 2.3 (Generated \\(\\sigma\\)-field) The smallest \\(\\sigma\\)-field containing a collection of subsets, \\({\\mathcal{C}}\\), is called the \\(\\sigma\\)-field generated by \\({\\mathcal{C}}\\). \\(\\sigma\\left({\\mathcal{C}}\\right)\\) is used to denote the \\(\\sigma\\)-field generated by \\({\\mathcal{C}}\\), and is by definition the smallest \\(\\sigma\\)-field that contains \\({\\mathcal{C}}\\): if \\({\\mathcal{F}}\\) is a \\(\\sigma\\)-field with \\({\\mathcal{C}}\\subset {\\mathcal{F}}\\), then \\(\\sigma\\left({\\mathcal{C}}\\right) \\subseteq {\\mathcal{F}}\\). 2.1.1.3 Borel \\(\\sigma\\)-field A particular important \\(\\sigma\\)-field is the Borel \\(\\sigma\\)-field. In general, this is defined as the \\(\\sigma\\)-field generated by the collection of all open subsets of a specific topology. In particular, if we consider \\({\\mathbb{R}}^k\\) is the \\(k\\)-dimensional Euclidean space, \\({\\mathcal{O}} = \\left\\{O \\subseteq {\\mathbb{R}}^k \\left | O\\ \\text{open set} \\right\\}\\right.\\), then \\(\\sigma\\left({\\mathcal{O}}\\right) = {\\mathcal{B}}^k\\) (the Borel \\(\\sigma\\)-field on \\({\\mathbb{R}}^k\\)). It can be shown that the \\(\\sigma\\)-field generated by the collection of all closed sets is also the Borel \\(\\sigma\\)-field. Sometimes it is useful to be able to limit ourselves to a subspace of \\({\\mathbb{R}}^k\\). In such cases, we can create the Borel \\(\\sigma\\)-field on that subspace in the following way: if \\(C \\in {\\mathcal{B}}^k\\), then \\({\\mathcal{B}}_C = \\left\\{ C\\cap B \\left | B \\in {\\mathcal{B}}^k \\right\\}\\right.\\) is the Borel \\(\\sigma\\)-field on \\(C\\). 2.1.1.4 Measures Definition 2.4 (Measure) Let \\(\\left( \\Omega, {\\mathcal{F}}\\right)\\) is a measurable space \\(\\nu: {\\mathcal{F}}\\rightarrow {\\mathbb{R}}\\cup\\{\\infty\\}\\) is said to be a measure if \\(0 \\leq \\nu(A) \\leq \\infty\\) for all \\(A \\in {\\mathcal{F}}\\) \\(\\nu(\\emptyset) = 0\\) If \\(A_i \\in {\\mathcal{F}}\\) for \\(i=1,2,...\\), and \\(A_i \\cap A_j = \\emptyset, \\forall i \\neq j\\) (i.e. \\(A_i\\)’s are pairwise disjoint), then it must hold that \\[\\nu\\left(\\bigcup_{i=1}^\\infty A_i \\right) = \\sum_{i=1}^\\infty \\nu(A_i)\\] Example 2.2 (Counting Measure) The counting measure is simply the measure that returns the number of elements in a set. Example 2.3 (Lebesgue Measure) The measure \\(m: {\\mathbb{R}}\\rightarrow {\\mathbb{R}}\\) satisfying that for all intervals \\([a,b], a &lt; b\\), \\[m([a,b]) = b-a,\\] is called the lebesgue measure. This measure is unique. Definition 2.5 (\\(\\sigma\\)-finite measures) A measure \\(\\nu\\) is called \\(\\sigma\\)-finite if and only if there exists a sequence \\(\\left\\{A_1,A_2,\\ldots\\right\\}\\) such that \\(\\cup A_i = \\Omega\\) and \\(\\nu(A_i) &lt; \\infty, \\forall i\\). Definition 2.6 (Measure Space) If \\(\\nu\\) is a measure on \\({\\mathcal{F}}\\), and \\((\\Omega, {\\mathcal{F}})\\) is a measurable space, then \\((\\Omega, {\\mathcal{F}}, \\nu)\\) is a measure space. Example 2.4 Both the Lebesque measure is \\(\\sigma\\)-finite. The counting measure is \\(\\sigma\\)-finite if and only if \\(\\Omega\\) is countable. Definition 2.7 (Probability Space) If \\((\\Omega, {\\mathcal{F}}, \\nu)\\) is a measurable space with \\(\\nu(\\Omega) = 1\\), then it is called a probability space. Proposition 2.1 (Properties of measures) Let \\((\\Omega, {\\mathcal{F}}, \\nu)\\) be a measure space. Then the following holds: Monotonicity: if \\(A \\subseteq B\\), then \\(\\nu(A) \\leq \\nu(B)\\) Subadditivity: for any sequence, \\(A_1,A_2,\\ldots\\), \\[ \\nu\\left(\\bigcup_{i=1}^\\infty A_i\\right) \\leq \\sum_{i=1}^\\infty \\nu(A_i) \\] Continuity: if \\(A_1 \\subset A_2 \\subset \\dots\\) (or \\(A_1 \\supset A_2 \\supset \\dots\\)), then \\[ \\nu\\left(\\lim_{n\\rightarrow \\infty}A_n\\right) = \\lim_{n\\rightarrow\\infty}\\nu\\left(A_n\\right), \\] where \\[ \\lim_{n\\rightarrow\\infty}A_n = \\bigcup_{i=1}^\\infty A_i \\left(\\text{or} = \\bigcap_{i=1}^\\infty A_i\\right) \\] Definition 2.8 (Cumulative Distribution Function) The cumulative distribution function (c.d.f.) of a measure \\(\\nu\\) is defined as \\[F(x) = \\nu((-\\infty,x]), x\\in{\\mathbb{R}}.\\] There is a one-to-one correpsondence between probability measures on \\(({\\mathbb{R}}, {\\mathcal{B}})\\) and the set of c.d.f.’s. Proposition 2.2 (Properties of c.d.f.’s) i) For a c.d.f, \\({\\mathcal{F}}\\), on \\({\\mathbb{R}}\\), it holds that: a) \\(F(-\\infty) = 0\\) b) \\(F(\\infty) = 1\\) c) \\(x \\leq y \\Rightarrow F(x) \\leq F(y)\\) (non-decreasing) d) \\(\\lim_{y\\rightarrow x^+} F(y) = F(x)\\) (right continuous) ii) If a function \\(F: {\\mathbb{R}}\\rightarrow {\\mathbb{R}}\\) satisfies the four conditions above, it is a c.d.f. of a unique probability measure on \\(({\\mathbb{R}}, {\\mathcal{B}})\\). Proposition 2.3 (The Product Measure Theorem) If \\(\\left(\\Omega_i, {\\mathcal{F}}_i, \\nu_i\\right), i = 1,\\ldots,k\\) are measure spaces with \\(\\sigma\\)-finite measures. Then there exists a unique measure on the \\(\\sigma\\)-field \\(\\sigma({\\mathcal{F}}_1 \\times \\dots {\\mathcal{F}}_k)\\): \\[ \\nu_1 \\times \\dots \\times \\nu_k(A_1 \\times \\dots \\times A_k) = \\nu_1(A_1)\\dots \\nu_k(A_k) \\] for all \\(A_i \\in {\\mathcal{F}}_i, i = 1,\\ldots,k\\). This measure is called the product measure. Definition 2.9 (Joint and Marginal c.d.f.’s) The join c.d.f. of a probability measure on \\(({\\mathbb{R}}^k, {\\mathcal{B}}^k)\\) is defined as \\[ F(x_1,\\ldots, x_k) = P((-\\infty, x_1]\\times \\dots \\times (-\\infty,x_k]), \\quad x_i \\in {\\mathbb{R}}. \\] 2.2 Lecture 2: 9/11 Definition 2.10 (Measurable Function) Let \\((\\Omega, {\\mathcal{F}})\\) and \\((\\Lambda, \\mathcal{G})\\) be measurable spaces. Let \\(f: \\Omega \\rightarrow \\Lambda\\). \\(f\\) is called a measurable function if and only if \\[ f^{-1}(\\mathcal{G}) \\subset {\\mathcal{F}}(\\text{i.e.} f^{-1}(G) \\in {\\mathcal{F}}\\forall G \\in \\mathcal{G}). \\] Note that if \\({\\mathcal{F}}\\) is the collection of all subsets of \\(\\Omega\\), then all functions are measurable. Definition 2.11 (\\(\\sigma\\)-field generated by a function) Let \\(f\\) be as in @ref{measurable-function}. Then \\(f^{-1}(\\mathcal{G})\\) is a sub-\\(\\sigma\\)-field of \\({\\mathcal{F}}\\). We call it the \\(\\sigma\\)-field generated by \\(f\\), and denote it by \\(\\sigma(f)\\). Definition 2.12 (Borel Functions) A function from \\((\\Omega, {\\mathcal{F}})\\) to \\(({\\mathbb{R}}, {\\mathcal{B}})\\) is called a *Borel function$ if it is measurable. Proposition 2.4 (Properties of Borel Functions) Let \\((\\Omega, {\\mathcal{F}})\\) be a measurable space. A function is Borel if and only if \\(f^{-1}(a,\\infty) \\in {\\mathcal{F}}\\) for all \\(a \\in {\\mathbb{R}}\\). If \\(f\\) and \\(g\\) are Borel, then so are \\(fg\\) and \\(af + bg\\), where \\(a,b \\in {\\mathbb{R}}\\). Also, if \\(g(\\omega) \\neq 0\\) for all \\(\\omega \\in \\Omega\\), then \\(f/g\\) is also Borel. If \\(f_1, f_2, \\ldots\\) are all Borel functions, then so are \\(\\sup_n f_n\\), \\(\\inf_n f_n\\), \\(\\lim \\sup_n f_n\\), and \\(\\lim \\inf_n f_n\\). Furthermore, the set \\[ A = \\left\\{ \\omega \\in \\Omega | \\lim_{n \\rightarrow \\infty} f_n(\\omega) \\text{ exists} \\right \\} \\] is an event, and the function \\[ h(\\omega) = \\left\\{ \\begin{array}{ll} \\lim_{n\\rightarrow \\infty} f_n \\omega &amp; \\quad \\omega \\in A \\\\ f_1(\\omega) &amp; \\quad \\omega \\notin A \\end{array} \\right . \\] is borel. Suppose that \\(f\\) is measurable from \\((\\Omega, {\\mathcal{F}})\\) to \\((\\Lambda, \\mathcal{G})\\) and \\(g\\) is measurable from \\((\\Lambda, \\mathcal{G})\\) to \\((\\Delta, \\mathcal{H})\\). Then the composite function \\(g \\circ f\\) is measurable from \\((\\Omega, {\\mathcal{F}})\\) to \\((\\Delta, \\mathcal{H})\\). Let \\(\\Omega\\) be a Borel set in \\({\\mathbb{R}}^p\\). If \\(f\\) is a continuous function from \\(\\Omega\\) to \\({\\mathbb{R}}^q\\), then \\(f\\) is measurable. Proposition 2.5 For any non-negative Borel function \\(f\\) there exists a sequence of non-negative simple functions \\(f_1, f_2, \\ldots\\) such that \\[f_n \\rightarrow f \\text{ for } n \\rightarrow \\infty\\] Definition 2.13 (Distribution) Let \\((\\Omega, {\\mathcal{F}}, \\nu)\\) be a measure space, and \\(f\\) a measurable function from this measure space into the measurable space \\((\\Lambda, \\mathcal{G})\\). The measure defined as \\[ \\nu \\circ f^{-1}(B) = \\nu(f\\in B) = \\nu(f^{-1}(B)), \\quad B \\in \\mathcal{G} \\] is called the induced measure by \\(f\\). If \\(\\nu\\) is a probability measure and \\(f\\) is a random variable (i.e. a Borel function), then \\(\\nu\\circ f^{-1}\\) is called the distribution (or law) of \\(f\\), and is denoted \\(\\nu_f\\). Notice that there are many notations for the same thing. If \\(P\\) is a probability measure and \\(X\\) a random variable, then \\[P_X(B) = P(X \\in B) = P(X^{-1}(B)) = P \\circ X^{-1}.\\] 2.2.1 Integration Definition 2.14 (Simple Function) A function \\(\\phi\\) is called a simple function if it is of the form \\[ \\phi = \\sum_{i=1}^\\infty a_i 1_{A_i}, \\] where \\(A_1, A_2, \\ldots\\) are sets. If \\(a_i \\geq 0\\) for all \\(i \\ge 1\\), then \\(\\phi\\) is a non-negative simple function. Definition 2.15 (Integral of a Non-negative Simple Function) The integral of a non-negative simple function \\(\\phi\\) with respect to a measure \\(\\nu\\) is defined as \\[ \\int \\phi d\\nu = \\sum_{i=1}^k a_i \\nu(A_i). \\] Definition 2.16 (Integral of Non-negative Borel Function) Let \\(f\\) be a non-negative Borel function. Let \\(\\mathcal{S}_f\\) be the collection of ALL non-negative simple function with \\(\\phi(\\omega) \\le f(\\omega), \\forall \\omega \\in \\Omega\\). The integral of \\(f\\) with respect to \\(\\nu\\) is defined as \\[ \\int f d\\nu = \\sup\\left\\{\\int \\phi d\\nu \\left | \\phi \\in \\mathcal{S}_f \\right\\} \\right . . \\] Note: one consequence of this is that for any non-negative Borel function, there exists a sequence of simple functions \\(\\phi_1, \\phi_2, \\ldots\\) such that \\(0 \\leq \\phi_i \\leq f\\) for all i and \\[ \\lim_{n \\rightarrow \\infty} \\int \\phi_n d\\nu = \\int f d\\nu \\] Definition 2.17 (Integral of General Borel Function) Let \\(f\\) be a Borel function, and let \\(f_+(\\omega) = \\max\\{f(\\omega), 0\\}\\) (i.e. the positive part) and \\(f_-(\\omega) = \\max\\{-f(\\omega), 0\\}\\) (i.e. the negative part). If at least one of \\(\\int f_+ d\\nu\\) and \\(\\int f_- d\\nu\\) is finite, we say that \\(\\int f d\\nu\\) exists and \\[ \\int f d\\nu = \\int f_+ d\\nu - \\int f_- d\\nu. \\] Definition 2.18 (Integrable Functions) When \\(\\int f d\\nu &lt; \\infty\\), i.e. the integral of both the positive and negative part of \\(f\\) is finite, we say that \\(f\\) is integrable. Note: as a consequence of the definition of an integrable function we have that a Borel function is integrable if and only if \\(|f|\\) is integrable. (This is true since \\(|f| = f_+ + f_-\\).) Notation: There are many different ways to write down an integral: \\[ \\int f d\\nu = \\int_\\Omega f d\\nu = \\int f(\\omega) d\\nu = \\int f(\\omega) d\\nu(\\omega) = \\int f(\\omega) \\nu(d\\omega), \\] and if \\(F\\) is the c.d.f. (2.8) of a probability measure P on \\(({\\mathbb{R}}^k, {\\mathcal{B}}^k)\\), \\[ \\int f(x) dP = \\int f(x) dF(x) = \\int fdF \\] Proposition 2.6 (Linearity of Integrals) Let \\((\\Omega, {\\mathcal{F}}, \\nu)\\) be a measure space, and \\(f\\) and \\(g\\) be Borel functions. If \\(\\int fd\\nu\\) exists, then for any \\(a \\in {\\mathbb{R}}\\), \\(\\int (af)d\\nu\\) exists, and \\[ \\int (af)d\\nu = a \\int f d\\nu \\] If \\(\\int f d\\nu\\) and \\(\\int g d\\nu\\) both are well defined, then \\(\\int (f+g) d\\nu\\) exists and \\[ \\int (f+g) d\\nu = \\int f d\\nu + \\int g d\\nu \\] Proof. Show that it holds for indicator functions, simple functions, non-negative functions, and then all functions. Definition 2.19 (Almost Everywhere or Almost Surely) A statement is said to be true \\(\\nu\\)-a.e. (or \\(\\nu\\)-a.s.) if it is true for all \\(\\omega \\notin N\\) and \\(\\nu(N) = 0\\). Proposition 2.7 (a.e. for integrals) Let \\((\\Omega, {\\mathcal{F}}, \\nu)\\) be a measure space, and \\(f\\) and \\(g\\) be Borel functions. If \\(f\\leq g\\) \\(\\nu\\)-a.e., then \\(\\int f d\\nu \\le \\int g d\\nu\\), given that both integrals exist If \\(f \\ge 0\\) \\(\\nu\\)-a.e. and \\(\\int f d\\nu = 0\\), then \\(f = 0\\) \\(\\nu\\)-a.e. Proof. ii) Let \\(A = \\{f&gt;0\\}\\) and \\(A_n = \\{f \\ge n^{-1}\\}\\), \\(n=1,2,\\ldots\\). Then \\(A_n \\subset A\\) for any \\(n\\) and \\(\\lim_{n \\rightarrow \\infty} A_n = \\cup A_n = A\\) (show that this holds). Then, by (iii) of 2.1, \\(\\lim_{n \\rightarrow \\infty} \\nu(A_n) = \\nu(A)\\). By part (i) and proposition 2.6, we get that, for any n, \\[\\begin{align*} n^{-1} \\nu(A_n) = \\int n^{-1} I_{A_n} d\\nu \\le \\int f I_{A_n} d\\nu \\le \\int f d\\nu = 0. \\end{align*}\\] 2.2.2 Radon-Nikodym Derivatives 2.3 Lecture 3: 9/13 Proof of Ex 1.11: for any borel set A: if A = (-infty, x), it holds. If not, then… \\(\\pi\\)- and \\(\\lambda\\)-systems. Definition: \\(\\pi\\)-system If \\({\\mathcal{C}}\\) is a collection of subsets, and it holds that \\(A,B \\in {\\mathcal{C}}\\Rightarrow A \\cap B \\in {\\mathcal{C}}\\). For a pi system, \\(\\sigma({\\mathcal{C}}) = {\\mathcal{B}}\\) Proposition 2.8 (Calculus with Radon-Nikodym Derivatives) Let \\(\\nu\\) be a \\(\\sigma\\)-finite measure on a measure space \\((\\Omega, {\\mathcal{F}})\\). All other measures discussed in the following are defined on \\((\\Omega, {\\mathcal{F}})\\). If \\(\\lambda\\) is a meaure, \\(\\lambda &lt;&lt; \\nu\\), and \\(f\\ge 0\\), then \\[\\int f d\\lambda = \\int f \\frac{d\\lambda}{d\\nu}d\\nu.\\] If \\(\\lambda_i\\), \\(i=1,2\\), are measures and \\(\\lambda_i &lt;&lt; \\nu\\), then \\(\\lambda_1 + \\lambda_2 &lt;&lt; \\nu\\) and \\[\\frac{d(\\lambda_1 + \\lambda_2)}{d\\nu} = \\frac{d\\lambda_1}{d\\nu} + \\frac{d\\lambda_2}{d\\nu}\\quad \\nu\\text{-a.e.}\\] If \\(\\tau\\) is a measure, \\(\\lambda\\) a \\(\\sigma\\)-finite measure, and \\(\\tau &lt;&lt; \\lambda &lt;&lt; \\nu\\), then \\[\\frac{d\\tau}{d\\nu} = \\frac{d\\tau}{d\\lambda}\\frac{d\\lambda}{d\\nu}\\quad \\nu\\text{-a.e.}.\\] Let \\((\\Omega_i, {\\mathcal{F}}_i, \\nu_i)\\) be a measure space and \\(\\nu_i\\) be \\(\\sigma\\)-finite, \\(i=1,2\\). Let \\(\\lambda_i\\) be a \\(\\sigma\\)-finite measure on \\((\\Omega_i, {\\mathcal{F}}_i)\\) and \\(\\lambda_1 &lt;&lt; \\nu_i\\), \\(i=1,2\\). Then \\(\\lambda_1 \\times \\lambda_2 &lt;&lt; \\nu_1 \\times \\nu_2\\) and \\[\\frac{d(\\lambda_1 \\times \\lambda_2)}{d(\\nu_1 \\times \\nu_2)}(\\omega_1,\\omega_2) = \\frac{d\\lambda_1}{d\\nu_1}(\\omega_1)\\frac{d\\lambda_2}{d\\nu_2}(\\omega_2)\\quad \\nu_1\\times \\nu_2\\text{-a.e.}\\]. "],
["discussion-notes.html", "Chapter 3 Discussion Notes 3.1 Discussion 1: 5/14", " Chapter 3 Discussion Notes 3.1 Discussion 1: 5/14 3.1.1 \\(\\sigma\\)-fields Exercise 3.1 (Countable intersection/union of \\(\\sigma\\)-fields) Let \\({\\mathcal{F}}_n, n=1,2,\\ldots\\) be a sequance of \\(\\sigma\\)-fields on \\(\\Omega\\). Show the following: \\(\\cap_{i=1}^\\infty {\\mathcal{F}}_n\\) is a \\(\\sigma\\)-field. If \\({\\mathcal{F}}_1 \\subset {\\mathcal{F}}_2 \\subset \\dots\\), then \\(\\cup_{i=1}^\\infty {\\mathcal{F}}_n\\) is not necessarily a \\(\\sigma\\)-field. Solution (3.1 a)). We need to show (i)-(iii) from definition 2.1. Since \\({\\mathcal{F}}_n\\) are all \\(\\sigma\\)-fields, \\(\\emptyset \\in {\\mathcal{F}}_n\\) for all \\(n=1,2,\\ldots\\). Hence, \\(\\emptyset \\in \\cap_{i=1}^{\\infty} {\\mathcal{F}}_n\\). As (i). Let \\(\\{A_i\\}_{i=1}^\\infty\\) be a sequence of subsets from \\(\\cap_{i=1}^{\\infty} {\\mathcal{F}}_n\\). Then, for all \\(i\\), \\(A_i \\in {\\mathcal{F}}_n\\) for all \\(n\\). Since \\(F_n\\) is a \\(\\sigma\\)-field, \\(\\cup_{i=1}^\\infty A_i \\in {\\mathcal{F}}_n\\) for all \\(n\\), and so \\(\\cup_{i=1}^\\infty A_i \\in \\cap_{i=1}^\\infty {\\mathcal{F}}_n\\). Hence, \\(\\cap_{i=1}^\\infty {\\mathcal{F}}_n\\) is a \\(\\sigma\\)-field. Solution (3.1 b)). Let \\(\\Omega = [0,1]\\), and \\({\\mathcal{F}}_n = \\sigma \\left\\{[0,\\tfrac{1}{2^n}),[\\tfrac{1}{2^n},\\tfrac{2}{2^n}), \\ldots, [\\tfrac{2^{n-1}}{2^n}, 1)\\right\\}\\). Now, consider the set \\(B_n = [0, \\tfrac{1}{2^n})\\). Clearly \\(B_n \\in {\\mathcal{F}}_n\\) for all \\(n\\), hence \\(B_n \\in \\cup_{i=1}^\\infty {\\mathcal{F}}_n\\). Hower, \\(\\cap_{i = 1}^{\\infty} B_n = \\{0\\} \\notin \\cup_{i=1}^\\infty {\\mathcal{F}}_n\\). So \\(\\cup_{i=1}^\\infty {\\mathcal{F}}_n\\) is not closed under countable intersection, i.e. it is not a \\(\\sigma\\)-algebra. 3.1.2 \\(\\pi-\\lambda\\) systems Definition 3.1 (\\(\\pi\\)-system) Let \\(\\mathcal{D}\\) be a collection of subsets of \\(\\Omega\\). \\(\\mathcal{D}\\) is said to be a \\(\\pi\\)-system if it is closed under intersection, i.e. if \\[ A,B \\in \\mathcal{D} \\Rightarrow A \\cap B \\in \\mathcal{D}. \\] Definition 3.2 (\\(\\lambda\\)-system) Let \\(\\mathcal{L}\\) be a collection of subsets of \\(\\Omega\\). \\(\\mathcal{L}\\) is said to be a \\(\\lambda\\)-system if it satisfies that \\(\\Omega \\in \\mathcal{L}\\), If \\(A,B \\in \\Omega\\) with \\(A \\subset B\\), then \\(B\\setminus A \\in \\Omega\\) If \\(A_n \\in \\mathcal{L}\\) and \\(A_n \\subset A_{n+1}\\) for all \\(n\\), then \\[ \\cup_{i=1}^{\\infty} A_n \\in \\mathcal{L} \\] Theorem 3.1 (\\(\\pi-\\lambda\\) Theorem) If \\(\\mathcal{D}\\) is a \\(\\pi\\)-system and \\(\\mathcal{L}\\) is a \\(\\lambda\\)-system s.t. \\(\\mathcal{D} \\subset \\mathcal{L}\\), the \\(\\sigma\\{\\mathcal(D)\\} \\subset \\mathcal{L}\\). Exercise 3.2 (Proof of the \\(\\pi-\\lambda\\) Theorem) Solution. Proof hints: If \\(\\mathcal{L}_t\\) is \\(\\lambda\\)-system for all \\(t \\in I\\), \\(\\mathcal{D} \\subset \\mathcal{L}_t\\), then \\(\\cap_{t \\in I} \\mathcal{L}_t\\) is a \\(\\lambda\\)-system. Denote this \\(\\mathcal{L}(\\mathcal{D})\\) (smallest \\(\\lambda\\)-system containing \\(\\mathcal{D}\\)). If \\(\\mathcal{L}\\) is a \\(\\pi\\)-system AND a \\(\\lambda\\)-system, then \\(\\mathcal{L}\\) is a \\(\\sigma\\)-field. If \\(\\mathcal{D}\\) is \\(\\pi\\)-system, then \\(\\mathcal{L}(\\mathcal{D})\\) is \\(\\pi\\)-system. By 1)-3), \\(\\mathcal{L} = \\sigma(\\mathcal{D})\\), which implies … 3.1.3 The “Good Sets” Principle Exercise 3.3 Let \\(\\mathcal{P}\\) be a \\(\\pi\\)-system, and \\(\\nu_1\\) and \\(\\nu_2\\) two measures that agree on \\(\\mathcal{P}\\), i.e. \\[ \\nu_1(A) = \\nu_2(A) \\text{ for all } A \\in \\mathcal{P}. \\] Assume there is a sequence of sets \\(A_n \\in \\mathcal{P}\\) with \\(A_n \\uparrow \\Omega\\) and \\(\\nu_i(A_n) &lt; \\infty\\) for all \\(n\\). Use the \\(\\pi-\\lambda\\) theorem to prove that \\(\\nu_1\\) and \\(\\nu_2\\) agree on \\(\\sigma(\\mathcal{P})\\). Solution. Let \\({\\mathcal{F}}_n\\) be given by \\[ {\\mathcal{F}}_n = \\left \\{A \\in \\sigma(\\mathcal{P}) \\left | \\nu_1(A \\cap A_n) = \\nu_2(A \\cap A_n) \\forall n \\right \\} \\right . \\] Let \\(A \\in \\mathcal{P}\\). Since \\(A_n \\in \\mathcal{P}\\) for all \\(n\\) and \\(\\mathcal{P}\\) is a \\(\\pi\\)-system, \\(A \\cap A_n \\in \\mathcal{P}\\). So \\(\\nu_1(A \\cap A_n) = \\nu_2(A \\cap A_n)\\), hence \\(\\mathcal{P} \\subset {\\mathcal{F}}_n\\). By definition, \\({\\mathcal{F}}_n \\subset \\sigma(\\mathcal{P})\\), so \\(\\mathcal{P} \\subset {\\mathcal{F}}_n \\subset \\sigma(\\mathcal{P})\\). Now, if we can prove that \\({\\mathcal{F}}_n\\) is a \\(\\lambda\\)-system for all \\(n\\), then by the \\(\\pi-\\lambda\\) theorem (theorem 3.1), we have that \\(\\sigma(\\mathcal{P}) \\subset {\\mathcal{F}}_n\\), which combined with the paragraph above gives us that \\(\\sigma(\\mathcal{P}) = {\\mathcal{F}}_n\\), hence \\(\\nu_1\\) and \\(\\nu_2\\) agree on \\(\\sigma(\\mathcal{P})\\). So let us show that \\({\\mathcal{F}}_n\\) is indeed a \\(\\lambda\\)-system: \\(\\Omega \\in {\\mathcal{F}}_n\\). Since \\(A_n \\uparrow \\Omega\\), we can use continuity of measure (proposition 2.1) to conclude that \\[\\begin{align*} \\lim_{n \\rightarrow \\infty} \\nu_i(A_n) &amp;= \\nu_i(\\lim_{n \\rightarrow \\infty} A_n) \\\\ &amp;= \\nu_i(\\Omega). \\end{align*}\\] Since \\(\\nu_1(A_n) = \\nu_2(A_n)\\) (\\(A_n \\in \\mathcal{P}\\)), it holds that \\(\\nu_1(\\Omega) = \\nu_2(\\Omega)\\), so \\(\\Omega \\in {\\mathbb{P}}\\subset {\\mathcal{F}}_n\\). Let \\(A,B \\in {\\mathcal{F}}_n\\) with \\(A \\subset B\\). So, \\[\\begin{align*} \\nu_1((A\\setminus B) \\cap A_n) &amp;= \\nu_1(A\\cap A_n) - \\nu_1(B\\cap A_n) \\\\ &amp;= \\nu_2(A\\cap A_n) - \\nu_2(B\\cap A_n) \\\\ &amp;= \\nu_2((A\\setminus B) \\cap A_n), \\end{align*}\\] which means that \\(A\\setminus B \\in {\\mathcal{F}}_n\\). Let \\(B_i \\in {\\mathcal{F}}_n\\) s.t. \\(B_i \\subset B_{i+1}\\). Then, once again using continuity of measures to move limits around, we have \\[\\begin{align} \\nu_1\\left(\\cup_{i=1}^\\infty B_i \\cap A_n \\right) &amp;= \\nu_1\\left(\\cup_{i=1}^\\infty (B_i \\cap A_n) \\right) \\\\ &amp;= \\lim_{i \\rightarrow \\infty} \\nu_1(B_i \\cap A_n) \\\\ &amp;= \\lim_{i \\rightarrow \\infty} \\nu_2(B_i \\cap A_n) \\\\ &amp;= \\nu_2\\left(\\cup_{i=1}^\\infty (B_i \\cap A_n) \\right) \\\\ &amp;= \\nu_2\\left(\\cup_{i=1}^\\infty B_i \\cap A_n \\right), \\end{align}\\] which gives us that \\(\\cup_{i = 1}^\\infty B_i \\in {\\mathcal{F}}_n\\), hence \\({\\mathcal{F}}_n\\) is a \\(\\lambda\\)-system. 3.1.4 From Indicator Function to General (Borel) Function When we deine the Lebesgue integral, we define it in three steps. First for indicator functions, which in turn is generalized to simple non-negative functions (i.e. linear combinations of indicator functions). Second for any non-negative functions (which is done by utilizing that any such function can be described as the limit of a sequence of simple functions) A general function (by separating the positive and negative parts) Exercise 3.4 Let \\(\\Omega = \\left\\{\\omega_1, \\omega_2, \\ldots \\right\\}\\) be a countable set, \\({\\mathcal{F}}\\) all subsets of \\(\\Omega\\), and \\(\\nu\\) the counting measure on \\(\\Omega\\). Show that for any Borel function \\(f\\), the integral of \\(f\\) with respect to \\(\\nu\\) is \\[\\begin{equation} \\int f d\\nu = \\sum_{i=1}^\\infty f(\\omega_i) \\tag{3.1} \\end{equation}\\] Solution. Let \\(A \\in {\\mathcal{F}}\\) and define \\(f = 1_A\\). Then \\[\\begin{align*} \\int f d\\nu &amp;= \\int_A d\\nu \\\\ &amp;= \\nu(A) \\\\ &amp;= \\sum_{i=1}^\\infty 1_A(\\omega_i) \\end{align*}\\] I.e. (3.1) holds for indicator functions, and hence also for simple functions. Now, let \\(f\\) be a non-negative Borel function. Then we know that there exists a sequence \\((f_n)_i^{\\infty}\\) of simple functions such that \\(f_n \\uparrow f\\). Then \\[\\begin{align*} \\int f d\\nu &amp;= \\int \\lim_{n \\rightarrow \\infty} f_n d\\nu \\\\ &amp;= \\lim_{n\\rightarrow \\infty} \\int f_n d\\nu. \\end{align*}\\] Since \\(f_n\\) is a simple function, we know that @ref{eq:ex14} holds. Hence, \\[\\begin{align*} \\int f d\\nu &amp;= \\lim_{n \\rightarrow \\infty} \\sum_{i=1}^\\infty f_n(\\omega_i) \\\\ &amp;= \\sum_{i=1}^\\infty \\lim_{n \\rightarrow \\infty} f_n(\\omega_i) \\\\ &amp;= \\sum_{i=1}^\\infty f(\\omega_i), \\end{align*}\\] and so @ref{eq:ex14} holds for non-negative Borel functions. Finally, let \\(f\\) be any Borel function. Then we can write \\(f = f_+ - f_-\\), where \\(f_+ = \\max(f,0)\\) and \\(f_- = \\max(-f, 0)\\). Then both \\(f_+\\) and \\(f_-\\) are non-negative Borel functions, hence @ref{eq:ex14} holds for both. So \\[\\begin{align*} \\int f d\\nu &amp;= \\int f_+ d\\nu - \\int f_- d\\nu \\\\ &amp;= \\sum_{i=1}^\\infty f_+(\\omega_i) - \\sum_{i=1}^\\infty f_-(\\omega_i) \\\\ &amp;= \\sum_{i=1}^\\infty f_+(\\omega_i) - f_-(\\omega_i) \\\\ &amp;= \\sum_{i=1}^\\infty f(\\omega_i). \\end{align*}\\] So (3.1) holds for all Borel functions. 3.1.5 Switch the Order of Integration and Limit Exercise 3.5 (Generalized Dominated Convergence Theorem) If \\(\\lim f_n = f\\) and there exists a sequence of integrable functions \\(g_1, g_2, g_3, \\ldots\\) such that \\(|f_n| \\leq g_n\\) a.e. \\(g_n \\rightarrow g\\) a.e. \\(\\lim_{n \\rightarrow \\infty} \\int g_n d\\nu = \\int g d\\nu\\) then \\[\\begin{equation} \\int \\lim_{n \\rightarrow \\infty} f_n d\\nu = \\lim_{n \\rightarrow \\infty} \\int f_n d\\nu \\tag{3.2} \\end{equation}\\] "],
["homework.html", "Chapter 4 Homework 4.1 First Exam Period", " Chapter 4 Homework 4.1 First Exam Period 4.1.1 Assigned Problems NOTE: This homework submission is for both Ralph Trane and Alex Hayes. For almost all of the problems here, we worked together on a whiteboard. We then took pictures or handwritten notes of the solutions and wrote them up here. Exercise 4.1 (Ex 2) Let \\({\\mathcal{C}}\\) be a collection of subsets of \\(\\Omega\\) and let \\(\\Gamma = \\{ {\\mathcal{F}}| {\\mathcal{F}}\\text{ is a } \\sigma \\text{-field on } \\Omega \\text{ and } {\\mathcal{C}}\\subset {\\mathcal{F}}\\}\\). Show that \\(\\Gamma \\neq \\emptyset\\) and \\(\\sigma({\\mathcal{C}}) = \\cap_{{\\mathcal{F}}\\in \\Gamma} {\\mathcal{F}}\\). Solution (Ex 2). Let \\({\\mathbb{P}}(\\Omega)\\) be the collection of all subsets of \\(\\Omega\\). We know that this is a \\(\\sigma\\)-field. It also contains \\({\\mathcal{C}}\\). Hence, \\(\\Gamma \\neq \\emptyset\\). By definition, \\(\\sigma({\\mathcal{C}})\\) is the smallest \\(\\sigma\\)-field that contains \\({\\mathcal{C}}\\), hence \\(\\sigma({\\mathcal{C}}) \\in \\Gamma\\) and \\(\\sigma({\\mathcal{C}}) \\subset {\\mathcal{F}}\\) for all \\({\\mathcal{F}}\\in \\Gamma\\). Therefore, \\(\\sigma({\\mathcal{C}}) \\subset \\cap_{{\\mathcal{F}}\\in \\Gamma} {\\mathcal{F}}\\). But since \\(\\sigma({\\mathcal{C}}) \\in \\Gamma\\), \\(\\sigma({\\mathcal{C}}) \\in \\cap_{{\\mathcal{F}}\\in \\Gamma} {\\mathcal{F}}\\), which in turn ensures that \\(\\cap_{{\\mathcal{F}}\\in \\Gamma} {\\mathcal{F}}\\subset \\sigma({\\mathcal{C}})\\). Hence \\(\\sigma({\\mathcal{C}}) = \\cap_{{\\mathcal{F}}\\in \\Gamma} {\\mathcal{F}}\\). Exercise 4.2 (Ex 5) a) Let \\({\\mathcal{C}}\\) be a \\(\\pi\\)-system and \\(\\mathcal{D}\\) be a \\(\\lambda\\)-system such that \\({\\mathcal{C}}\\subset \\mathcal{D}\\). Show that \\(\\sigma({\\mathcal{C}}) \\subset \\mathcal{D}\\). Solution (Ex 5). TODO Exercise 4.3 (Ex 12) Let \\(\\nu\\) and \\(\\lambda\\) be two measures on \\((\\Omega, {\\mathcal{F}})\\) such that \\(\\nu(A) = \\lambda(A)\\) for any \\(A \\in {\\mathcal{C}}\\subset {\\mathcal{F}}\\), where \\({\\mathcal{C}}\\) is a \\(\\pi\\)-system (3.1). Assume that \\(\\nu\\) is \\(\\sigma\\)-finite (2.5). Show that \\(\\nu(A) = \\lambda(A)\\) for all \\(A \\in \\sigma({\\mathcal{C}})\\). Solution (Ex 12). Let \\({\\mathcal{F}}= \\{A \\in \\sigma({\\mathcal{C}}) | \\nu(A) = \\lambda(A)\\}\\). Then \\({\\mathcal{C}}\\subset {\\mathcal{F}}\\). If we can show that \\({\\mathcal{F}}\\) is a \\(\\sigma\\)-field, then \\(\\sigma({\\mathcal{C}}) \\subset {\\mathcal{F}}\\) (since \\(\\sigma({\\mathcal{C}})\\) is the smallest \\(\\sigma\\)-field that contains \\({\\mathcal{C}}\\)), which proves that \\(\\nu(A) = \\lambda(A)\\) for all \\(A \\in \\sigma({\\mathcal{C}})\\). Exercise 4.4 (Ex 14) Prove proposition 1.4 (proposition 2.4) Solution (Ex 14 (i)). Assume \\(f\\) is Borel. Then \\(f^{-1}(A) \\in {\\mathcal{F}}\\) for all open sets \\(A \\in {\\mathcal{B}}\\), hence \\(f^{-1}(a, \\infty) \\in {\\mathcal{F}}\\). Now assume \\(f^{-1}(a, \\infty) \\in {\\mathcal{F}}\\) for all \\(a \\in {\\mathbb{R}}\\), and let \\(\\mathcal{G} = \\{ A \\in {\\mathcal{B}}| f^{-1}(A) \\in {\\mathcal{F}}\\}\\). So, \\((a, \\infty) \\in \\mathcal{G}\\) for all \\(a \\in {\\mathbb{R}}\\). If we can show that \\(\\mathcal{G}\\) is a \\(\\sigma\\)-field, then we will have that \\(\\sigma((a, \\infty)) = {\\mathcal{B}}\\subset \\mathcal{G}\\), hence \\(f^{-1}(B) \\in {\\mathcal{F}}\\) for all \\(B \\in {\\mathcal{B}}\\), meaning that \\(f\\) is measurable. So let us prove that \\(\\mathcal{G}\\) is a \\(\\sigma\\)-field. First of all, \\(f^{-1}(\\emptyset) = \\emptyset \\in {\\mathcal{F}}\\). Second, let \\(A \\in \\mathcal{G}\\). Since \\(f^{-1}(A^C) = (f^{-1}(A))^C \\in {\\mathcal{F}}\\) (\\({\\mathcal{F}}\\) is a \\(\\sigma\\)-field and \\(f^{-1}(A) \\in {\\mathcal{F}}\\), so \\((f^{-1}(A))(^C) \\in {\\mathcal{F}}\\)). Finally, let \\(A_1, A_2, \\ldots\\) be a sequence of sets such that \\(A_i \\in \\mathcal{G}\\) for all \\(i\\). Then \\(f^{-1}\\left(\\cup_{i=1}^\\infty A_i \\right) = \\cup_{i=1}^\\infty f^{-1}(A_i)\\). Since \\(f^{-1}(A_i) \\in {\\mathcal{F}}\\) for all \\(i\\) and \\({\\mathcal{F}}\\) is a \\(\\sigma\\)-field, \\(\\cup_{i=1}^\\infty f^{-1}(A_i) \\in {\\mathcal{F}}\\), so \\(\\cup_{i=1}^\\infty A_i \\in \\mathcal{G}\\). So \\(\\mathcal{G}\\) is a \\(\\sigma\\)-field, which concludes the proof. Solution (Ex 14 (ii)). Assume \\(f\\) and \\(g\\) are Borel functions. Let \\(a,b \\in {\\mathbb{R}}\\). \\(af\\) is Borel, since \\[ (af)^{-1}((c,\\infty)) = \\left\\{ \\omega \\in \\Omega : a\\cdot f(\\omega) \\in (c, \\infty) \\right\\}. \\] If \\(a \\neq 0\\), \\[\\begin{aligned} (af)^{-1}((c,\\infty)) &amp;= \\left\\{ \\omega \\in \\Omega : f(\\omega) \\in (\\tfrac{c}{a}, \\infty) \\right\\} \\\\ &amp;= f^{-1}(\\tfrac{c}{a}, \\infty). \\end{aligned}\\] Since \\(f\\) is Borel, this is a measurable set (by (i)). If \\(a = 0\\), then \\[(af)^{-1}((c,\\infty)) = \\left\\{ \\begin{matrix} \\Omega &amp; \\text{ if } c \\le 0 \\\\ \\emptyset &amp; \\text{ if } c &lt; 0 \\end{matrix} \\right . \\] In either case, \\((af)^{-1}((c, \\infty)) \\in {\\mathcal{F}}\\). Since it holds that for all \\(a,c \\in {\\mathbb{R}}\\) that \\((af)^{-1}((c,\\infty)) \\in {\\mathcal{F}}\\), \\(af\\) is measurable by (i). Let \\(c \\in {\\mathbb{R}}\\). Now consider the sum of \\(f\\) and \\(g\\): \\[\\begin{aligned} (f + g)^{-1}((c, \\infty)) &amp;= \\left\\{ \\omega \\in \\Omega : f(\\omega) + g(\\omega) &gt; c \\right\\} \\\\. &amp;= \\cup_{t \\in {\\mathbb{Q}}} \\{\\omega \\in \\Omega : f(\\omega) &gt; c - t \\} \\cap \\{\\omega \\in \\Omega : g(\\omega) &gt; t \\} \\\\ &amp;= \\cup_{t \\in {\\mathbb{Q}}} f^{-1}((c-t, \\infty)) \\cap g^{-1}((t, \\infty)). \\end{aligned}\\] Since \\(f\\) and \\(g\\) are both measurable, \\(f^{-1}((c-t, \\infty)) \\in {\\mathcal{F}}\\) and \\(g^{-1}((t, \\infty))\\in {\\mathcal{F}}\\) for all \\(t \\in {\\mathbb{R}}\\). Hence, the intersection of the two is measurable for any \\(t \\in {\\mathbb{R}}\\), which in turn implies that the union over all rational numbers is measurable (countable union of measurable sets). Hence, \\(f+g\\) is measurable. Combine the two results to get the final result.1 Solution (Ex 14 (iii)). TODO Solution (Ex 14 (iv)). Assume \\(f\\) is measurable from \\((\\Omega, {\\mathcal{F}})\\) to \\((\\Lambda, \\mathcal{G})\\), and \\(g\\) measureable from \\((\\Lambda, \\mathcal{G})\\) to \\((\\Delta, \\mathcal{H})\\). Let \\(H \\in \\mathcal{H}\\). We want to show that \\((g \\circ f)^{-1}(H) \\in {\\mathcal{F}}\\), since this would mean \\(g \\circ f\\) is measurable. So, \\[\\begin{aligned} (g \\circ f)^{-1}(H) &amp;= \\left\\{ \\omega \\in \\Omega | g(f(\\omega)) \\in H \\right\\} \\\\ &amp;= \\left\\{ \\omega \\in \\Omega | f(\\omega) \\in g^{-1}(H) \\right\\} \\\\ &amp;= f^{-1}(g^{-1}(H)). \\end{aligned}\\] Since \\(g\\) is measurable, \\(g^{-1}(H) \\in \\mathcal{G}\\), and since \\(f\\) is measurable, \\(f^{-1}(g^{-1}(H)) \\in {\\mathcal{F}}\\). So, \\(g \\circ f\\) is measurable. Solution (Ex 14 (v)). Let \\(f: \\Omega \\to {\\mathbb{R}}^p\\), where \\(\\Omega\\) is a borel set. Assume \\(f\\) is continuous. Then, if \\(A\\) is an open set, \\(f^{-1}(A)\\) is an open set, and therefore borel. Hence, \\(f^{-1}((a,\\infty))\\) is a borel set for all \\(a\\), and by \\((i)\\) we have that \\(f\\) is a borel function. Exercise 4.5 (Ex 19) Let \\(\\{f_n\\}\\) be a sequence of Borel functions on a measurable space. Show that \\(\\sigma(f_1, f_2, \\ldots) = \\sigma(\\cup_{j=1}^{\\infty} \\sigma(f_j)) = \\sigma(\\cup_{j=1}^\\infty \\sigma(f_1,\\ldots, f_j)).\\) \\(\\sigma(\\lim \\sup_n f_n) \\subset \\cap_{n=1}^\\infty \\sigma(f_n, f_{n+1},\\ldots).\\) Solution (Ex 19). TODO Exercise 4.6 (Ex 24) Let \\(f\\) be an integrable function on \\((\\Omega, {\\mathcal{F}}, \\nu)\\). Show that for each \\(\\epsilon &gt; 0\\), there exists a \\(\\delta_\\epsilon\\) such that for \\(A \\in {\\mathcal{F}}\\): \\[ \\nu(A) &lt; \\delta_\\epsilon \\to \\int_A |f| d\\nu &lt; \\epsilon. \\] Solution. Let \\(\\epsilon &gt; 0\\), \\(A \\in {\\mathcal{F}}\\) with \\(\\nu(A) &lt; \\delta_\\epsilon = \\frac{\\epsilon}{\\sup_{\\omega \\in A} |f(\\omega)|}\\). Then \\[\\begin{align*} \\int_A |f| d\\nu &amp;\\leq \\int_A \\sup_{\\omega \\in A} |f(\\omega)| d\\nu \\\\ &amp;= \\sup_{\\omega \\in A} |f(\\omega)| \\nu(A) \\\\ &amp;&lt; \\epsilon. \\end{align*}\\] Exercise 4.7 (Ex 30) For any c.d.f. \\(F\\) and any \\(a \\ge 0\\), show that \\(\\int [F(x+a) - F(x)] dx = a\\) Solution. Note that \\(F(X) = \\int 1_{-\\infty, x} dP\\). Then \\[ \\begin{aligned} \\int [F(x+a) - F(x)] dx &amp;= \\int_{\\mathbb{R}}\\left(\\int 1_{-\\infty, x + a} dP \\right) - \\left(\\int 1_{-\\infty, x} dP \\right) dx\\\\ &amp;= \\int_{\\mathbb{R}}\\int 1_{x, x + a} dx \\\\ &amp;= a \\end{aligned} \\] Exercise 4.8 (Ex 34) Prove proposition 2.8 Solution (Ex 34 i)). Let \\(g\\) be the unique function denoted by \\(\\frac{d\\lambda}{d\\nu}\\). Assume \\(f = 1_A\\) for some \\(A\\in {\\mathcal{F}}\\). Since \\(\\lambda &lt;&lt; \\nu\\), we know that \\(\\lambda(A) = \\int_A g d\\nu\\). So, \\[\\begin{align*} \\int f d\\lambda &amp;= \\int 1_A d\\lambda \\\\ &amp;= \\lambda(A) \\\\ &amp;= \\int_A g d\\nu \\\\ &amp;= \\int 1_A g d\\nu = \\int f g d\\nu. \\end{align*}\\] Hence, (i) is true for all indicator functions, and so by linearity of integrals (2.6) for all non-negative simple functions. Now, let \\(f\\) be a general non-negative Borel function. Then we know that there exists a sequence of simple functions \\(\\phi_1, \\phi_2, \\ldots\\) such that \\(\\phi_n \\uparrow f\\). Hence, utilizing the monotone convergence theorem and the fact that we know (i) holds for simple functions, \\[\\begin{align*} \\int f d\\lambda &amp;= \\int \\lim_{n \\to \\infty} \\phi_n d\\lambda \\\\ &amp;= \\lim_{n \\to \\infty} \\int \\phi_n d\\lambda \\\\ &amp;= \\lim_{n \\to \\infty} \\int \\phi_n g d\\nu \\\\ &amp;= \\int \\lim_{n \\to \\infty} \\phi_n g d\\nu \\\\ &amp;= \\int f g d\\nu, \\end{align*}\\] and so we have shown that (i) holds for any non-negative Borel function. Solution (Ex 34 ii)). Assume \\(\\lambda_1 &lt;&lt; \\nu\\) and \\(\\lambda_2 &lt;&lt; \\nu\\). Then \\[\\begin{align*} (\\lambda_1 + \\lambda_2)(A) &amp;= \\lambda_1(A) + \\lambda_2(A) \\\\ &amp;= \\int_A g_1 d\\nu + \\int_A g_2 d\\nu \\\\ &amp;= \\int_A (g_1 + g_2)d\\nu, \\end{align*}\\] so \\(\\lambda_1 + \\lambda_2 &lt;&lt; \\nu\\), and \\[\\frac{d(\\lambda_1 + \\lambda_2)}{d\\nu} = g_1 + g_2 = \\frac{d\\lambda_1}{d\\nu} + \\frac{d\\lambda_2}{d\\nu}.\\] Solution (Ex 34 iii)). Since \\(\\tau &lt;&lt; \\lambda\\), \\[\\tau(A) = \\int_A \\frac{d\\tau}{d\\lambda}d\\lambda.\\] Since \\(\\lambda &lt;&lt; \\nu\\), we can use (i) with \\(f = \\frac{d\\tau}{d\\lambda}\\), to get \\[\\tau(A) = \\int_A \\frac{d\\tau}{d\\lambda}\\frac{d\\lambda}{d\\tau} d\\tau,\\] which tells us that \\(\\tau &lt;&lt; \\nu\\) and \\[\\frac{d\\tau}{d\\nu} = \\frac{d\\tau}{d\\lambda}\\frac{d\\lambda}{d\\tau}.\\] Solution (Ex 34 iv)). By definition, \\((\\lambda_1 \\times \\lambda_2)(A) = \\int_A d(\\lambda_1 \\times \\lambda_2) = \\int 1_A d(\\lambda_1 \\times \\lambda_2)\\). Since \\(1_A \\ge 0\\), we can use Fubini to get \\[ (\\lambda_1 \\times \\lambda_2)(A) = \\int \\int 1_A d\\lambda_1 d\\lambda_2. \\] Since \\(\\lambda_1 &lt;&lt; \\nu_1\\), we can use (i) with \\(f = 1_A\\) (\\(1_A\\) is non-negative) to obtain that \\[(\\lambda_1 \\times \\lambda_2)(A) = \\int \\int 1_A \\frac{d\\lambda_1}{d\\nu_1}d\\nu_1 d\\lambda_2,\\] and then, since \\(\\lambda_2 &lt;&lt; \\nu_2\\), using (i) again with \\(f = \\int 1_A \\frac{d\\lambda_1}{d\\nu_1}d\\nu_1\\) (which is non-negative) to get \\[(\\lambda_1 \\times \\lambda_2)(A) = \\int \\int 1_A \\frac{d\\lambda_1}{d\\nu_1}d\\nu_1 \\frac{d\\lambda_2}{d\\nu_2}d\\nu_2.\\] Finally, using Fubini again we get \\[\\begin{aligned} (\\lambda_1 \\times \\lambda_2)(A) &amp;= \\int \\int 1_A \\frac{d\\lambda_1}{d\\nu_1}\\frac{d\\lambda_2}{d\\nu_2} d\\nu_1 d\\nu_2 \\\\ &amp;= \\int_A \\frac{d\\lambda_1}{d\\nu_1}\\frac{d\\lambda_2}{d\\nu_2} d(\\nu_1\\times\\nu_2). \\end{aligned}\\] I.e. \\(\\lambda_1 \\times \\lambda_2 &lt;&lt; \\nu_1 \\times \\nu_2\\) and \\(\\frac{d(\\lambda_1 \\times \\lambda_2)}{d(\\nu_1 \\times \\nu_2)} = \\frac{d\\lambda_1}{d\\nu_1}\\frac{d\\lambda_2}{d\\nu_2}\\). Exercise 4.9 (Ex 35) Let \\(\\{a_n\\}\\) be a sequence of positive numbser with \\(\\sum_{i=1}^\\infty a_n = 1\\), and \\(\\{P_n\\}\\) a sequence of probability measure on a common measurable space, \\((\\Omega, {\\mathcal{F}})\\). Define \\(P = \\sum_{n=1}^\\infty P_n\\). Show that \\(P\\) is a probability measure. Let \\(\\nu\\) be a \\(\\sigma\\)-finite measure. Show that \\[P_n &lt;&lt; \\nu \\text{ for all } n \\in {\\mathbb{N}}\\quad \\iff \\quad P &lt;&lt; \\nu.\\] Derive the Lebesgue p.d.f. of \\(P\\) when \\(P_n\\) is the gamma distribution \\(\\Gamma(\\alpha, n^{-1})\\) with \\(\\alpha &gt; 1\\) and \\(a_n \\propto n^{-\\alpha}\\). Solution (Ex 35 a)). Need to show that \\(P = \\sum_{n=1}^{\\infty} a_n P_n\\) is a probability measure. So we check the three properties for a probability measure (2.4), with the extra property that \\(P(\\Omega) = 1\\): \\(P(A) = \\sum_{n=1}^\\infty a_n P_n(A) \\geq 0\\) for all \\(A\\) since \\(a_n &gt; 0\\) for all \\(n\\) by assumption, and \\(P_n(A) \\ge 0\\) for all \\(n\\), since \\(P_n\\) is a probability measure. Furthermore, \\(P(\\Omega) = \\sum_{n=1}^\\infty a_n P_n(\\Omega) = \\sum_{n=1}^\\infty a_n = 1\\), where the second equality holds since \\(P_n\\) is a probability measure (by assumption), and the last equality is exactly the assumption we made about the \\(a_n\\)s. I.e. \\(0 \\le P(A) \\le 1\\). Since \\(P_n(\\emptyset) = 0\\), \\(P(\\emptyset) = \\sum_{n=1}^\\infty a_n P_n(\\emptyset) = 0\\). Let \\(A_1, A_2,\\ldots\\) be a countable sequence of pairwise disjoint sets. Then using that \\(P_n\\) is a measure for all \\(n\\), \\[\\begin{aligned} P(\\cup_{i=1}^\\infty A_i) &amp;= \\sum_{n=1}^\\infty a_nP_n\\left(\\cup_{i=1}^\\infty A_i\\right) \\\\ &amp;= \\sum_{n=1}^\\infty a_n\\sum_{i=1}^\\infty P_n(A_i) \\\\ &amp;= \\sum_{i=1}^\\infty \\sum_{n=1}^\\infty a_n P_n(A_i) \\\\ &amp;= \\sum_{i=1}^\\infty P(A_i). \\end{aligned}\\] Solution (Ex 35 b)). Assume \\(P &lt;&lt; \\nu\\). Let \\(A \\in {\\mathcal{F}}\\) with \\(\\nu(A) = 0\\). Assume there exists \\(n \\in {\\mathbb{N}}\\) such that \\(P_n(A) &gt; 0\\). Then \\(P(A) &gt; a_n P_n(A) &gt; 0\\). But \\(P &lt;&lt; \\nu\\) implies that \\(P(A) = 0\\), so by contradiction, \\(P_n(A) = 0\\) for all \\(n \\in {\\mathbb{N}}\\). Now assume \\(P_n &lt;&lt; \\nu\\). Let \\(A \\in {\\mathcal{F}}\\) with \\(\\nu(A) = 0\\). Then \\(P_n(A) = 0\\) for all \\(n \\in {\\mathbb{N}}\\). Hence, \\(P(A) = \\sum_{n=1}^\\infty a_n P_n(A) = 0\\), which means that \\(P &lt;&lt; \\nu\\). Exercise 4.10 (Ex 50) Exercise 4.11 (Ex 55) Let \\(X\\) be a random variable. Show that If \\(E X\\) exists, then \\(E X = \\int_0^\\infty P(X &gt; x) dx - \\int_{-\\infty}^0 P(X \\le x) dx\\). If \\(X\\) has range \\(0, 1, 2, ...\\), then \\(E X = \\sum_{n=1}^\\infty P(X \\ge x)\\) Solution (EX 55 (a)). First rewrite the RHS in terms of PDFS \\[\\int_0^\\infty \\int_x^\\infty f(y) dy dx - \\int_{-\\infty}^0 \\int_{-\\infty}^x f(y) dy dx\\] Then we can use Fubini (since \\(f\\) is positive) to switch the order of the integrals \\[ \\begin{aligned} &amp;= \\int_0^\\infty \\int_0^y f(y) dy dx - \\int_{-\\infty}^0 \\int_{-y}^0 f(y) dy dx \\\\ &amp;= \\int_0^\\infty f(y) \\int_0^y 1 dx dy - \\int_{-\\infty}^0 f(y) \\int_{-y}^0 1 dx dy \\\\ &amp;= \\int_0^\\infty f(y) y dy dx - \\int_{-\\infty}^0 -y \\cdot f(y) dy \\\\ &amp;= E X \\end{aligned} \\] Exercise 4.12 (Ex 56) Calculate the expectation and variance of the noncentral t distribution. Solution (Ex 56 (a)). We did these. The integrals were hard. There were two. We don’t have time to write up the nasty calculus, but do know that we suffered to prove this result. YAY MAAAAATH! We may staple the ugly to the back to the back of the nice solutions. Exercise 4.13 (Ex 65) TODO Exercise 4.14 (Ex 74) Let \\(\\phi_n\\) be a the chf of a probability measure \\(P_n, n = 1, 2, ...\\). Let \\(\\{a_n\\}\\) be a sequence of nonnegative numbers with \\(\\sum_{n=1}^\\infty a_n = 1\\). Show that \\(\\sum_{n=1}^\\infty a_n \\phi_n\\) is a ch.f. and find its corresponding probability measure. Solution (Ex 74). Take \\(P = \\sum_n a_n P_n\\). Note that \\(P_n\\) is dominated by \\(P\\), so that there exists a density \\(g_n = dP_n/dP\\) for each \\(n\\) (exercise 35). Consider \\(P(\\Omega) = \\int_\\Omega \\sum a_n g_n(x) dP = 1\\), so that \\(\\sum a_n g_n(x) = 1\\) almost everywhere. Then \\[ \\begin{aligned} \\sum_n a_n \\phi_n &amp;= \\sum_n a_n \\int e^{itx} g_n(x) dP \\\\ &amp;= \\int \\sum_n a_n e^{itx} g_n(x) dP \\qquad \\text{Fubini} \\\\ &amp;= \\int e^{itx} dP \\\\ &amp;= \\phi(x) \\end{aligned} \\] Exercise 4.15 (Ex 83) Exercise 4.16 (Ex 85) TODO Exercise 4.17 (Ex 93) TODO Exercise 4.18 (Ex 99) LEt \\(X_1, X_2, ...\\) be i.i.d random variables and let \\(Y\\) be a discrete random variable taking positive integer values. Assume that \\(X_i\\) and \\(Y\\) are independent. Obtain the ch.f. of Z Show \\(E Z = E Y E X_1\\) Show Var Z = E Y Var(X_1) + Var(Y) (E X_1)^2 Solution (Ex 99 (a)). TODO Solution (Ex 99 (b)). \\[ \\begin{aligned} E Z &amp;= E(\\sum_{i=1}^Y X_i) \\\\ &amp;= E( E(\\sum_{i=1}^Y X_i) | Y ) \\\\ &amp;= E(Y E(X_1 | Y)) \\\\ &amp;= EY E(E(X_1 | Y)) \\\\ &amp;= EY E X_1 \\end{aligned} \\] Solution (Ex 99 (c)). \\[ \\begin{aligned} Var Z &amp;= Var(E(Z | Y)) + E(Var(Z | Y)) \\\\ &amp;= Var(E(Y X_1 | Y)) + E(Var(Y X_1)) \\\\ &amp;= Var(Y E(X_1 | Y)) + E(Y^2 Var(X_1)) \\\\ &amp;= (E(X_1))^2 Var(Y) + E(Y^2) Var(X_1) \\end{aligned} \\] Exercise 4.19 (Ex 101) TODO Exercise 4.20 (Ex 106) Let \\(\\{Y_n\\}\\) be a sequence of independent random. Show that the following are martingales: \\(X_1 = Y_1\\), \\(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n)\\) where \\(h_n\\) are Borel. Suppose \\(E Y_n = 0\\) and \\(Var Y_n = \\sigma^2\\) for all \\(n\\). \\(X_n = (sum_{j=1}^n Y_j)^2 - n \\sigma^2\\) Suppose \\(Y_n &gt; 0\\) and \\(E Y_n = 1\\) for all \\(n\\). \\(X_n = Y_1 \\cdot ... \\cdot Y_n\\). Solution (Ex 106 (a)). Recall that a sequence \\(X_n\\) is a martingale if \\(E(X_{n+1} | X_1, ..., X_n) = X_n\\). \\[ \\begin{aligned} E(X_{n+1} = X_n + Y_{n+1} h_n(X_1, ..., X_n) | X_1, ..., X_n) &amp;= X_n + h_n(X_1, ..., X_n) E(Y_{n+1} | X_1, ..., X_n) \\\\ &amp;= X_n + h_n(X_1, ..., X_n) 0 \\\\ &amp;= X_n \\end{aligned} \\] Solution (Ex 106 (b)). \\[ \\begin{aligned} E(\\sum_{j=1}^{n+1} Y_j)^2 - (n + 1) \\sigma^2 | X_1, ..., X_n) &amp;= E(\\sum_{j=1}^{n} Y_j + Y_{n+1})^2 | X_1, ..., X_n) - (n + 1) \\sigma^2 \\\\ &amp;= E(\\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1} \\cdot \\sum_{j=1}^{n} Y_j | X_1, ..., X_n) + E(Y_{n+1}^2 | X_1, ..., X_n) - (n + 1) \\sigma^2 \\\\ &amp;= E(\\sum_{j=1}^{n} Y_j | X_1, ..., X_n)^2 + E(Y_{n+1}) E(\\sum_{j=1}^{n} Y_j | X_1, ..., X_n) + \\sigma^2 - (n + 1) \\sigma^2 \\\\ &amp;= (\\sum_{j=1}^{n} Y_j)^2 + n \\sigma^2 \\end{aligned} \\] Solution (Ex 106 (c)). \\[ \\begin{aligned} E( Y_1 \\cdot ... \\cdot Y_n \\cdot Y_{n+1} | X_1, ..., X_n) &amp;= Y_1 \\cdot ... \\cdot Y_n E(Y_{n+1} | X_1, ..., X_n) \\\\ &amp;= Y_1 \\cdot ... \\cdot Y_n \\\\ &amp;= X_n \\end{aligned} \\] Exercise 4.21 (Ex 115) Let \\(X_1, X_2, ...\\) be a sequence of identically distributed random variables with finite \\(E |X_1|\\) and let \\(Y_n = n^{-1} \\max_{i \\le n} |X_i|\\). Show that \\(Y_n \\to 0\\) in \\(L_1\\) Show that \\(Y_n \\to 0\\) almost surely Solution (Ex 115 (a)). \\(E Y_n = \\int_0^\\infty {1 \\over n} P(\\max_{i \\le n} |X_i| &gt; t) dt\\) by exercise 1.55. The integrand is then bounded by \\[{1 \\over n} \\sum P(\\max_{i \\le n} |X_i| &gt; t)\\] which equals \\({1 \\over n} P(|X_1| &gt; t)\\) since the \\(X_i\\) are identical. This is finite by hypothesis. Thus we can apply the DCT to see that \\[\\lim E Y_n = \\int_0^\\infty \\lim {1 \\over n} P(\\max_{i \\le n} |X_i| &gt; t) dt = 0\\] Solution (Ex 115 (b)). The condition that \\(E |X_1|\\) converges and being identical gives us that that \\(\\lim X_n / n\\) converges to zero almost surely. then we truncate. for some large enough N, \\(X_n / n\\) must be less than epsilon. then for \\(|X_n| / n\\) for n &lt; N, there are only finitely many cases and so the max exists and is bounded, and goes to zero by the \\(n\\) in the denominator. this gives us that \\(\\lim Y_n\\) goes to zero as \\(n\\) goes to zero. in fact it goes to zero almost everywhere, since the limit \\(|X_n| / n\\) goes to zero almost everywhere by the hypothesis that \\(X_n\\) is absolutely integrable. thus \\(\\lim Y_n\\) goes to zero almost surely. Exercise 4.22 (Ex 117) Exercise 4.23 (Ex 126) Prove (vii) of Theorem 1.8 Solution. Let \\(X_n \\to d X\\), \\(P(X = c) = 1\\). Apply triangle inequality and assumption: \\[ \\lim_{n \\to \\infty} P({\\left | \\left | X_n - c \\right | \\right |} &gt; \\epsilon) \\le \\lim_{n \\to \\infty} P({\\left | \\left | X_n - X \\right | \\right |} &gt; \\epsilon) + \\lim_{n \\to \\infty} P({\\left | \\left | X - c \\right | \\right |} &gt; \\epsilon) = 0. \\] Exercise 4.24 (Ex 127) (a) Suppose X_n converge in distribution to X. Show X_n is O_P(1). Solution (Ex 127 (a)). Suppose X_n converge in distribution to X. For large enough M, we have \\(P(|X| &gt; M) &lt; \\epsilon_1\\) (i.e the tail probability is small). For large enough \\(n\\), \\(P(|X_n| &gt; \\epsilon_1) - P(|X| &gt; \\epsilon) &lt; \\epsilon) &lt; \\epsilon_2\\). Pick \\(n\\) large enough so that \\(\\epsilon_2\\) is controlled. http://users.ices.utexas.edu/~alen/articles/asymp-final.pdf - page 7 Exercise 4.25 (Ex 128) Exercise 4.26 (Ex 137) Let \\(\\{X_n\\}\\) and \\(\\{Y_n\\}\\) be two sequences of R.Vs. Assume \\(X_n \\to_d X\\) and \\(P_{Y_n | X_n = x_n} \\to_w P_Y\\) almost surely for every sequence of numbers \\(\\{x_n\\}\\), where \\(X\\) and \\(Y\\) are independent random variables. Show that \\(X_n + Y_n \\to_d X + Y\\). Solution. \\[ P_{Y_n,X_n} = P_{Y_n|X_n}\\cdot P_{X_n} \\to P_Y P_X = P_{Y,X}, \\] where the last equality holds due to independence of \\(X\\) and \\(Y\\). Exercise 4.27 (Ex 138) Exercise 4.28 (Ex 140) \\(X_n \\sim N(\\mu_n, \\sigma^2_n, n \\in {\\mathbb{N}}\\) and \\(X \\sim N(\\mu, \\sigma^2)\\). Show that \\(X_n \\to_d X \\iff \\mu_n \\to \\mu\\) and \\(\\sigma_n \\to \\sigma\\). Solution. Assume \\(\\mu_n \\to \\mu\\) and \\(\\sigma_n \\to \\sigma\\). Then \\(f_n(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma_n}e^{\\tfrac{-(x-\\mu_n)^2}{\\sigma_n}} \\to f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\tfrac{-(x-\\mu)^2}{\\sigma}}\\) for all \\(x\\). Hence, \\(X_n \\to_d X\\). Assume \\(X_n \\to_d X\\), and assume for contradiciton that \\((\\mu_n, \\sigma^2_n) \\to (a,b^2) \\neq (\\mu, \\sigma^2)\\). This implies that \\(f_n = \\frac{1}{\\sqrt{2\\pi}\\sigma_n}e^{\\tfrac{-(x-\\mu_n)^2}{\\sigma_n}} \\to f = \\frac{1}{\\sqrt{2\\pi}b}e^{\\tfrac{-(x-a)^2}{b}}\\), hence \\(X_n \\to_d Y\\) where \\(Y \\sim N(a,b^2)\\). Since \\((a,b) \\neq (\\mu, \\sigma^2)\\), and we know the limiting distribution is unique, this contradicts our assumption. Exercise 4.29 (Ex 142) \\(f_n\\) is the Lebesgue p.d.f. of the t-distribution \\(t_n\\). Show that \\(f_n(x) \\to f(x)\\) for all \\(x \\in {\\mathbb{R}}\\), where \\(f\\) is the Lebesgue p.d.f. for standard normal. Solution. By definition, \\(f_n(x) = \\frac{\\Gamma(\\tfrac{n+1}{2})}{\\sqrt{n\\pi} \\Gamma(\\tfrac{n}{2})}\\left(1 + \\frac{x^2}{n}\\right)^{\\tfrac{-(n+1)}{2}}\\). Note that \\(\\lim_{n \\to \\infty}\\left(1+\\frac{x}{n}\\right)^n = e^x\\). So, since \\(\\sqrt{1+\\tfrac{x^2}{n}} \\to 0\\), \\[\\left(1 + \\frac{x^2}{n}\\right)^{\\tfrac{-(n+1)}{2}} = \\frac{1}{\\left(1+\\tfrac{x^2/2}{n/2}\\right)^{-n/2}\\sqrt{1+\\tfrac{x^2}{n}}} \\to e^{-x^2/2}.\\] Since \\(\\lim_{n \\to \\infty} \\frac{\\Gamma(n + c)}{\\Gamma(n)n^c} = 1\\), \\[\\lim_{n \\to \\infty} \\frac{\\Gamma(\\tfrac{n}{2} + \\tfrac{1}{2})}{\\Gamma(\\tfrac{n}{2})\\sqrt{n/2}} = 1.\\] So \\[\\begin{aligned} \\lim_{n \\to \\infty} f_n(x) &amp;= \\lim_{n\\to \\infty} \\frac{\\Gamma(\\tfrac{n+1}{2})}{\\sqrt{n\\pi} \\Gamma(\\tfrac{n}{2})}\\left(1 + \\frac{x^2}{n}\\right)^{\\tfrac{-(n+1)}{2}} \\\\ &amp;= \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}\\lim_{n\\to \\infty}\\frac{\\Gamma(\\tfrac{n}{2} + \\tfrac{1}{2})}{\\Gamma(\\tfrac{n}{2})\\sqrt{n/2}} \\\\ &amp;= \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}. \\end{aligned}\\] Exercise 4.30 (Ex 146) Let \\(U_1, U_2, \\ldots\\) be i.i.d. random variables, \\(U_i \\sim U[0,1]\\). Let \\(Y_n = (\\prod_{i=1}^n U_i)^{-1/n}\\). Show that \\(\\sqrt{n}(Y_n - e) \\to_d N(0,e^2)\\). Solution. Let \\(X_i = -log(U_i)\\). Then \\(EX_1 = \\text{Var}(X_1) = 1\\), and implies \\(U_i = e^{-X_i}\\). So \\[\\begin{aligned} Y_n &amp;= \\left(\\prod_{i=1}^n e^{-X_u} \\right)^{-1/n} \\\\ &amp;= e^{\\tfrac{1}{n}\\sum_{i=1}^n X_i}. \\end{aligned}\\] By the CLT (corollary 1.2; page 69), \\(\\tfrac{1}{\\sqrt{n}}\\sum_{i=1}^n (X_i - EX_1) = \\tfrac{n}{\\sqrt{n}}\\left(\\tfrac{1}{n}\\sum_{i=1}^n X_i - 1\\right) \\to_d N(0, 1)\\). Let \\(g = e^{x}\\). Then \\(g^\\prime(x) = g(x)\\), and \\(U_i = g(X_i)\\). Using the delta method (specifically corollary 1.1; page 61), we get that \\[ \\sqrt{n}\\left(Y_n - e\\right) = \\tfrac{n}{\\sqrt{n}}\\left(g\\left(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\right) - g(1)\\right) \\to_d N(0,g(1)^2) = N(0, e^2). \\] Exercise 4.31 (Ex 149) Let \\(X_1, \\ldots X_n\\) be i.i.d. random variables such that for \\(x = 3,4,\\ldots\\), \\(P(X_1 = \\pm x) = (2cx^2 \\log(x))^{-1}\\), where \\(c = \\sum_{x=3}^\\infty \\tfrac{x^{-2}}{\\log(x)}\\). Show that \\(E|X_1| = \\infty\\), but \\(\\tfrac{1}{n} \\sum_{i=1}^n X_i \\to_p 0\\), using Theorem 1.13(i). Solution. Notice that \\[ E|X_1| = \\sum_{x=3}^\\infty 2\\frac{x}{2cx^2\\log(x)} = \\frac{1}{c}\\sum_{x=3}^\\infty \\frac{1}{x\\log(x)} \\ge \\tfrac{1}{c} \\int_3^\\infty \\frac{1}{x\\log(x)}dx = \\infty, \\] and that \\(EX_1 = 0\\). (To see that the inequality above holds, draw it!) Consider \\(nP(|X_1| &gt; n)\\): \\[ \\begin{aligned} nP(|X_1| &gt; n) &amp;= n\\sum(x=n)^\\infty \\frac{1}{2cx^2\\log(x)} \\\\ &amp;\\le \\frac{n}{c} \\int_n^\\infty \\frac{1}{x^2\\log(x)} dx \\\\ &amp;\\le \\frac{n}{c\\log(n)} \\int_n^\\infty \\frac{1}{x^2} dx \\\\ &amp;= \\frac{n}{c\\log(n)} \\frac{1}{n} \\to 0 \\text{ as } n \\to \\infty. \\end{aligned} \\] So by theorem 1.13(i), we \\(\\frac{1}{n}\\sum_{i=1}^n X_i - a_n \\to_p 0\\), where \\(a_n = E(X_1 I_{\\left\\{|X_1| \\le n\\right\\}}) \\to 0\\) (can be seen using an argument as above). Exercise 4.32 (Ex 152) Let \\(T_n = \\sum_{i=1}^n X_i\\), where \\(X_1,X_2,\\ldots\\) are independent and \\(P(X_n = \\pm n^\\theta) = 0.5\\) for some \\(\\theta &gt; 0\\). Show that when \\(\\theta &lt; 0.5\\), then \\(T_n/n \\to_{a.s.} 0\\) Show that when \\(\\theta \\ge 1\\), then \\(T_n/n \\to_{p} 0\\) does NOT hold Solution. (a) Since \\(\\theta &lt; 0.5\\), \\(2(\\theta - 1) &lt; -1\\). So \\[ \\begin{aligned} \\sum_{n=1}^\\infty \\frac{E|X_n|^2}{n^2} &amp;= \\sum_{n=1}^\\infty \\frac{(n^\\theta)^2}{n^2} \\\\ &amp;= \\sum_{n=1}^\\infty n^{2(\\theta - 1)} &lt; \\infty. \\end{aligned} \\] By SLLN, \\(T_n/n = \\frac{1}{n} \\sum_{i=1}^\\infty X_i \\to_{a.s.} EX_1 = 0\\). Note that the p.d.f. of \\(X_n\\) is \\(F_n(x) = 0 1_{X_n &lt; -n^\\theta} + \\tfrac{1}{2}1_{-n^\\theta \\le X_n &lt; n^\\theta} + 1_{X_n \\ge n^\\theta}\\). By definition, \\(X_n \\to_d 0\\) if and only if \\(F_n(x) \\to F(x) = 1_{(X \\ge 0)}\\) for all \\(x\\) continuity points of \\(F\\). For any \\(n &gt; 1\\), \\(F_n(\\tfrac{-n^\\theta}{2}) = 0.5 \\neq F(\\tfrac{-n^\\theta}{2}) = 0\\). So \\(X_n\\) does not converge to \\(0\\) in distribution. By theorem 1.8(iii), this means that \\(X_n\\) does not converge to \\(0\\) in probability (since convergence in probability implies convergence in distribution). Exercise 4.33 (Ex 153) Let \\(X_2, X_3, \\ldots\\) be independent random variables with \\(P(X_n = \\pm \\sqrt{n/\\log(n)}) = 0.5\\). Show that \\(\\sum_{k=1}^\\infty \\frac{E|X_k|^p}{k^p} = \\infty\\) for all \\(p \\in [1,2]\\), but \\(\\lim_{n \\to \\infty}\\frac{1}{n^2} \\sum_{i = 1}^\\infty E|X_i|^2 = 0\\). Solution. For any \\(p\\in [1,2]\\): \\[ \\sum_{n=2}^\\infty \\frac{E|X_n|^p}{n^p} = \\sum_{n=2}^\\infty \\frac{(n/\\log(n))^{p/2}}{n^p} = \\sum_{n=2}^/infty \\frac{1}{(n\\log(n))^{p/2}} = \\infty. \\] Use that \\(\\log(x)\\) is an increasing function: \\[\\begin{aligned} \\lim_{n \\to \\infty} \\frac{1}{n^2} \\sum_{k=2}^n E|X_k|^2 &amp;= \\lim_{n \\to \\infty} \\frac{1}{n^2} \\sum_{k=2}^\\infty \\frac{k}{\\log(k)} \\\\ &amp;\\leq \\lim_{n \\to \\infty} \\frac{(n-1)\\tfrac{n}{\\log(n)}}{n^2} \\\\ &amp;\\leq \\lim_{n \\to \\infty} \\frac{n \\tfrac{n}{\\log(n)}}{n^2} \\\\ &amp;\\leq \\lim_{n \\to \\infty} \\frac{1}{\\log(n)} = 0. \\end{aligned}\\] Exercise 4.34 (Ex 163) Exercise 4.35 (Ex 164) Let \\(X_1, X_2, \\ldots\\) be independent variables with \\(P(X_j = \\pm j^a) = P(X_j = 0) = \\tfrac{1}{3}\\), where \\(a &gt; 0\\), \\(j=1,2,\\ldots\\). Does Liapounov’s condition hold? Solution. \\(\\sigma_n^ = \\sqrt{\\sum_{j=1}^n \\frac{2j^{2a}}{3}}\\). So, want to see if \\[ \\frac{\\sum_{j=1}^n E|X_j - EX_j|^{2+\\delta}}{\\sigma_n^{2+\\delta}} \\to 0. \\] So, \\[\\begin{aligned} \\frac{\\sum_{j=1}^n \\left(\\tfrac{2}{3}j^{2a}\\right)^{2+\\delta}}{\\left(\\tfrac{2}{3}\\sum_{j=1}^n j^{2a}\\right)^{(2+\\delta)/2}} &amp;= \\frac{(\\tfrac{2}{3})^{2+\\delta}}{(\\tfrac{2}{3})^{(2+\\delta)/2}} \\frac{\\sum_{j=1}^\\infty j^{(2+\\delta)a}}{\\left(\\sum_{j=1}^\\infty j^{2a}\\right)^{(2+\\delta)/2}}. \\end{aligned}\\] Choose \\(\\delta = 2\\). Using Jensens inequality with \\(\\phi(x) = x^2\\) and the ratio test, we see that \\[ \\frac{(\\tfrac{2}{3})^4}{(\\tfrac{2}{3})^2} \\frac{\\sum_{j=1}^\\infty ((j^a)^2)^2}{\\left(\\sum_{j=1}^\\infty j^{2a}\\right)^{2}} \\to 0. \\] 4.1.2 Suggested Problems Exercise 4.36 (Ex 3) Let \\(\\Omega, {\\mathcal{F}}_j)\\), \\(j=1,2,\\ldots\\), be measurable spaces such that \\({\\mathcal{F}}_j \\subset {\\mathcal{F}}_{j+1}\\). Is \\(\\cup_j {\\mathcal{F}}_j\\) a \\(\\sigma\\)-field? Solution (Ex 3). No. Let \\(\\Omega = [0,1]\\), and \\({\\mathcal{F}}_n = \\sigma \\left\\{[0,\\tfrac{1}{2^n}),[\\tfrac{1}{2^n},\\tfrac{2}{2^n}), \\ldots, [\\tfrac{2^{n-1}}{2^n}, 1)\\right\\}\\). Now, consider the set \\(B_n = [0, \\tfrac{1}{2^n})\\). Clearly \\(B_n \\in {\\mathcal{F}}_n\\) for all \\(n\\), hence \\(B_n \\in \\cup_{i=1}^\\infty {\\mathcal{F}}_i\\). Hower, \\(\\cap_{i = 1}^{\\infty} B_i = \\{0\\} \\notin \\cup_{i=1}^\\infty {\\mathcal{F}}_i\\). So \\(\\cup_{i=1}^\\infty {\\mathcal{F}}_i\\) is not closed under countable intersection, i.e. it is not a \\(\\sigma\\)-algebra. Exercise 4.37 (Ex 6) Prove part (ii) and (iii) of proposition 2.1. Solution (Ex 6). i) Let \\(A \\subset B\\). Then \\(B \\setminus A \\cap A = \\emptyset\\), hence \\(\\nu(B) = \\nu((B\\setminus A) \\cup A) = \\nu(B\\setminus A) + \\nu(A) \\geq \\nu(A)\\). Let \\(A_1, A_2, \\ldots\\) be a sequence of sets. Define \\(B_i = A_i \\setminus \\left(\\cup_{k = 1}^{i-1} A_k \\right)\\). Then the \\(B_i\\)s are pairwise disjoint. Hence, \\[\\begin{align*} \\nu\\left(\\cup_{i = 1}^\\infty A_i\\right) &amp;= \\nu\\left(\\cup_{i=1}^\\infty B_i\\right) \\\\ &amp;= \\sum_{i=1}^\\infty \\nu(B_i) \\\\ &amp;= \\sum_{i=1}^\\infty \\nu\\left(A_i \\setminus \\left(\\cup_{k=1}^{i-1} A_k \\right ) \\right ). \\end{align*}\\] Since \\(A_i \\setminus \\left(\\cup_{k=1}^{i-1} A_k \\right) \\subset A_i\\), we use (i) to get the result: \\[\\begin{align*} \\sum_{i=1}^\\infty \\nu\\left(A_i \\setminus \\left(\\cup_{k=1}^{i-1} A_k \\right ) \\right ) \\leq \\sum_{i=1}^\\infty \\nu\\left(A_i \\right ) \\end{align*}\\] Let \\(A_1 \\subset A_2 \\subset A_3 \\subset \\dots\\). Define \\(B_i = A_i \\setminus A_{i-1}\\). Then \\(B_1, B_2, \\ldots\\) is a sequence of pairwise disjoint sets, and \\(\\cup_{i = 1}^\\infty B_i = \\cup_{i=1}^\\infty A_i\\). Hence, \\[\\begin{align*} \\nu\\left(\\cup_{i=1}^k A_i\\right) &amp;= \\nu\\left(\\cup_{i=1}^k B_i\\right) \\\\ &amp;= \\sum_{i=1}^k \\nu(B_i) \\\\ &amp;= \\sum_{i=1}^k \\nu(A_i\\setminus A_{i-1}) \\\\ &amp;= \\sum_{i=1}^k \\nu(A_i) - \\nu(A_{i-1}) \\\\ &amp;= \\nu(A_k). \\end{align*}\\] Taking the limit on both sides gives us \\[ \\nu\\left(\\cup_{i=1}^k A_i \\right) = \\lim_{n \\to \\infty} \\nu(A_n). \\] Exercise 4.38 (Ex 15) Show that a monotone function from \\({\\mathbb{R}}\\) to \\({\\mathbb{R}}\\) is Borel, and a c.d.f. on \\({\\mathbb{R}}^k\\) is Borel. Exercise 4.39 (Ex 17) Let \\(f\\) be a non-negative Borel function on \\((\\Omega, {\\mathcal{F}})\\). Show that \\(f\\) is the limit of a sequence of simple functions \\(\\{\\phi_n \\}\\) on \\((\\Omega, {\\mathcal{F}})\\) with \\(0 \\le \\phi_1 \\le \\phi_2 \\le \\dots \\le f\\). Exercise 4.40 (Ex 23) Exercise 4.41 (Ex 25) Exercise 4.42 (Ex 31) Exercise 4.43 (Ex 36) Exercise 4.44 (Ex 46) Exercise 4.45 (Ex 53) Exercise 4.46 (Ex 57) Exercise 4.47 (Ex 61) Exercise 4.48 (Ex 66) Exercise 4.49 (Ex 70) Exercise 4.50 (Ex 73) Exercise 4.51 (Ex 78) Exercise 4.52 (Ex 79) Exercise 4.53 (Ex 81) Exercise 4.54 (Ex 82) Exercise 4.55 (Ex 86) Exercise 4.56 (Ex 88) Exercise 4.57 (Ex 91) Exercise 4.58 (Ex 97) Exercise 4.59 (Ex 98) Exercise 4.60 (Ex 102) Exercise 4.61 (Ex 104) Exercise 4.62 (Ex 114) Exercise 4.63 (Ex 116) Exercise 4.64 (Ex 116) Exercise 4.65 (Ex 118) Exercise 4.66 (Ex 119) Exercise 4.67 (Ex 121) Exercise 4.68 (Ex 122) TODO - Alex Exercise 4.69 (Ex 125) Exercise 4.70 (Ex 136) Exercise 4.71 (Ex 141) Exercise 4.72 (Ex 144) Exercise 4.73 (Ex 145) Exercise 4.74 (Ex 150) Exercise 4.75 (Ex 154) Exercise 4.76 (Ex 156) Exercise 4.77 (Ex 161) Exercise 4.78 (Ex 166) Note: This could be done in one step, but I found it easier to split up into two.↩ "]
]
